[
  {
    "conv_id": "barcor_redial_03368a16-93bd-4b21-885d-b9a21e3498ba",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0,
          "interestingness": 0.8374999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.675,
          "interestingness": 1.003125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.30000000000000004,
          "interestingness": 0.475
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.6875,
          "interestingness": 1.2499999999999998
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.1125,
          "interestingness": 0.25000000000000006
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.1375,
          "interestingness": 0.12499999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5125,
      "task_completion": 0.34166666666666673,
      "interest_arousal": 0.3486111111111111,
      "efficiency": 0.20416666666666666,
      "dialogue_overall": 1.5708333333333333
    }
  },
  {
    "conv_id": "barcor_opendialkg_06002459-56ea-4392-9230-3625e0477259",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9999999999999999,
          "interestingness": 0.7749999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.004166666666666667,
          "interestingness": 0.05833333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.08125,
          "interestingness": 0.9624999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.23125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.44583333333333336
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.25113636363636366,
      "task_completion": 0.13068181818181818,
      "interest_arousal": 0.20113636363636364,
      "efficiency": 0.051136363636363646,
      "dialogue_overall": 1.0079545454545453
    }
  },
  {
    "conv_id": "kbrd_opendialkg_07f6c3a0-7623-43d3-85a9-0608b6876c59",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.1125,
          "interestingness": 0.7
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9249999999999999,
          "interestingness": 1.1458333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.11875000000000002,
          "interestingness": 0.5375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.13333333333333333,
          "interestingness": 0.29166666666666663
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.22750000000000006,
      "task_completion": 0.20625000000000004,
      "interest_arousal": 0.2675,
      "efficiency": 0.03,
      "dialogue_overall": 1.02875
    }
  },
  {
    "conv_id": "kbrd_opendialkg_049a839e-89e5-4e0b-92e7-f72eb5052ca5",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.2625,
          "interestingness": 0.4083333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2041666666666667,
      "task_completion": 0.07916666666666666,
      "interest_arousal": 0.2875000000000001,
      "efficiency": 0.05416666666666667,
      "dialogue_overall": 0.8416666666666668
    }
  },
  {
    "conv_id": "barcor_redial_06c2c40a-921b-414a-85cc-2501469605cd",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6875,
          "interestingness": 0.6
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.18750000000000003,
          "interestingness": 0.275
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.05,
          "interestingness": 0.7458333333333332
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.05
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.17500000000000002,
          "interestingness": 0.3125
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.35
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.15
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.6083333333333334,
          "interestingness": 0.7958333333333333
        }
      },
      {
        "turn_ind": 19,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.275
        }
      },
      {
        "turn_ind": 21,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.15000000000000002
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3539473684210526,
      "task_completion": 0.44999999999999996,
      "interest_arousal": 0.2440789473684211,
      "efficiency": 0.10986842105263159,
      "dialogue_overall": 1.2717105263157895
    }
  },
  {
    "conv_id": "kbrd_opendialkg_06c2c40a-921b-414a-85cc-2501469605cd",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.3375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.3125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.6208333333333333,
          "interestingness": 0.9125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.05625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.09230769230769231,
      "task_completion": 0.08365384615384616,
      "interest_arousal": 0.10288461538461541,
      "efficiency": 0.03076923076923077,
      "dialogue_overall": 0.8500000000000001
    }
  },
  {
    "conv_id": "barcor_opendialkg_03368a16-93bd-4b21-885d-b9a21e3498ba",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9625000000000001,
          "interestingness": 0.9499999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5125000000000001,
          "interestingness": 0.73125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.4541666666666667,
          "interestingness": 0.9708333333333333
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.11666666666666665,
          "interestingness": 0.46249999999999997
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.21250000000000002,
          "interestingness": 0.975
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.41250000000000003
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.64375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4883928571428572,
      "task_completion": 0.32946428571428565,
      "interest_arousal": 0.3776785714285715,
      "efficiency": 0.12053571428571425,
      "dialogue_overall": 1.5339285714285713
    }
  },
  {
    "conv_id": "chatgpt_redial_112ed1c0-abc5-44bc-bf14-b1f9267845da",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.32083333333333336,
          "interestingness": 0.4458333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3833333333333334,
      "task_completion": 0.2750000000000001,
      "interest_arousal": 0.4166666666666667,
      "efficiency": 0.3458333333333334,
      "dialogue_overall": 2.029166666666667
    }
  },
  {
    "conv_id": "kbrd_redial_07f6c3a0-7623-43d3-85a9-0608b6876c59",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.16875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.51875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.025,
      "task_completion": 0.0125,
      "interest_arousal": 0.021875,
      "efficiency": 0.003125,
      "dialogue_overall": 0.88125
    }
  },
  {
    "conv_id": "kbrd_redial_11454a65-c9de-406d-ba1c-47130c903123",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.275
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.1875
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.5
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.05833333333333333,
      "task_completion": 0.049999999999999996,
      "interest_arousal": 0.06249999999999999,
      "efficiency": 0.0,
      "dialogue_overall": 0.8833333333333334
    }
  },
  {
    "conv_id": "crbcrs_redial_112ed1c0-abc5-44bc-bf14-b1f9267845da",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.8125000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.15625,
      "task_completion": 0.043750000000000004,
      "interest_arousal": 0.56875,
      "efficiency": 0.0125,
      "dialogue_overall": 1.16875
    }
  },
  {
    "conv_id": "kbrd_opendialkg_11454a65-c9de-406d-ba1c-47130c903123",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.1625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.020833333333333336,
          "interestingness": 0.35833333333333334
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.037500000000000006
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.052500000000000005,
      "task_completion": 0.045,
      "interest_arousal": 0.07500000000000001,
      "efficiency": 0.0,
      "dialogue_overall": 0.8324999999999999
    }
  },
  {
    "conv_id": "chatgpt_redial_1219a3b4-799e-469d-93b9-b3f0301af910",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.14166666666666666,
          "interestingness": 0.41666666666666663
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.5675,
          "interestingness": 0.69125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.1288461538461536,
      "task_completion": 0.7384615384615386,
      "interest_arousal": 0.7326923076923076,
      "efficiency": 0.6134615384615385,
      "dialogue_overall": 2.583653846153846
    }
  },
  {
    "conv_id": "kbrd_opendialkg_1222c881-4bcb-4140-bbe1-7de32cbc5a4b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.23750000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.016666666666666666,
          "interestingness": 0.22083333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.21250000000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.003125,
          "interestingness": 0.11250000000000002
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.026923076923076925,
      "task_completion": 0.021153846153846155,
      "interest_arousal": 0.042307692307692296,
      "efficiency": 0.0,
      "dialogue_overall": 0.6711538461538461
    }
  },
  {
    "conv_id": "crbcrs_redial_1219a3b4-799e-469d-93b9-b3f0301af910",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.4375,
          "interestingness": 0.4
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.49999999999999994,
          "interestingness": 0.5812499999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.07500000000000001,
          "interestingness": 0.8812499999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.07083333333333333,
          "interestingness": 0.65
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.19375000000000003,
          "interestingness": 0.69375
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.041666666666666664,
          "interestingness": 0.6958333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.14642857142857144,
      "task_completion": 0.08928571428571429,
      "interest_arousal": 0.18928571428571425,
      "efficiency": 0.03035714285714286,
      "dialogue_overall": 1.1178571428571427
    }
  },
  {
    "conv_id": "unicrs_opendialkg_12983dfe-96a9-46f5-b807-17c90659e3a8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.075
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.0,
      "task_completion": 0.0,
      "interest_arousal": 0.0625,
      "efficiency": 0.0,
      "dialogue_overall": 0.7625000000000001
    }
  },
  {
    "conv_id": "unicrs_redial_12983dfe-96a9-46f5-b807-17c90659e3a8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.36250000000000004
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.0875,
      "task_completion": 0.0,
      "interest_arousal": 0.1125,
      "efficiency": 0.0125,
      "dialogue_overall": 0.9625000000000001
    }
  },
  {
    "conv_id": "barcor_opendialkg_16369e84-4f9d-4651-ae37-47476fa0d3eb",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7583333333333334,
          "interestingness": 0.44583333333333325
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.43437499999999996,
          "interestingness": 0.778125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6839285714285714,
      "task_completion": 0.2946428571428572,
      "interest_arousal": 0.46964285714285714,
      "efficiency": 0.11250000000000002,
      "dialogue_overall": 1.5446428571428574
    }
  },
  {
    "conv_id": "unicrs_opendialkg_16369e84-4f9d-4651-ae37-47476fa0d3eb",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0999999999999999,
          "interestingness": 0.09999999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5125,
      "task_completion": 0.23750000000000004,
      "interest_arousal": 0.30000000000000004,
      "efficiency": 0.075,
      "dialogue_overall": 1.025
    }
  },
  {
    "conv_id": "barcor_opendialkg_183a5018-f232-4b96-9a77-1b18641f48d4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6437499999999999,
          "interestingness": 0.8625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.44999999999999996,
          "interestingness": 0.6625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.6875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.19375000000000003,
          "interestingness": 0.9624999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.2916666666666667,
          "interestingness": 0.30833333333333335
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2111111111111111,
      "task_completion": 0.13055555555555556,
      "interest_arousal": 0.20833333333333334,
      "efficiency": 0.018055555555555557,
      "dialogue_overall": 1.3027777777777774
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_199b3c22-e01a-4930-a148-caeb5c48b21d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.145,
          "interestingness": 0.8350000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.6500000000000001,
          "interestingness": 1.0989583333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.5102941176470586,
      "task_completion": 0.9176470588235294,
      "interest_arousal": 1.1632352941176474,
      "efficiency": 0.7698529411764707,
      "dialogue_overall": 2.886764705882353
    }
  },
  {
    "conv_id": "chatgpt_redial_199b3c22-e01a-4930-a148-caeb5c48b21d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.37083333333333335,
          "interestingness": 1.0999999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.605,
          "interestingness": 1.175
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.92875,
          "interestingness": 0.4800000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.9282608695652174,
      "task_completion": 1.0934782608695652,
      "interest_arousal": 0.6364130434782609,
      "efficiency": 0.321195652173913,
      "dialogue_overall": 2.485869565217391
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_2143d736-b14f-4668-a1df-4d03f281df60",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9916666666666667,
          "interestingness": 0.8875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.814423076923077,
          "interestingness": 1.4625000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5833333333333334,
          "interestingness": 1.4375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.1587499999999997,
          "interestingness": 0.8937499999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.3250000000000002,
          "interestingness": 1.3875
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.30833333333333335,
          "interestingness": 0.6416666666666666
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6651515151515153,
      "task_completion": 0.4977272727272727,
      "interest_arousal": 0.4151515151515152,
      "efficiency": 0.15946969696969696,
      "dialogue_overall": 1.806439393939394
    }
  },
  {
    "conv_id": "chatgpt_redial_22bd263f-c560-4cf5-be82-84e9130ec998",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.245833333333333,
          "interestingness": 0.4708333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8458333333333333,
      "task_completion": 0.3166666666666667,
      "interest_arousal": 0.6583333333333332,
      "efficiency": 0.6166666666666666,
      "dialogue_overall": 2.4000000000000004
    }
  },
  {
    "conv_id": "barcor_opendialkg_22bd263f-c560-4cf5-be82-84e9130ec998",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.33125,
          "interestingness": 0.7562500000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.2125,
          "interestingness": 0.5874999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.4708333333333333,
          "interestingness": 1.3624999999999998
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.37142857142857144,
      "task_completion": 0.19642857142857142,
      "interest_arousal": 0.4964285714285715,
      "efficiency": 0.057142857142857155,
      "dialogue_overall": 1.7464285714285719
    }
  },
  {
    "conv_id": "unicrs_opendialkg_25ded133-2225-4183-af7b-ff98096d85e1",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.115625,
          "interestingness": 0.26250000000000007
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.025
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.08000000000000002,
      "task_completion": 0.0825,
      "interest_arousal": 0.16750000000000004,
      "efficiency": 0.037500000000000006,
      "dialogue_overall": 1.135
    }
  },
  {
    "conv_id": "unicrs_redial_25ded133-2225-4183-af7b-ff98096d85e1",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.7875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5208333333333334,
          "interestingness": 0.7250000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.0250000000000001,
      "task_completion": 0.459375,
      "interest_arousal": 0.6499999999999999,
      "efficiency": 0.48749999999999993,
      "dialogue_overall": 2.3
    }
  },
  {
    "conv_id": "barcor_opendialkg_2143d736-b14f-4668-a1df-4d03f281df60",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9083333333333334,
          "interestingness": 0.44583333333333336
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.3125,
          "interestingness": 0.2
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.49374999999999997,
          "interestingness": 0.79375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.74375,
          "interestingness": 0.296875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5125000000000001,
      "task_completion": 0.34125,
      "interest_arousal": 0.28750000000000003,
      "efficiency": 0.043750000000000004,
      "dialogue_overall": 1.19
    }
  },
  {
    "conv_id": "kbrd_opendialkg_27a7298f-4ca2-441a-83dc-011f5d1ed5ea",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.1375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.0125,
      "task_completion": 0.037500000000000006,
      "interest_arousal": 0.0625,
      "efficiency": 0.0,
      "dialogue_overall": 0.875
    }
  },
  {
    "conv_id": "barcor_opendialkg_28979d07-3f1c-44db-b669-df937a4353a1",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.31875,
          "interestingness": 0.81875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5958333333333332,
          "interestingness": 1.0125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.47500000000000003,
          "interestingness": 0.5666666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.38749999999999996,
      "task_completion": 0.7921874999999999,
      "interest_arousal": 0.6140625,
      "efficiency": 0.275,
      "dialogue_overall": 1.7999999999999998
    }
  },
  {
    "conv_id": "kbrd_redial_28946c66-4c5b-40b4-96a7-b2c99202aa42",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6375,
          "interestingness": 1.0
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.2999999999999998,
          "interestingness": 1.1874999999999998
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6312500000000001,
          "interestingness": 0.6375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.0125,
          "interestingness": 0.9999999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.23333333333333334
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.10000000000000002,
          "interestingness": 0.49062500000000003
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.7,
          "interestingness": 0.33333333333333337
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.09999999999999999,
          "interestingness": 0.12499999999999999
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.8187499999999999,
          "interestingness": 1.1812499999999997
        }
      },
      {
        "turn_ind": 19,
        "turn_level_pred": {
          "relevance": 1.0437500000000002,
          "interestingness": 0.675
        }
      },
      {
        "turn_ind": 21,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.46249999999999997
        }
      },
      {
        "turn_ind": 23,
        "turn_level_pred": {
          "relevance": 0.03125,
          "interestingness": 0.42500000000000004
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5062500000000001,
      "task_completion": 0.26116071428571425,
      "interest_arousal": 0.178125,
      "efficiency": 0.06339285714285714,
      "dialogue_overall": 1.4651785714285714
    }
  },
  {
    "conv_id": "kbrd_redial_27a7298f-4ca2-441a-83dc-011f5d1ed5ea",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5083333333333333,
          "interestingness": 0.38333333333333336
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.24999999999999997,
      "task_completion": 0.18750000000000006,
      "interest_arousal": 0.4833333333333334,
      "efficiency": 0.28333333333333344,
      "dialogue_overall": 1.6958333333333333
    }
  },
  {
    "conv_id": "chatgpt_redial_29791d4d-5364-42e9-aa7a-77bfbe7c5241",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.21666666666666667,
          "interestingness": 0.5666666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.5087499999999998,
          "interestingness": 0.6537499999999998
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.2182692307692307,
      "task_completion": 0.726923076923077,
      "interest_arousal": 0.7644230769230769,
      "efficiency": 0.5451923076923076,
      "dialogue_overall": 2.5913461538461537
    }
  },
  {
    "conv_id": "crbcrs_redial_29791d4d-5364-42e9-aa7a-77bfbe7c5241",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.15625,
          "interestingness": 0.325
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8625000000000002,
          "interestingness": 0.3625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.0625,
          "interestingness": 1.49375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.965,
          "interestingness": 1.035
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3791666666666667,
          "interestingness": 0.6125
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.12500000000000003,
          "interestingness": 0.6624999999999999
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.08124999999999999,
          "interestingness": 0.42500000000000004
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3786764705882353,
      "task_completion": 0.2801470588235294,
      "interest_arousal": 0.32941176470588235,
      "efficiency": 0.08088235294117647,
      "dialogue_overall": 1.3860294117647058
    }
  },
  {
    "conv_id": "kbrd_opendialkg_2c72ee94-03bb-4b81-8bda-d36617b89987",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6375,
          "interestingness": 0.9375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.18750000000000006,
          "interestingness": 0.49374999999999997
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.7425,
          "interestingness": 0.775
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.39305555555555555,
      "task_completion": 0.3666666666666666,
      "interest_arousal": 0.35972222222222233,
      "efficiency": 0.12638888888888886,
      "dialogue_overall": 1.3430555555555554
    }
  },
  {
    "conv_id": "kbrd_redial_2c72ee94-03bb-4b81-8bda-d36617b89987",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.44583333333333336,
          "interestingness": 0.6624999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.17916666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.8562500000000001,
          "interestingness": 1.1125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.08750000000000001,
          "interestingness": 0.51875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5125000000000001,
          "interestingness": 0.9875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.15454545454545454,
      "task_completion": 0.2102272727272727,
      "interest_arousal": 0.12840909090909092,
      "efficiency": 0.007954545454545455,
      "dialogue_overall": 1.3045454545454545
    }
  },
  {
    "conv_id": "unicrs_opendialkg_2e6d6a22-b6ab-438a-a183-91761d804b90",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.225,
          "interestingness": 1.04
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.2125,
          "interestingness": 0.8875000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.35000000000000003,
          "interestingness": 1.325
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.2374999999999998,
          "interestingness": 0.725
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.671875,
      "task_completion": 0.8203124999999999,
      "interest_arousal": 0.42500000000000004,
      "efficiency": 0.33593750000000006,
      "dialogue_overall": 2.0296875
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_28979d07-3f1c-44db-b669-df937a4353a1",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.21250000000000005
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.33333333333333337
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.3375,
          "interestingness": 0.19166666666666668
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.7625,
          "interestingness": 1.3749999999999998
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.21750000000000005,
      "task_completion": 0.73875,
      "interest_arousal": 0.11750000000000005,
      "efficiency": 0.035,
      "dialogue_overall": 1.1425
    }
  },
  {
    "conv_id": "unicrs_redial_2e6d6a22-b6ab-438a-a183-91761d804b90",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9375,
          "interestingness": 1.175
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7000000000000001,
          "interestingness": 0.9999999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.566666666666667,
          "interestingness": 1.1875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.225,
          "interestingness": 0.425
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.3375
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.2062499999999998,
          "interestingness": 1.35
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 1.0875,
          "interestingness": 1.025
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 1.0125,
          "interestingness": 1.6875000000000002
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 1.358333333333333,
          "interestingness": 1.0375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.9541666666666667,
      "task_completion": 0.8993055555555556,
      "interest_arousal": 0.6506944444444444,
      "efficiency": 0.2722222222222222,
      "dialogue_overall": 2.328472222222222
    }
  },
  {
    "conv_id": "kbrd_opendialkg_2eab6a3b-8027-4a96-866f-db6cefcc8721",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.28750000000000003,
          "interestingness": 0.41250000000000003
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.2281250000000001,
          "interestingness": 1.7531250000000003
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.1625,
          "interestingness": 0.17500000000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.06875,
          "interestingness": 0.403125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.30000000000000004,
          "interestingness": 0.9249999999999999
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.5,
          "interestingness": 1.23125
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.07500000000000001,
          "interestingness": 0.625
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.7125,
          "interestingness": 1.0062499999999999
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.15625,
          "interestingness": 0.259375
        }
      },
      {
        "turn_ind": 19,
        "turn_level_pred": {
          "relevance": 0.09375,
          "interestingness": 0.3375
        }
      },
      {
        "turn_ind": 21,
        "turn_level_pred": {
          "relevance": 0.09166666666666666,
          "interestingness": 0.0875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3541666666666667,
      "task_completion": 0.3958333333333333,
      "interest_arousal": 0.37916666666666654,
      "efficiency": 0.10601851851851851,
      "dialogue_overall": 1.210185185185185
    }
  },
  {
    "conv_id": "kbrd_redial_2eab6a3b-8027-4a96-866f-db6cefcc8721",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.05
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.018750000000000003,
          "interestingness": 0.31875000000000003
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.31875,
          "interestingness": 0.45
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.10833333333333332,
          "interestingness": 0.3458333333333333
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.4583333333333333,
          "interestingness": 0.44583333333333336
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.2
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.4750000000000001
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.5750000000000001
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.9791666666666665,
          "interestingness": 1.1374999999999997
        }
      },
      {
        "turn_ind": 19,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.05
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.09464285714285714,
      "task_completion": 0.07202380952380952,
      "interest_arousal": 0.08273809523809525,
      "efficiency": 0.0011904761904761906,
      "dialogue_overall": 0.8964285714285716
    }
  },
  {
    "conv_id": "kbrd_redial_2fb4b4d8-4bd3-4be2-ba1d-b1895546355d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.1,
          "interestingness": 0.075
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.51875,
          "interestingness": 0.81875
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.018750000000000003,
          "interestingness": 0.41250000000000003
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.42500000000000004
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.23333333333333336,
      "task_completion": 0.1791666666666667,
      "interest_arousal": 0.19861111111111115,
      "efficiency": 0.03333333333333333,
      "dialogue_overall": 1.1319444444444442
    }
  },
  {
    "conv_id": "unicrs_opendialkg_2fb4b4d8-4bd3-4be2-ba1d-b1895546355d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.8125,
          "interestingness": 0.1875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.35833333333333334,
          "interestingness": 0.8125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.3125000000000001,
          "interestingness": 0.3125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.22291666666666665,
      "task_completion": 0.1479166666666667,
      "interest_arousal": 0.3333333333333333,
      "efficiency": 0.01875,
      "dialogue_overall": 1.1333333333333333
    }
  },
  {
    "conv_id": "crbcrs_redial_34c7bc47-a027-44b8-89d1-d55ee201768e",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.4875000000000001,
          "interestingness": 1.15
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.14166666666666666,
          "interestingness": 0.5375000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.2812500000000001,
          "interestingness": 1.05625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.04583333333333334,
          "interestingness": 0.5791666666666666
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.255,
      "task_completion": 0.17250000000000004,
      "interest_arousal": 0.32625,
      "efficiency": 0.07750000000000001,
      "dialogue_overall": 1.54125
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_34d6d5e8-3eb7-4cf1-b7b6-631c9e794a4c",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.5041666666666662,
          "interestingness": 0.5416666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.1541666666666666,
          "interestingness": 1.579166666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.2862500000000001,
          "interestingness": 0.8912499999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.46874999999999994,
          "interestingness": 0.5
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.1678571428571427,
          "interestingness": 1.1285714285714286
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.0312499999999998,
          "interestingness": 0.9812500000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8009259259259259,
      "task_completion": 0.8527777777777776,
      "interest_arousal": 0.35277777777777775,
      "efficiency": 0.10555555555555554,
      "dialogue_overall": 2.2939814814814814
    }
  },
  {
    "conv_id": "chatgpt_redial_34d6d5e8-3eb7-4cf1-b7b6-631c9e794a4c",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9374999999999998,
          "interestingness": 0.6874999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6124999999999999,
          "interestingness": 1.1437499999999998
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.3849999999999998,
          "interestingness": 1.27875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {}
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.004166666666666667,
          "interestingness": 0.07916666666666666
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.3375,
          "interestingness": 0.475
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.2166666666666667,
          "interestingness": 0.4208333333333333
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.008333333333333333,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.3958333333333334,
          "interestingness": 0.9249999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.42666666666666675,
      "task_completion": 0.21916666666666665,
      "interest_arousal": 0.2416666666666667,
      "efficiency": 0.04666666666666667,
      "dialogue_overall": 1.3620833333333335
    }
  },
  {
    "conv_id": "kbrd_opendialkg_35b2e818-dc0b-48fc-b401-d36fa4ea892e",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.23750000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.41666666666666674,
          "interestingness": 0.99375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.09999999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.003125,
          "interestingness": 0.06250000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5125,
          "interestingness": 0.6874999999999999
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.2916666666666667,
          "interestingness": 0.6916666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.16319444444444448,
      "task_completion": 0.13333333333333333,
      "interest_arousal": 0.17083333333333334,
      "efficiency": 0.09791666666666665,
      "dialogue_overall": 0.9937499999999999
    }
  },
  {
    "conv_id": "kbrd_opendialkg_36f23e39-2b82-443c-8b9c-25d8a43b4fa6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.025
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.19375000000000003,
          "interestingness": 0.8125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.037500000000000006
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.0375
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.05416666666666667,
          "interestingness": 0.19583333333333333
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.18333333333333335,
          "interestingness": 0.6625
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.2125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.19416666666666668,
      "task_completion": 0.11666666666666668,
      "interest_arousal": 0.125,
      "efficiency": 0.016666666666666666,
      "dialogue_overall": 0.9924999999999999
    }
  },
  {
    "conv_id": "kbrd_redial_36f23e39-2b82-443c-8b9c-25d8a43b4fa6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0374999999999999,
          "interestingness": 1.1375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.875,
          "interestingness": 1.3062500000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.9833333333333332,
          "interestingness": 1.0041666666666667
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.2125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.47500000000000003,
      "task_completion": 0.575,
      "interest_arousal": 0.45178571428571435,
      "efficiency": 0.21964285714285717,
      "dialogue_overall": 1.9357142857142857
    }
  },
  {
    "conv_id": "barcor_opendialkg_3751f282-b255-4ddf-9faf-2f9895699783",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.17500000000000002,
          "interestingness": 0.46875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.08750000000000001,
          "interestingness": 0.4125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5,
          "interestingness": 0.5875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.11250000000000002,
          "interestingness": 0.35625
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.33333333333333337,
          "interestingness": 0.44166666666666676
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.13295454545454546,
      "task_completion": 0.10454545454545454,
      "interest_arousal": 0.14886363636363636,
      "efficiency": 0.006818181818181819,
      "dialogue_overall": 1.095454545454545
    }
  },
  {
    "conv_id": "crbcrs_redial_3751f282-b255-4ddf-9faf-2f9895699783",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.30625,
          "interestingness": 0.6687500000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.3999999999999997,
          "interestingness": 1.5458333333333334
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.020833333333333332,
          "interestingness": 0.32083333333333336
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.21250000000000002,
          "interestingness": 0.8937499999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.45416666666666666,
          "interestingness": 1.0125
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.08125,
          "interestingness": 0.6375000000000001
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.6166666666666666
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.40625,
          "interestingness": 1.44375
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.14375000000000004,
          "interestingness": 0.9687499999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2909090909090909,
      "task_completion": 0.2931818181818182,
      "interest_arousal": 0.34886363636363626,
      "efficiency": 0.03579545454545455,
      "dialogue_overall": 1.311931818181818
    }
  },
  {
    "conv_id": "barcor_opendialkg_375251c2-c528-4e87-b78b-da0ff5d6b405",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7875,
          "interestingness": 0.9750000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4625,
      "task_completion": 0.38750000000000007,
      "interest_arousal": 0.5125,
      "efficiency": 0.17500000000000002,
      "dialogue_overall": 1.1624999999999999
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_375251c2-c528-4e87-b78b-da0ff5d6b405",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5083333333333333,
          "interestingness": 0.3458333333333334
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.628125,
          "interestingness": 0.9864583333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5375,
          "interestingness": 1.1624999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.5875,
          "interestingness": 1.0
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.0312499999999998,
          "interestingness": 1.175
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.7083333333333334,
          "interestingness": 0.7333333333333334
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.15833333333333333,
          "interestingness": 0.4791666666666667
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.675,
          "interestingness": 0.6291666666666667
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.7666666666666666,
          "interestingness": 0.6124999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5689516129032258,
      "task_completion": 0.3846774193548387,
      "interest_arousal": 0.32096774193548383,
      "efficiency": 0.10685483870967741,
      "dialogue_overall": 1.7532258064516133
    }
  },
  {
    "conv_id": "unicrs_opendialkg_380a0c03-8837-4f45-a114-c504dfa2c6e6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.08125,
          "interestingness": 0.26875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.1,
          "interestingness": 0.24375000000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.09375000000000003,
          "interestingness": 0.0875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.03125,
      "task_completion": 0.058333333333333334,
      "interest_arousal": 0.04583333333333333,
      "efficiency": 0.0,
      "dialogue_overall": 0.7729166666666668
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_395ab128-2bb0-43ab-989c-93ee428dc023",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.625,
          "interestingness": 0.8916666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.14375000000000004,
          "interestingness": 1.2687499999999998
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.4612499999999997,
          "interestingness": 0.7924999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8406249999999998,
          "interestingness": 0.8187500000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.8375,
          "interestingness": 1.0
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.9363095238095239,
      "task_completion": 0.7464285714285716,
      "interest_arousal": 0.5815476190476191,
      "efficiency": 0.2880952380952381,
      "dialogue_overall": 2.2916666666666665
    }
  },
  {
    "conv_id": "chatgpt_redial_395ab128-2bb0-43ab-989c-93ee428dc023",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5583333333333333,
          "interestingness": 0.9166666666666666
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8125,
          "interestingness": 1.48125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.8550000000000001,
          "interestingness": 0.7674999999999998
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.9229166666666667,
          "interestingness": 1.1916666666666669
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.08750000000000001,
          "interestingness": 0.49999999999999994
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.6250000000000002,
          "interestingness": 0.6875
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 1.1362500000000002,
          "interestingness": 0.6775000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8914285714285713,
      "task_completion": 0.7078571428571429,
      "interest_arousal": 0.4267857142857142,
      "efficiency": 0.22964285714285712,
      "dialogue_overall": 2.1342857142857143
    }
  },
  {
    "conv_id": "chatgpt_redial_3b2ecfd2-47b9-4391-9ac5-28cb5991a383",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.18333333333333335,
          "interestingness": 0.6208333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.25000000000000006,
          "interestingness": 0.41250000000000003
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.3125000000000001,
          "interestingness": 0.1125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.10250000000000002,
      "task_completion": 0.0675,
      "interest_arousal": 0.09000000000000002,
      "efficiency": 0.005,
      "dialogue_overall": 0.9525
    }
  },
  {
    "conv_id": "crbcrs_redial_3d1fae40-ee5c-4956-97e7-efbc58a51671",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.625,
          "interestingness": 0.525
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.16250000000000003
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.008333333333333333,
          "interestingness": 0.25000000000000006
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.11250000000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.004166666666666667,
          "interestingness": 0.22083333333333335
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0035714285714285718,
          "interestingness": 0.32857142857142857
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.054166666666666655,
      "task_completion": 0.029861111111111113,
      "interest_arousal": 0.1111111111111111,
      "efficiency": 0.0,
      "dialogue_overall": 0.8652777777777778
    }
  },
  {
    "conv_id": "crbcrs_redial_418379b2-b787-4ef3-bdfc-9da59d125622",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.01875,
          "interestingness": 0.7625000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5083333333333334,
          "interestingness": 0.9916666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.3708333333333334,
          "interestingness": 0.9291666666666667
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.053125000000000006,
          "interestingness": 0.6781250000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.053125000000000006,
          "interestingness": 0.37812500000000004
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.1,
          "interestingness": 0.5125000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.25062500000000004,
      "task_completion": 0.26875000000000004,
      "interest_arousal": 0.40375000000000005,
      "efficiency": 0.07937500000000001,
      "dialogue_overall": 1.5312499999999998
    }
  },
  {
    "conv_id": "kbrd_opendialkg_469f24c4-c352-41a3-9a1e-24fa64d3edba",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.10000000000000002,
          "interestingness": 0.36874999999999997
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.18750000000000006,
          "interestingness": 0.6666666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.06875,
          "interestingness": 0.6312500000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.09999999999999999,
          "interestingness": 0.5125000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2390625,
      "task_completion": 0.2015625,
      "interest_arousal": 0.1796875,
      "efficiency": 0.07187500000000001,
      "dialogue_overall": 1.2093749999999999
    }
  },
  {
    "conv_id": "kbrd_opendialkg_380a0c03-8837-4f45-a114-c504dfa2c6e6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.08333333333333333,
          "interestingness": 0.3958333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.09166666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.025
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.075
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.05277777777777777,
      "task_completion": 0.030555555555555555,
      "interest_arousal": 0.02638888888888889,
      "efficiency": 0.001388888888888889,
      "dialogue_overall": 0.8208333333333334
    }
  },
  {
    "conv_id": "kbrd_redial_469f24c4-c352-41a3-9a1e-24fa64d3edba",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.45
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.38333333333333336,
          "interestingness": 0.1625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.04375,
          "interestingness": 0.26875000000000004
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.15833333333333333,
          "interestingness": 0.43333333333333335
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.9749999999999999,
          "interestingness": 0.9
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.24166666666666664,
          "interestingness": 0.7124999999999999
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.2
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.37734375,
      "task_completion": 0.47421874999999997,
      "interest_arousal": 0.24375,
      "efficiency": 0.08984375,
      "dialogue_overall": 1.4218749999999998
    }
  },
  {
    "conv_id": "kbrd_opendialkg_48dce97e-7fda-4288-8001-0ce07d2a08cb",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.25,
          "interestingness": 0.46875000000000006
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.32500000000000007,
          "interestingness": 0.6666666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.037500000000000006
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2333333333333333,
      "task_completion": 0.31041666666666673,
      "interest_arousal": 0.3583333333333333,
      "efficiency": 0.175,
      "dialogue_overall": 1.2291666666666665
    }
  },
  {
    "conv_id": "kbrd_redial_48dce97e-7fda-4288-8001-0ce07d2a08cb",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.2750000000000001,
          "interestingness": 0.475
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.22500000000000003,
          "interestingness": 0.7124999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.20833333333333334,
          "interestingness": 0.6041666666666667
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.1291666666666667,
          "interestingness": 0.8083333333333333
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.3375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1611111111111111,
      "task_completion": 0.23750000000000002,
      "interest_arousal": 0.21805555555555553,
      "efficiency": 0.03194444444444444,
      "dialogue_overall": 1.0902777777777777
    }
  },
  {
    "conv_id": "barcor_opendialkg_4a0ccb43-cc54-45d0-8ec1-dd659a9f3a16",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.05625,
          "interestingness": 0.63125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.049999999999999996,
          "interestingness": 0.09583333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05416666666666666,
          "interestingness": 0.7125000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.03125,
          "interestingness": 0.525
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.11249999999999999
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.23750000000000004,
          "interestingness": 0.4000000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.18942307692307692,
      "task_completion": 0.16634615384615387,
      "interest_arousal": 0.17500000000000004,
      "efficiency": 0.007692307692307693,
      "dialogue_overall": 1.2413461538461537
    }
  },
  {
    "conv_id": "unicrs_opendialkg_4a0ccb43-cc54-45d0-8ec1-dd659a9f3a16",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {}
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.34375000000000006,
          "interestingness": 0.41875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2375,
      "task_completion": 0.0625,
      "interest_arousal": 0.15625,
      "efficiency": 0.00625,
      "dialogue_overall": 1.2062500000000003
    }
  },
  {
    "conv_id": "barcor_opendialkg_4bf90840-2741-496d-a017-6c34c3ee7a21",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.8624999999999999,
          "interestingness": 0.725
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.09583333333333333,
          "interestingness": 0.675
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6,
          "interestingness": 0.9875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.20535714285714285,
      "task_completion": 0.18571428571428572,
      "interest_arousal": 0.2821428571428571,
      "efficiency": 0.08214285714285716,
      "dialogue_overall": 1.3946428571428573
    }
  },
  {
    "conv_id": "unicrs_redial_4bd39cf8-77c6-4f0e-bbb6-efed0dacd23c",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3750000000000001,
          "interestingness": 0.6425000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.11249999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5208333333333333,
          "interestingness": 0.3625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.16250000000000006,
      "task_completion": 0.23472222222222225,
      "interest_arousal": 0.1652777777777778,
      "efficiency": 0.043055555555555555,
      "dialogue_overall": 1.2305555555555554
    }
  },
  {
    "conv_id": "barcor_redial_4bf90840-2741-496d-a017-6c34c3ee7a21",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6999999999999998,
          "interestingness": 0.609375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.3041666666666667,
          "interestingness": 0.8541666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.0999999999999999,
          "interestingness": 0.9875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3421875000000001,
      "task_completion": 0.290625,
      "interest_arousal": 0.4296875000000001,
      "efficiency": 0.09687500000000002,
      "dialogue_overall": 1.7609375000000003
    }
  },
  {
    "conv_id": "unicrs_opendialkg_4c51bc49-ed5e-456f-9ff4-6283c48ee43f",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.93125,
          "interestingness": 0.6937500000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6375000000000001,
      "task_completion": 0.15000000000000002,
      "interest_arousal": 0.3375,
      "efficiency": 0.06249999999999999,
      "dialogue_overall": 1.4250000000000003
    }
  },
  {
    "conv_id": "barcor_opendialkg_4dafa3ab-554f-4fe4-9f10-ca6bd5a0e562",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.018750000000000003,
          "interestingness": 0.13750000000000004
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.0,
      "task_completion": 0.0,
      "interest_arousal": 0.14375000000000004,
      "efficiency": 0.0,
      "dialogue_overall": 0.65625
    }
  },
  {
    "conv_id": "unicrs_opendialkg_4dafa3ab-554f-4fe4-9f10-ca6bd5a0e562",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2125,
          "interestingness": 0.3
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.2333333333333334,
      "task_completion": 0.8125,
      "interest_arousal": 0.05416666666666666,
      "efficiency": 0.4416666666666667,
      "dialogue_overall": 2.1458333333333335
    }
  },
  {
    "conv_id": "crbcrs_redial_500b7708-2674-464c-a21b-06c7cb219618",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.1208333333333331,
          "interestingness": 1.2374999999999996
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.25
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6656249999999999,
          "interestingness": 0.934375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4078125000000001,
      "task_completion": 0.1703125,
      "interest_arousal": 0.35937499999999994,
      "efficiency": 0.10468750000000002,
      "dialogue_overall": 1.6921875
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_4ef780c9-3dca-44dc-92e4-cc43eb77f686",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {}
      }
    ],
    "dial_level_pred": {}
  },
  {
    "conv_id": "unicrs_opendialkg_500b7708-2674-464c-a21b-06c7cb219618",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5,
          "interestingness": 0.25625000000000003
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7374999999999999,
          "interestingness": 0.6312499999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.37187500000000007,
      "task_completion": 0.19374999999999998,
      "interest_arousal": 0.425,
      "efficiency": 0.046875,
      "dialogue_overall": 1.2656250000000002
    }
  },
  {
    "conv_id": "barcor_opendialkg_502f08fd-2970-4d8a-84b5-1d410999e309",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.8250000000000001,
          "interestingness": 0.7075
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9291666666666666,
          "interestingness": 0.65
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.7156250000000001,
      "task_completion": 0.47343750000000007,
      "interest_arousal": 0.6109375000000001,
      "efficiency": 0.45156250000000003,
      "dialogue_overall": 2.059375
    }
  },
  {
    "conv_id": "barcor_redial_502f08fd-2970-4d8a-84b5-1d410999e309",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2374999999999996,
          "interestingness": 1.1624999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9125,
          "interestingness": 1.1500000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.9208333333333334,
          "interestingness": 0.7749999999999998
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.7374999999999999,
          "interestingness": 0.45000000000000007
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8125,
      "task_completion": 0.9083333333333333,
      "interest_arousal": 0.5229166666666667,
      "efficiency": 0.24166666666666667,
      "dialogue_overall": 1.9604166666666667
    }
  },
  {
    "conv_id": "barcor_opendialkg_5382d294-e84c-4cf5-9b40-3f36aabeaa7b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.7437500000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7625000000000001,
          "interestingness": 1.0999999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.14166666666666666,
          "interestingness": 0.2666666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.17857142857142855,
      "task_completion": 0.13750000000000004,
      "interest_arousal": 0.23750000000000002,
      "efficiency": 0.05892857142857144,
      "dialogue_overall": 1.1535714285714285
    }
  },
  {
    "conv_id": "crbcrs_redial_4e151e5e-c51a-43f7-93a4-159e9ebfcc7f",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.4666666666666667,
          "interestingness": 0.6083333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.20416666666666666,
      "task_completion": 0.10416666666666666,
      "interest_arousal": 0.24166666666666667,
      "efficiency": 0.024999999999999998,
      "dialogue_overall": 1.1875
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_5382d294-e84c-4cf5-9b40-3f36aabeaa7b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2958333333333334,
          "interestingness": 0.85
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.79375,
          "interestingness": 1.0062499999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.45625000000000004,
          "interestingness": 0.6775
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.9600000000000001,
          "interestingness": 0.8537499999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.6187500000000001,
          "interestingness": 1.8987500000000004
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.084375,
          "interestingness": 0.346875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.9262820512820514,
      "task_completion": 1.042628205128205,
      "interest_arousal": 0.8250000000000002,
      "efficiency": 0.3092948717948718,
      "dialogue_overall": 2.5916666666666663
    }
  },
  {
    "conv_id": "kbrd_opendialkg_53deb45d-6301-43e4-b119-cf25c2e9cd14",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.15000000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.2583333333333334,
          "interestingness": 0.8583333333333334
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.01875,
          "interestingness": 0.103125
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.10833333333333332,
          "interestingness": 0.39583333333333337
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.09910714285714287,
      "task_completion": 0.05714285714285714,
      "interest_arousal": 0.06785714285714284,
      "efficiency": 0.005357142857142857,
      "dialogue_overall": 0.6883928571428573
    }
  },
  {
    "conv_id": "kbrd_opendialkg_56759a2a-e597-41ec-85d5-e15bf9899ebf",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.2
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.259375,
          "interestingness": 0.9874999999999998
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.22499999999999998
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.1375,
          "interestingness": 0.5750000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.05833333333333333,
          "interestingness": 0.17500000000000002
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.23124999999999998,
          "interestingness": 0.640625
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.175,
          "interestingness": 0.9999999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.22109375,
      "task_completion": 0.1609375,
      "interest_arousal": 0.19296875000000005,
      "efficiency": 0.0171875,
      "dialogue_overall": 0.9921875000000001
    }
  },
  {
    "conv_id": "kbrd_redial_56759a2a-e597-41ec-85d5-e15bf9899ebf",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.8625,
          "interestingness": 0.9125000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.25,
          "interestingness": 0.9874999999999998
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.07812500000000003,
          "interestingness": 0.09687500000000003
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.11249999999999999,
          "interestingness": 0.45416666666666666
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.18749999999999997,
          "interestingness": 0.65625
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.35833333333333334,
          "interestingness": 0.7583333333333333
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.043750000000000004,
          "interestingness": 0.45625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5073529411764707,
      "task_completion": 0.34264705882352947,
      "interest_arousal": 0.3058823529411765,
      "efficiency": 0.11029411764705882,
      "dialogue_overall": 1.5375
    }
  },
  {
    "conv_id": "unicrs_opendialkg_57ac2c8f-75fa-49ad-be36-574004b0c47a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7625,
          "interestingness": 1.2249999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6875,
          "interestingness": 0.9
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6625,
          "interestingness": 0.71875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.14583333333333337,
          "interestingness": 0.24583333333333332
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.41250000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.23333333333333325,
      "task_completion": 0.18472222222222223,
      "interest_arousal": 0.18333333333333335,
      "efficiency": 0.022222222222222223,
      "dialogue_overall": 1.2305555555555554
    }
  },
  {
    "conv_id": "unicrs_redial_57ac2c8f-75fa-49ad-be36-574004b0c47a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7916666666666667,
          "interestingness": 0.9083333333333332
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 1.1125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.11249999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.23750000000000004
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {}
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2833333333333334,
      "task_completion": 0.24375,
      "interest_arousal": 0.31666666666666665,
      "efficiency": 0.14583333333333334,
      "dialogue_overall": 1.38125
    }
  },
  {
    "conv_id": "barcor_opendialkg_58870fd6-f8b4-47f5-ab1a-693d3880e483",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.25416666666666665,
          "interestingness": 0.425
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.25,
          "interestingness": 0.24999999999999994
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.03125,
          "interestingness": 0.43125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.004166666666666667,
          "interestingness": 0.25833333333333336
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.20000000000000007,
          "interestingness": 0.48125000000000007
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.6187500000000001,
          "interestingness": 1.79375
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.3
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.037500000000000006
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.16250000000000003,
          "interestingness": 0.3375000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.34513888888888883,
      "task_completion": 0.3361111111111111,
      "interest_arousal": 0.3173611111111111,
      "efficiency": 0.05763888888888888,
      "dialogue_overall": 1.1472222222222221
    }
  },
  {
    "conv_id": "barcor_redial_58870fd6-f8b4-47f5-ab1a-693d3880e483",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.86875,
          "interestingness": 1.2312500000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7375,
          "interestingness": 0.9333333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.9250000000000002,
          "interestingness": 1.425
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.16875,
          "interestingness": 0.17500000000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.41875000000000007,
          "interestingness": 0.8437500000000001
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.5875,
          "interestingness": 0.5875
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.5499999999999999,
          "interestingness": 0.8625000000000002
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.09999999999999999
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.1
        }
      },
      {
        "turn_ind": 19,
        "turn_level_pred": {
          "relevance": 0.2875,
          "interestingness": 0.9875000000000002
        }
      },
      {
        "turn_ind": 21,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.475
        }
      },
      {
        "turn_ind": 23,
        "turn_level_pred": {
          "relevance": 1.2875,
          "interestingness": 0.575
        }
      },
      {
        "turn_ind": 25,
        "turn_level_pred": {
          "relevance": 0.015625,
          "interestingness": 0.265625
        }
      },
      {
        "turn_ind": 27,
        "turn_level_pred": {
          "relevance": 0.8374999999999999,
          "interestingness": 0.9624999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6765625,
      "task_completion": 0.6942708333333332,
      "interest_arousal": 0.45,
      "efficiency": 0.17656249999999998,
      "dialogue_overall": 1.8161458333333333
    }
  },
  {
    "conv_id": "kbrd_opendialkg_5a8bc61d-6c3e-4786-a0cd-6c5c72b678f7",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.3
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8875,
          "interestingness": 1.1937499999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.07500000000000001,
          "interestingness": 0.1875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.014583333333333332,
          "interestingness": 0.14375
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.17500000000000002,
          "interestingness": 0.16250000000000003
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.33437500000000003,
          "interestingness": 0.45937500000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.21875000000000003,
      "task_completion": 0.19791666666666666,
      "interest_arousal": 0.21319444444444446,
      "efficiency": 0.05555555555555556,
      "dialogue_overall": 1.0277777777777777
    }
  },
  {
    "conv_id": "kbrd_redial_5a8bc61d-6c3e-4786-a0cd-6c5c72b678f7",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.2625,
          "interestingness": 0.7625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.03333333333333333,
          "interestingness": 0.22500000000000003
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.2375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.25,
          "interestingness": 0.5812499999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.1208333333333333,
          "interestingness": 1.1708333333333332
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.35000000000000003
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.35
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.21875000000000006
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.19196428571428573,
      "task_completion": 0.24107142857142855,
      "interest_arousal": 0.1955357142857143,
      "efficiency": 0.03839285714285715,
      "dialogue_overall": 1.19375
    }
  },
  {
    "conv_id": "kbrd_redial_5e6389b7-0dad-4e0e-946b-8ba2ea5a5c8d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.07500000000000001,
          "interestingness": 0.53125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5000000000000001,
          "interestingness": 1.325
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.058333333333333334,
          "interestingness": 0.4708333333333334
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.058333333333333334,
          "interestingness": 0.33333333333333337
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.19250000000000003,
      "task_completion": 0.15375000000000003,
      "interest_arousal": 0.22375000000000003,
      "efficiency": 0.017499999999999998,
      "dialogue_overall": 1.0875
    }
  },
  {
    "conv_id": "unicrs_redial_5e6389b7-0dad-4e0e-946b-8ba2ea5a5c8d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.31250000000000006
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.3416666666666667,
          "interestingness": 0.5625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.1375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.15250000000000005,
      "task_completion": 0.17750000000000002,
      "interest_arousal": 0.0825,
      "efficiency": 0.01,
      "dialogue_overall": 0.9924999999999999
    }
  },
  {
    "conv_id": "barcor_opendialkg_5f8abdf2-bd9a-429c-91ae-1c4dc382c70d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.43750000000000006
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.17500000000000002,
      "task_completion": 0.05,
      "interest_arousal": 0.275,
      "efficiency": 0.05,
      "dialogue_overall": 1.2750000000000001
    }
  },
  {
    "conv_id": "crbcrs_redial_5fa354b3-3838-4b8e-9b4e-dd57012d5291",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.12499999999999999,
          "interestingness": 0.6041666666666669
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.175,
      "task_completion": 0.07916666666666666,
      "interest_arousal": 0.18333333333333335,
      "efficiency": 0.008333333333333333,
      "dialogue_overall": 1.1708333333333334
    }
  },
  {
    "conv_id": "chatgpt_redial_5fa354b3-3838-4b8e-9b4e-dd57012d5291",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2249999999999999,
          "interestingness": 0.5475
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8200000000000001,
      "task_completion": 0.32000000000000006,
      "interest_arousal": 0.585,
      "efficiency": 0.6074999999999999,
      "dialogue_overall": 2.35
    }
  },
  {
    "conv_id": "barcor_redial_5f8abdf2-bd9a-429c-91ae-1c4dc382c70d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.675,
          "interestingness": 1.0125000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9874999999999999,
          "interestingness": 0.6041666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.5874999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8250000000000002,
      "task_completion": 0.5474999999999999,
      "interest_arousal": 0.5900000000000001,
      "efficiency": 0.445,
      "dialogue_overall": 2.1100000000000003
    }
  },
  {
    "conv_id": "barcor_opendialkg_65061ac6-d961-4d7b-a7f6-b21937ce0d1a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9875,
          "interestingness": 1.19375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.1125,
          "interestingness": 0.6375000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.13749999999999998
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.015625,
          "interestingness": 0.178125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.037500000000000006
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.15000000000000002
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.18750000000000003,
          "interestingness": 0.6375000000000001
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.1375,
          "interestingness": 0.825
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.06250000000000001,
          "interestingness": 0.28125000000000006
        }
      },
      {
        "turn_ind": 19,
        "turn_level_pred": {
          "relevance": 0.16875,
          "interestingness": 0.58125
        }
      },
      {
        "turn_ind": 21,
        "turn_level_pred": {
          "relevance": 0.2125,
          "interestingness": 0.8312499999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.24062500000000006,
      "task_completion": 0.12500000000000003,
      "interest_arousal": 0.20312499999999994,
      "efficiency": 0.0125,
      "dialogue_overall": 1.055625
    }
  },
  {
    "conv_id": "kbrd_redial_65061ac6-d961-4d7b-a7f6-b21937ce0d1a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.05,
          "interestingness": 1.2125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.21250000000000005,
          "interestingness": 0.1791666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.175
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.3625
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.47500000000000003,
          "interestingness": 0.9299999999999999
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.18750000000000003
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.15000000000000002
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.12499999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3375,
      "task_completion": 0.27058823529411763,
      "interest_arousal": 0.19044117647058822,
      "efficiency": 0.1014705882352941,
      "dialogue_overall": 1.2279411764705879
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_67c07d8a-1ef9-4f98-963b-89b911500a25",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6541666666666667,
          "interestingness": 0.6291666666666668
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.1049999999999998,
          "interestingness": 0.3975000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.8625000000000002,
          "interestingness": 0.9374999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.4725000000000001,
          "interestingness": 0.7925
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.9545000000000001,
      "task_completion": 0.6815000000000001,
      "interest_arousal": 0.5640000000000001,
      "efficiency": 0.25849999999999995,
      "dialogue_overall": 2.209
    }
  },
  {
    "conv_id": "unicrs_opendialkg_656b0046-ff99-4c18-89de-b1a5e97df188",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.21250000000000005
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.38125,
          "interestingness": 0.18125000000000002
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.028124999999999997,
      "task_completion": 0.065625,
      "interest_arousal": 0.10937500000000003,
      "efficiency": 0.0,
      "dialogue_overall": 0.7718750000000001
    }
  },
  {
    "conv_id": "kbrd_opendialkg_67dbe46e-ef61-4f45-a569-5cbab9b593f6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.23750000000000002
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.07500000000000001,
      "task_completion": 0.05,
      "interest_arousal": 0.125,
      "efficiency": 0.0,
      "dialogue_overall": 0.925
    }
  },
  {
    "conv_id": "kbrd_redial_67dbe46e-ef61-4f45-a569-5cbab9b593f6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.21666666666666673,
          "interestingness": 0.2416666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.17500000000000002,
          "interestingness": 0.4875000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.09999999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.4
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.23333333333333336,
      "task_completion": 0.16875000000000004,
      "interest_arousal": 0.21875000000000003,
      "efficiency": 0.05,
      "dialogue_overall": 1.2083333333333333
    }
  },
  {
    "conv_id": "barcor_opendialkg_6b48e981-5be3-4c58-a480-6efc4ea96ab6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3218750000000001,
          "interestingness": 0.8624999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.24583333333333335,
          "interestingness": 0.5041666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2392857142857143,
      "task_completion": 0.08214285714285713,
      "interest_arousal": 0.3696428571428571,
      "efficiency": 0.028571428571428574,
      "dialogue_overall": 1.3607142857142855
    }
  },
  {
    "conv_id": "barcor_redial_6b48e981-5be3-4c58-a480-6efc4ea96ab6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9125,
          "interestingness": 1.1125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7500000000000001,
          "interestingness": 0.975
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.42916666666666675,
          "interestingness": 0.49166666666666675
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8275000000000001,
      "task_completion": 0.4450000000000001,
      "interest_arousal": 0.47,
      "efficiency": 0.14500000000000002,
      "dialogue_overall": 1.8975000000000002
    }
  },
  {
    "conv_id": "barcor_opendialkg_6c892388-9f10-410e-aa6a-6d4774abf6a8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3166666666666667,
          "interestingness": 0.8833333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.20625000000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.04375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.3687500000000001,
          "interestingness": 0.3875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1736111111111111,
      "task_completion": 0.07916666666666668,
      "interest_arousal": 0.1736111111111111,
      "efficiency": 0.008333333333333333,
      "dialogue_overall": 0.9888888888888888
    }
  },
  {
    "conv_id": "barcor_redial_6c892388-9f10-410e-aa6a-6d4774abf6a8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0499999999999998,
          "interestingness": 1.3124999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.475
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.1749999999999998,
          "interestingness": 1.4625000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.14375,
          "interestingness": 0.35625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.33749999999999997,
      "task_completion": 0.6535714285714286,
      "interest_arousal": 0.3803571428571429,
      "efficiency": 0.1660714285714286,
      "dialogue_overall": 2.0267857142857144
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_6e85effe-3902-4094-a6ec-046c4c21032b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.8625,
          "interestingness": 0.9500000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7625,
          "interestingness": 1.55625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.146875,
          "interestingness": 1.0062499999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.5987500000000001,
          "interestingness": 1.06375
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6224999999999999,
          "interestingness": 0.6012500000000002
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.8374999999999999,
          "interestingness": 0.7541666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.701171875,
      "task_completion": 0.3957031250000001,
      "interest_arousal": 0.48125,
      "efficiency": 0.140234375,
      "dialogue_overall": 2.1757812499999996
    }
  },
  {
    "conv_id": "crbcrs_redial_6e85effe-3902-4094-a6ec-046c4c21032b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.8833333333333333,
          "interestingness": 1.1083333333333332
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.16875,
          "interestingness": 0.85
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4175000000000001,
      "task_completion": 0.28250000000000003,
      "interest_arousal": 0.43750000000000006,
      "efficiency": 0.2775,
      "dialogue_overall": 2.0750000000000006
    }
  },
  {
    "conv_id": "kbrd_redial_6f49bca4-a372-4e26-be9c-8e086fa140f4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6624999999999999,
          "interestingness": 1.1124999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9375,
          "interestingness": 0.7
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.9624999999999999,
          "interestingness": 1.140625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.4125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.049999999999999996,
          "interestingness": 0.5
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.7537499999999999,
      "task_completion": 0.6050000000000002,
      "interest_arousal": 0.45250000000000007,
      "efficiency": 0.2675,
      "dialogue_overall": 2.0162500000000003
    }
  },
  {
    "conv_id": "unicrs_redial_6f49bca4-a372-4e26-be9c-8e086fa140f4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.1958333333333334,
          "interestingness": 0.19583333333333336
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.20000000000000004
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.04375,
          "interestingness": 0.5625
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.48125000000000007,
          "interestingness": 0.44375000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.18472222222222223,
      "task_completion": 0.20833333333333331,
      "interest_arousal": 0.16388888888888892,
      "efficiency": 0.027777777777777776,
      "dialogue_overall": 1.1777777777777776
    }
  },
  {
    "conv_id": "crbcrs_redial_702d1ce0-3085-4169-8e67-8e5fcc65f0c6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.008333333333333333,
          "interestingness": 0.17916666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.029166666666666664,
      "task_completion": 0.03333333333333333,
      "interest_arousal": 0.11249999999999999,
      "efficiency": 0.0,
      "dialogue_overall": 0.7833333333333334
    }
  },
  {
    "conv_id": "unicrs_redial_70817c1d-6eb2-4a49-a83b-3710261d2dad",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.38035714285714284,
          "interestingness": 0.6125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.22500000000000003
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.7000000000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.37500000000000006,
          "interestingness": 0.7375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1675,
      "task_completion": 0.13750000000000004,
      "interest_arousal": 0.15625000000000003,
      "efficiency": 0.07250000000000001,
      "dialogue_overall": 1.2987499999999998
    }
  },
  {
    "conv_id": "kbrd_redial_70817c1d-6eb2-4a49-a83b-3710261d2dad",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.15833333333333333,
          "interestingness": 0.33749999999999997
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.1875,
          "interestingness": 0.6375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.22250000000000006,
      "task_completion": 0.15500000000000003,
      "interest_arousal": 0.4450000000000001,
      "efficiency": 0.10250000000000002,
      "dialogue_overall": 1.4325
    }
  },
  {
    "conv_id": "kbrd_opendialkg_75697d53-c159-49a8-ac4c-e1e45b82d5d3",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.11249999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.3583333333333334,
          "interestingness": 0.8916666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.037500000000000006
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.525
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.049999999999999996,
          "interestingness": 0.29062499999999997
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.08750000000000002,
          "interestingness": 0.5275000000000001
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.008333333333333333,
          "interestingness": 0.3041666666666667
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.11875000000000001,
          "interestingness": 0.3937500000000001
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.10833333333333332,
          "interestingness": 1.1208333333333331
        }
      },
      {
        "turn_ind": 19,
        "turn_level_pred": {
          "relevance": 0.1375,
          "interestingness": 0.2875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.18200000000000005,
      "task_completion": 0.239,
      "interest_arousal": 0.22000000000000006,
      "efficiency": 0.034,
      "dialogue_overall": 1.0710000000000002
    }
  },
  {
    "conv_id": "kbrd_redial_75697d53-c159-49a8-ac4c-e1e45b82d5d3",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2000000000000002,
          "interestingness": 1.24375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.275,
          "interestingness": 0.6499999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.7718750000000001,
          "interestingness": 1.23125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.125,
          "interestingness": 0.55625
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.35000000000000003
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.23750000000000004
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4288461538461539,
      "task_completion": 0.3096153846153847,
      "interest_arousal": 0.2798076923076923,
      "efficiency": 0.1432692307692308,
      "dialogue_overall": 1.5932692307692309
    }
  },
  {
    "conv_id": "kbrd_redial_786c0a8c-0968-4c8b-b4cf-d243d9f28dbf",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0375,
          "interestingness": 0.3666666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.28750000000000003
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.15,
          "interestingness": 0.8375000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.5625000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.12083333333333338,
      "task_completion": 0.27708333333333335,
      "interest_arousal": 0.16041666666666668,
      "efficiency": 0.027083333333333334,
      "dialogue_overall": 1.2499999999999998
    }
  },
  {
    "conv_id": "barcor_opendialkg_7899ee10-fbf7-48d6-bd15-781a1d51df4d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0925,
          "interestingness": 0.7100000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.925,
          "interestingness": 0.7499999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.01875,
          "interestingness": 0.071875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.043750000000000004,
          "interestingness": 0.23750000000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3550000000000001,
          "interestingness": 0.5075
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.11249999999999999,
          "interestingness": 0.8125000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2225,
      "task_completion": 0.10250000000000001,
      "interest_arousal": 0.2325,
      "efficiency": 0.013125,
      "dialogue_overall": 1.080625
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_7899ee10-fbf7-48d6-bd15-781a1d51df4d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.35000000000000003
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.69875,
          "interestingness": 0.8825000000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.9312500000000001,
          "interestingness": 0.89125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8291666666666668,
          "interestingness": 1.2833333333333334
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.355,
          "interestingness": 0.46625
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.30000000000000004,
          "interestingness": 0.6624999999999999
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 1.3583333333333336,
          "interestingness": 1.0916666666666666
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.3958333333333333,
          "interestingness": 0.4666666666666668
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.06249999999999999,
          "interestingness": 0.11249999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6892156862745098,
      "task_completion": 0.44583333333333336,
      "interest_arousal": 0.5377450980392158,
      "efficiency": 0.19803921568627453,
      "dialogue_overall": 2.0938725490196077
    }
  },
  {
    "conv_id": "barcor_redial_7ac99f08-ad3b-4dc8-b292-701b59fd4a05",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0999999999999999,
          "interestingness": 1.1874999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.625,
          "interestingness": 1.75
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5499999999999999,
          "interestingness": 0.6416666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.1174999999999997,
      "task_completion": 0.7549999999999999,
      "interest_arousal": 0.86,
      "efficiency": 0.5125,
      "dialogue_overall": 2.6000000000000005
    }
  },
  {
    "conv_id": "unicrs_redial_7ac99f08-ad3b-4dc8-b292-701b59fd4a05",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.4666666666666666,
          "interestingness": 0.7333333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.18125000000000002,
          "interestingness": 0.53125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.18000000000000002,
      "task_completion": 0.3475000000000001,
      "interest_arousal": 0.265,
      "efficiency": 0.10750000000000003,
      "dialogue_overall": 1.555
    }
  },
  {
    "conv_id": "crbcrs_redial_7c3b8cea-4d7a-4bb9-b889-73400b9131bc",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.1687500000000002,
          "interestingness": 1.28125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.004166666666666667,
          "interestingness": 0.22916666666666669
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.44375,
          "interestingness": 0.7968750000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.3375,
          "interestingness": 1.2624999999999997
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.39375,
      "task_completion": 0.39124999999999993,
      "interest_arousal": 0.32,
      "efficiency": 0.14500000000000002,
      "dialogue_overall": 1.5575
    }
  },
  {
    "conv_id": "crbcrs_redial_7fb22883-8295-4424-90ca-26a6791226fc",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.8750000000000001,
          "interestingness": 0.42083333333333334
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.39375,
          "interestingness": 0.9
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.525
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.06875,
          "interestingness": 0.8281249999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2575,
      "task_completion": 0.15375,
      "interest_arousal": 0.3125,
      "efficiency": 0.021249999999999998,
      "dialogue_overall": 1.1475
    }
  },
  {
    "conv_id": "unicrs_redial_7fb22883-8295-4424-90ca-26a6791226fc",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.5375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4833333333333333,
          "interestingness": 1.0791666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.4625000000000001,
          "interestingness": 1.4875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.45,
          "interestingness": 1.25
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.30416666666666664,
      "task_completion": 0.3125,
      "interest_arousal": 0.32708333333333334,
      "efficiency": 0.03333333333333333,
      "dialogue_overall": 1.3520833333333337
    }
  },
  {
    "conv_id": "chatgpt_redial_80c6279a-77ac-41ec-8386-6201c4bffdef",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7300000000000001,
          "interestingness": 0.9674999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.3035714285714284,
          "interestingness": 0.9660714285714285
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5464285714285715,
          "interestingness": 0.5017857142857143
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.3196428571428572,
          "interestingness": 0.19107142857142856
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.60625,
      "task_completion": 0.4673076923076923,
      "interest_arousal": 0.3504807692307692,
      "efficiency": 0.2096153846153846,
      "dialogue_overall": 1.9750000000000003
    }
  },
  {
    "conv_id": "unicrs_opendialkg_830c5256-f215-4df2-b0f1-0b65c89c5e4e",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.53125,
          "interestingness": 0.33125000000000004
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5625000000000001,
          "interestingness": 0.6
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6625,
          "interestingness": 0.6812500000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.15312500000000004,
          "interestingness": 0.4656250000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.20000000000000004,
          "interestingness": 0.21875
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.1375,
          "interestingness": 0.33125
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.34375,
          "interestingness": 0.18125
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.8500000000000001,
          "interestingness": 0.6875
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.27083333333333337,
          "interestingness": 0.39999999999999997
        }
      },
      {
        "turn_ind": 19,
        "turn_level_pred": {
          "relevance": 0.25,
          "interestingness": 0.38125000000000003
        }
      },
      {
        "turn_ind": 21,
        "turn_level_pred": {
          "relevance": 0.049999999999999996,
          "interestingness": 0.1875
        }
      },
      {
        "turn_ind": 23,
        "turn_level_pred": {
          "relevance": 0.28125,
          "interestingness": 0.7999999999999999
        }
      },
      {
        "turn_ind": 25,
        "turn_level_pred": {
          "relevance": 0.11875000000000002,
          "interestingness": 0.3812500000000001
        }
      },
      {
        "turn_ind": 27,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.0125
        }
      },
      {
        "turn_ind": 29,
        "turn_level_pred": {
          "relevance": 0.3458333333333333,
          "interestingness": 0.6833333333333333
        }
      },
      {
        "turn_ind": 31,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.16875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.19734848484848483,
      "task_completion": 0.1477272727272727,
      "interest_arousal": 0.1325757575757576,
      "efficiency": 0.00946969696969697,
      "dialogue_overall": 0.9893939393939393
    }
  },
  {
    "conv_id": "kbrd_opendialkg_8460fdbb-3dee-4b19-aa3e-057b40b4b9a6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.05
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5437500000000001,
          "interestingness": 0.28750000000000003
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.16250000000000003,
          "interestingness": 0.05
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.25937499999999997,
      "task_completion": 0.19062500000000002,
      "interest_arousal": 0.153125,
      "efficiency": 0.0125,
      "dialogue_overall": 1.0250000000000004
    }
  },
  {
    "conv_id": "kbrd_redial_8460fdbb-3dee-4b19-aa3e-057b40b4b9a6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6875000000000001,
          "interestingness": 1.2
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.1125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.725,
          "interestingness": 0.425
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.703125,
          "interestingness": 0.525
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.7875,
          "interestingness": 0.2375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4875000000000001,
      "task_completion": 0.6234374999999999,
      "interest_arousal": 0.371875,
      "efficiency": 0.11250000000000002,
      "dialogue_overall": 1.775
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_86733c0e-cf5f-49f9-8193-f55335b6e2cf",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.8750000000000001,
          "interestingness": 0.6708333333333334
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.22500000000000003,
          "interestingness": 1.0687499999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6687500000000001,
          "interestingness": 0.5325
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.35000000000000003,
          "interestingness": 1.45
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.49999999999999994,
          "interestingness": 0.475
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.524264705882353,
      "task_completion": 0.28308823529411764,
      "interest_arousal": 0.29705882352941176,
      "efficiency": 0.03529411764705882,
      "dialogue_overall": 1.4066176470588236
    }
  },
  {
    "conv_id": "barcor_redial_86c042fe-566a-4ec1-bfd9-ed299734038b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9874999999999999,
          "interestingness": 1.1625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6312500000000001,
          "interestingness": 0.9125000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.14583333333333331,
          "interestingness": 0.275
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.4375,
          "interestingness": 0.1625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.39218749999999997,
      "task_completion": 0.303125,
      "interest_arousal": 0.29218750000000004,
      "efficiency": 0.0640625,
      "dialogue_overall": 1.5015625
    }
  },
  {
    "conv_id": "barcor_opendialkg_8707ae3f-0a08-4fdb-880a-fa3181e5db02",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0656249999999998,
          "interestingness": 0.8468749999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9125000000000001,
          "interestingness": 1.0083333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.8250000000000001,
          "interestingness": 0.85
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.6562500000000001,
          "interestingness": 1.08125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.5375
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.14166666666666666,
          "interestingness": 0.29583333333333334
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.275
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.153125,
          "interestingness": 0.1875
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.08333333333333333,
          "interestingness": 0.029166666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4471590909090909,
      "task_completion": 0.3664772727272727,
      "interest_arousal": 0.28238636363636366,
      "efficiency": 0.10113636363636364,
      "dialogue_overall": 1.4443181818181816
    }
  },
  {
    "conv_id": "barcor_redial_8707ae3f-0a08-4fdb-880a-fa3181e5db02",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6375,
          "interestingness": 1.0999999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.0416666666666667,
          "interestingness": 1.0708333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.18750000000000003
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.275,
          "interestingness": 0.35
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.7999999999999999,
          "interestingness": 0.2125
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.1624999999999999,
          "interestingness": 1.3499999999999999
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.23750000000000002,
          "interestingness": 0.95
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.18749999999999997,
          "interestingness": 0.5750000000000001
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.1875,
          "interestingness": 0.25000000000000006
        }
      },
      {
        "turn_ind": 19,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.18749999999999997
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5437500000000001,
      "task_completion": 0.4052083333333334,
      "interest_arousal": 0.33958333333333335,
      "efficiency": 0.2145833333333333,
      "dialogue_overall": 1.5354166666666664
    }
  },
  {
    "conv_id": "barcor_opendialkg_86c042fe-566a-4ec1-bfd9-ed299734038b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.4249999999999998,
          "interestingness": 0.6499999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4541666666666666,
          "interestingness": 0.3625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.25,
          "interestingness": 0.1625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.38125,
          "interestingness": 0.2875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.38593749999999993,
      "task_completion": 0.29375000000000007,
      "interest_arousal": 0.228125,
      "efficiency": 0.08593749999999999,
      "dialogue_overall": 1.1328125
    }
  },
  {
    "conv_id": "unicrs_opendialkg_87efc87d-39a6-46f4-8f51-0b80d023dcda",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5499999999999999,
          "interestingness": 0.5375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.46666666666666673,
          "interestingness": 0.6083333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.7499999999999999,
          "interestingness": 0.90625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.6875000000000001,
          "interestingness": 0.2
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.35625,
          "interestingness": 0.5625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5318181818181819,
      "task_completion": 0.6068181818181819,
      "interest_arousal": 0.4659090909090909,
      "efficiency": 0.23068181818181818,
      "dialogue_overall": 1.706818181818182
    }
  },
  {
    "conv_id": "unicrs_redial_87efc87d-39a6-46f4-8f51-0b80d023dcda",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.505,
          "interestingness": 0.51
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.18750000000000006
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.4312500000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.0125000000000002,
          "interestingness": 0.4250000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.9500000000000002,
      "task_completion": 0.5847222222222221,
      "interest_arousal": 0.5555555555555555,
      "efficiency": 0.3375,
      "dialogue_overall": 2.073611111111111
    }
  },
  {
    "conv_id": "chatgpt_redial_8883ff49-089b-4e92-b506-c38e6c62c5b0",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6750000000000002,
          "interestingness": 0.46249999999999997
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5175000000000001,
          "interestingness": 0.36625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.9287499999999999,
          "interestingness": 0.87625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.9157608695652173,
      "task_completion": 0.6304347826086957,
      "interest_arousal": 0.6951086956521739,
      "efficiency": 0.34347826086956523,
      "dialogue_overall": 2.4081521739130434
    }
  },
  {
    "conv_id": "crbcrs_redial_8883ff49-089b-4e92-b506-c38e6c62c5b0",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.2125,
          "interestingness": 0.5208333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2083333333333334,
      "task_completion": 0.075,
      "interest_arousal": 0.24166666666666672,
      "efficiency": 0.0125,
      "dialogue_overall": 1.1541666666666668
    }
  },
  {
    "conv_id": "kbrd_opendialkg_89e56112-9ffb-4894-8bc4-fa1ee0b36b62",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.12499999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.3187499999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.05
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.024999999999999998,
          "interestingness": 0.521875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.07750000000000003,
      "task_completion": 0.08000000000000002,
      "interest_arousal": 0.14875000000000002,
      "efficiency": 0.0375,
      "dialogue_overall": 0.94875
    }
  },
  {
    "conv_id": "crbcrs_redial_89eaa221-edb1-4712-87c3-a9d4896ff540",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3275,
          "interestingness": 0.3175
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.175
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.12083333333333333,
          "interestingness": 0.2333333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.11666666666666665,
      "task_completion": 0.05277777777777778,
      "interest_arousal": 0.14444444444444446,
      "efficiency": 0.015277777777777777,
      "dialogue_overall": 1.2069444444444444
    }
  },
  {
    "conv_id": "unicrs_redial_89eaa221-edb1-4712-87c3-a9d4896ff540",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.4150000000000001,
          "interestingness": 0.5425
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.39,
      "task_completion": 0.32750000000000007,
      "interest_arousal": 0.3325000000000001,
      "efficiency": 0.0625,
      "dialogue_overall": 1.3025
    }
  },
  {
    "conv_id": "crbcrs_redial_8d3e25d2-2635-4b77-8b0f-af0ba98aa735",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6125,
          "interestingness": 1.0458333333333332
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5,
      "task_completion": 0.29583333333333334,
      "interest_arousal": 0.6708333333333334,
      "efficiency": 0.225,
      "dialogue_overall": 1.6541666666666668
    }
  },
  {
    "conv_id": "crbcrs_redial_8daae5d0-353b-477c-8187-a856180170db",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6708333333333333,
          "interestingness": 0.6791666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.2125,
          "interestingness": 0.61875
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.20000000000000004,
          "interestingness": 0.99375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.5458333333333334,
          "interestingness": 1.475
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.2625,
          "interestingness": 0.8291666666666668
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5326923076923077,
      "task_completion": 0.5048076923076923,
      "interest_arousal": 0.5125000000000001,
      "efficiency": 0.1625,
      "dialogue_overall": 1.6423076923076925
    }
  },
  {
    "conv_id": "chatgpt_redial_8d3e25d2-2635-4b77-8b0f-af0ba98aa735",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.85625,
          "interestingness": 0.7675000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.4024999999999999,
      "task_completion": 0.7825000000000001,
      "interest_arousal": 0.78375,
      "efficiency": 0.53125,
      "dialogue_overall": 2.5675
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_8f15133c-afb8-400e-ac88-d5c71d1b8918",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.2041666666666667,
          "interestingness": 0.3416666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.25,
      "task_completion": 0.22083333333333338,
      "interest_arousal": 0.2833333333333333,
      "efficiency": 0.20416666666666666,
      "dialogue_overall": 1.7333333333333336
    }
  },
  {
    "conv_id": "unicrs_redial_8daae5d0-353b-477c-8187-a856180170db",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9,
          "interestingness": 1.0250000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9125000000000001,
          "interestingness": 1.2249999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.925
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.26250000000000007,
          "interestingness": 1.49375
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.2916666666666665,
          "interestingness": 1.3791666666666662
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.26250000000000007
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5534090909090909,
      "task_completion": 0.8715909090909091,
      "interest_arousal": 0.5488636363636363,
      "efficiency": 0.26022727272727275,
      "dialogue_overall": 2.1386363636363637
    }
  },
  {
    "conv_id": "chatgpt_redial_8f15133c-afb8-400e-ac88-d5c71d1b8918",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.30833333333333335,
          "interestingness": 0.22083333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.375,
      "task_completion": 0.3208333333333333,
      "interest_arousal": 0.2958333333333334,
      "efficiency": 0.39166666666666666,
      "dialogue_overall": 2.016666666666667
    }
  },
  {
    "conv_id": "kbrd_opendialkg_8fb9001d-5a8c-49f7-b6de-322c0ae41f23",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.225
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.037500000000000006,
      "task_completion": 0.09999999999999999,
      "interest_arousal": 0.09999999999999999,
      "efficiency": 0.0,
      "dialogue_overall": 0.9
    }
  },
  {
    "conv_id": "barcor_redial_9037dce6-3df6-428c-951f-4767a78225cb",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.13749999999999998,
          "interestingness": 0.8625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.18125000000000005,
          "interestingness": 0.2
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.43749999999999994,
          "interestingness": 0.540625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.41428571428571426,
      "task_completion": 0.2464285714285714,
      "interest_arousal": 0.5071428571428572,
      "efficiency": 0.09285714285714285,
      "dialogue_overall": 1.3660714285714284
    }
  },
  {
    "conv_id": "unicrs_redial_9037dce6-3df6-428c-951f-4767a78225cb",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.28750000000000003,
          "interestingness": 0.42500000000000004
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.15625000000000003,
          "interestingness": 0.3812500000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.2224999999999997,
          "interestingness": 0.9125000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.475
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.49374999999999997,
          "interestingness": 0.8875000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.465625,
      "task_completion": 0.509375,
      "interest_arousal": 0.55,
      "efficiency": 0.2625,
      "dialogue_overall": 1.5947916666666666
    }
  },
  {
    "conv_id": "kbrd_opendialkg_907f7356-ce58-48b1-8b5e-dbae408cca93",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7750000000000001,
          "interestingness": 0.725
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.39166666666666666,
          "interestingness": 0.9208333333333334
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.07500000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.19500000000000006,
      "task_completion": 0.23500000000000004,
      "interest_arousal": 0.255,
      "efficiency": 0.17250000000000001,
      "dialogue_overall": 1.1824999999999999
    }
  },
  {
    "conv_id": "kbrd_redial_907f7356-ce58-48b1-8b5e-dbae408cca93",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7575000000000001,
          "interestingness": 0.48500000000000004
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.33749999999999997,
          "interestingness": 1.2625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.10625,
          "interestingness": 0.55
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.1,
          "interestingness": 0.09375000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3125,
          "interestingness": 0.7625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3035714285714286,
      "task_completion": 0.17589285714285716,
      "interest_arousal": 0.2607142857142857,
      "efficiency": 0.0732142857142857,
      "dialogue_overall": 1.2714285714285711
    }
  },
  {
    "conv_id": "crbcrs_redial_913203e0-98a2-435d-84c3-69faa0404508",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.016666666666666666,
          "interestingness": 0.6000000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.54375,
          "interestingness": 0.84375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.19,
      "task_completion": 0.0775,
      "interest_arousal": 0.18750000000000006,
      "efficiency": 0.015,
      "dialogue_overall": 1.615
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_9184395a-8608-4820-b7f6-18a0d40361fe",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.746875,
          "interestingness": 0.5625000000000002
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.740625,
      "task_completion": 0.378125,
      "interest_arousal": 0.675,
      "efficiency": 0.428125,
      "dialogue_overall": 2.1625
    }
  },
  {
    "conv_id": "kbrd_opendialkg_91f3802d-bad1-40e1-9431-747fa49a7488",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.21250000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.049999999999999996,
          "interestingness": 0.4333333333333334
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.09999999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.05833333333333333,
          "interestingness": 0.13333333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.054687500000000014,
      "task_completion": 0.0671875,
      "interest_arousal": 0.06093750000000001,
      "efficiency": 0.0125,
      "dialogue_overall": 0.778125
    }
  },
  {
    "conv_id": "unicrs_redial_91f3802d-bad1-40e1-9431-747fa49a7488",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.6825000000000003,
          "interestingness": 1.02
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.4250000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.0375,
      "task_completion": 0.5732142857142857,
      "interest_arousal": 0.6839285714285714,
      "efficiency": 0.557142857142857,
      "dialogue_overall": 2.191071428571428
    }
  },
  {
    "conv_id": "kbrd_opendialkg_94bd941f-595e-4345-ab42-bec55cfd6b4b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.35625000000000007,
          "interestingness": 0.9125000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.36250000000000004,
          "interestingness": 0.8791666666666665
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.9374999999999999,
          "interestingness": 0.9249999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.5,
          "interestingness": 1.1875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.049999999999999996,
          "interestingness": 0.3187500000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.17500000000000004,
      "task_completion": 0.15375000000000003,
      "interest_arousal": 0.17125000000000004,
      "efficiency": 0.053750000000000006,
      "dialogue_overall": 1.0725
    }
  },
  {
    "conv_id": "kbrd_redial_94bd941f-595e-4345-ab42-bec55cfd6b4b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.4166666666666667,
          "interestingness": 0.7250000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.1375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.04375,
          "interestingness": 0.125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.07083333333333333,
      "task_completion": 0.09166666666666667,
      "interest_arousal": 0.10833333333333336,
      "efficiency": 0.08333333333333334,
      "dialogue_overall": 0.9895833333333334
    }
  },
  {
    "conv_id": "crbcrs_redial_979a6d6e-692a-415c-8e03-694517ce19a4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6225,
          "interestingness": 0.4575000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.09166666666666666,
          "interestingness": 0.7166666666666668
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.25000000000000006
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.25555555555555554,
      "task_completion": 0.22916666666666666,
      "interest_arousal": 0.28055555555555556,
      "efficiency": 0.036111111111111115,
      "dialogue_overall": 1.5097222222222226
    }
  },
  {
    "conv_id": "unicrs_redial_979a6d6e-692a-415c-8e03-694517ce19a4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.4249999999999998,
          "interestingness": 1.3249999999999997
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.675
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.4375,
          "interestingness": 0.5499999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8300000000000002,
      "task_completion": 0.49750000000000005,
      "interest_arousal": 0.5100000000000001,
      "efficiency": 0.35250000000000004,
      "dialogue_overall": 2.0475000000000003
    }
  },
  {
    "conv_id": "barcor_opendialkg_9a84c009-0ac6-4a93-b039-ff8ae4c2e8fd",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.30000000000000004,
          "interestingness": 0.11875000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.003125,
          "interestingness": 0.11875000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.396875,
          "interestingness": 0.55
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.6749999999999999,
          "interestingness": 0.9750000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2697916666666667,
      "task_completion": 0.29687500000000006,
      "interest_arousal": 0.24375000000000002,
      "efficiency": 0.06249999999999999,
      "dialogue_overall": 1.2052083333333332
    }
  },
  {
    "conv_id": "unicrs_opendialkg_9a84c009-0ac6-4a93-b039-ff8ae4c2e8fd",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.33125000000000004,
          "interestingness": 0.06875000000000002
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1,
      "task_completion": 0.10625000000000001,
      "interest_arousal": 0.10000000000000002,
      "efficiency": 0.00625,
      "dialogue_overall": 0.8937499999999999
    }
  },
  {
    "conv_id": "chatgpt_redial_a25fbc51-fc2a-4921-a8ab-7d491e9d10b6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.45833333333333337,
          "interestingness": 0.27083333333333337
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.22875,
          "interestingness": 0.8424999999999998
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.4675,
          "interestingness": 0.8724999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8451388888888889,
      "task_completion": 0.6805555555555556,
      "interest_arousal": 0.4520833333333333,
      "efficiency": 0.2805555555555556,
      "dialogue_overall": 2.303472222222223
    }
  },
  {
    "conv_id": "chatgpt_redial_a3de80f6-e715-479d-aeb3-4e088a8965f8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9937500000000001,
          "interestingness": 1.5124999999999997
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4083333333333333,
          "interestingness": 0.8833333333333334
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6349999999999999,
          "interestingness": 0.7862500000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.7658333333333333,
      "task_completion": 0.5525,
      "interest_arousal": 0.7191666666666666,
      "efficiency": 0.15666666666666665,
      "dialogue_overall": 1.9808333333333334
    }
  },
  {
    "conv_id": "crbcrs_redial_a25fbc51-fc2a-4921-a8ab-7d491e9d10b6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.12916666666666668
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.020833333333333336,
      "task_completion": 0.037500000000000006,
      "interest_arousal": 0.04583333333333334,
      "efficiency": 0.0,
      "dialogue_overall": 0.9166666666666665
    }
  },
  {
    "conv_id": "crbcrs_redial_a3de80f6-e715-479d-aeb3-4e088a8965f8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.03125,
          "interestingness": 0.5
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.09999999999999999,
          "interestingness": 0.5750000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.03333333333333333,
      "task_completion": 0.04583333333333333,
      "interest_arousal": 0.11249999999999999,
      "efficiency": 0.0,
      "dialogue_overall": 0.9416666666666667
    }
  },
  {
    "conv_id": "kbrd_redial_ad4651f1-ed87-4538-bb80-19551548ec32",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.32500000000000007
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.21250000000000002,
          "interestingness": 0.2125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.11249999999999999,
          "interestingness": 0.5291666666666667
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.28125000000000006
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.12083333333333332,
          "interestingness": 0.525
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.37625,
      "task_completion": 0.27125,
      "interest_arousal": 0.285,
      "efficiency": 0.10375000000000001,
      "dialogue_overall": 1.3787500000000001
    }
  },
  {
    "conv_id": "unicrs_opendialkg_ad4651f1-ed87-4538-bb80-19551548ec32",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.39375,
          "interestingness": 0.3375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.2541666666666667,
          "interestingness": 0.4458333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.12750000000000003,
      "task_completion": 0.12250000000000001,
      "interest_arousal": 0.12250000000000003,
      "efficiency": 0.0225,
      "dialogue_overall": 0.8425
    }
  },
  {
    "conv_id": "chatgpt_redial_adb1169d-54dd-45f1-af96-5a1c35ea08e2",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.06562500000000002,
          "interestingness": 0.4218750000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.3087500000000001,
          "interestingness": 0.4487500000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.2125000000000001,
          "interestingness": 0.9187500000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.1328125,
      "task_completion": 0.7557291666666667,
      "interest_arousal": 0.7552083333333335,
      "efficiency": 0.4875,
      "dialogue_overall": 2.5593749999999997
    }
  },
  {
    "conv_id": "chatgpt_redial_aef2f6ea-58db-484a-ad29-990d81fdaaba",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.4041666666666667,
          "interestingness": 0.9666666666666666
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.0250000000000001,
          "interestingness": 0.47187499999999993
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.0416666666666665,
          "interestingness": 0.13333333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.24625000000000002,
      "task_completion": 0.20250000000000007,
      "interest_arousal": 0.20875000000000007,
      "efficiency": 0.03125,
      "dialogue_overall": 1.2512500000000002
    }
  },
  {
    "conv_id": "crbcrs_redial_af93223f-3250-41d7-9ce9-bde1288a578d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.43125,
          "interestingness": 0.6625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.26250000000000007,
          "interestingness": 1.0625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.20833333333333334,
          "interestingness": 0.8916666666666665
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.12500000000000003,
          "interestingness": 0.83125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.28124999999999994,
          "interestingness": 0.73125
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.94375,
          "interestingness": 0.8875000000000001
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.20000000000000004,
          "interestingness": 0.5833333333333334
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.85625
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.13749999999999998,
          "interestingness": 0.775
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2270833333333333,
      "task_completion": 0.1701388888888889,
      "interest_arousal": 0.20694444444444451,
      "efficiency": 0.04861111111111111,
      "dialogue_overall": 1.3409722222222222
    }
  },
  {
    "conv_id": "crbcrs_redial_aef2f6ea-58db-484a-ad29-990d81fdaaba",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.09583333333333333,
          "interestingness": 0.8708333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.675,
          "interestingness": 0.9687500000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.7812500000000001,
          "interestingness": 0.88125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.25,
          "interestingness": 1.5607142857142862
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.20625000000000007,
          "interestingness": 0.725
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.15416666666666667,
          "interestingness": 0.6916666666666668
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.9553571428571428,
          "interestingness": 1.1214285714285712
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.10625000000000001,
          "interestingness": 0.5437500000000001
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.42916666666666664,
          "interestingness": 0.7125000000000001
        }
      },
      {
        "turn_ind": 19,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.43750000000000006
        }
      },
      {
        "turn_ind": 21,
        "turn_level_pred": {
          "relevance": 0.29375000000000007,
          "interestingness": 0.6812499999999999
        }
      },
      {
        "turn_ind": 23,
        "turn_level_pred": {
          "relevance": 0.020833333333333332,
          "interestingness": 0.2791666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4544642857142858,
      "task_completion": 0.4669642857142857,
      "interest_arousal": 0.40357142857142847,
      "efficiency": 0.08779761904761907,
      "dialogue_overall": 1.711309523809524
    }
  },
  {
    "conv_id": "unicrs_redial_af93223f-3250-41d7-9ce9-bde1288a578d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9125,
          "interestingness": 1.3
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.2958333333333334,
          "interestingness": 0.5833333333333334
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.175
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.1875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.6875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5214285714285714,
      "task_completion": 0.3803571428571429,
      "interest_arousal": 0.37678571428571433,
      "efficiency": 0.27857142857142847,
      "dialogue_overall": 1.580357142857143
    }
  },
  {
    "conv_id": "chatgpt_redial_b0ccb7b7-9209-4edd-ae5b-ef0615e53511",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.5968749999999998,
          "interestingness": 0.7031250000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.4406249999999998,
      "task_completion": 0.85,
      "interest_arousal": 0.846875,
      "efficiency": 0.8499999999999998,
      "dialogue_overall": 2.8749999999999996
    }
  },
  {
    "conv_id": "crbcrs_redial_b18971bd-ed86-49d8-b2cf-1abbd4143e61",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.41666666666666663,
          "interestingness": 0.725
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.33125,
          "interestingness": 0.38229166666666675
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.09166666666666666,
          "interestingness": 0.525
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.509375,
          "interestingness": 0.8375000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.1875,
          "interestingness": 0.5104166666666666
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.08124999999999999,
          "interestingness": 0.5125000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.24625000000000002,
      "task_completion": 0.20791666666666667,
      "interest_arousal": 0.20916666666666667,
      "efficiency": 0.007916666666666667,
      "dialogue_overall": 1.3670833333333334
    }
  },
  {
    "conv_id": "chatgpt_redial_b18971bd-ed86-49d8-b2cf-1abbd4143e61",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7333333333333333,
          "interestingness": 0.5333333333333334
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6575,
          "interestingness": 1.0
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.0125000000000002,
          "interestingness": 1.3375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8650000000000002,
          "interestingness": 0.7074999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3375,
          "interestingness": 1.1375
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.1874999999999998,
          "interestingness": 1.0281249999999997
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 1.4583333333333333,
          "interestingness": 1.1083333333333334
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.2875,
          "interestingness": 0.86875
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 1.0375,
          "interestingness": 0.6416666666666666
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6847656249999999,
      "task_completion": 0.51796875,
      "interest_arousal": 0.4085937500000001,
      "efficiency": 0.131640625,
      "dialogue_overall": 1.94453125
    }
  },
  {
    "conv_id": "kbrd_redial_b233cfc4-6657-42d8-9a28-0a464de24a87",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2125,
          "interestingness": 1.1749999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.12499999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05833333333333333,
          "interestingness": 0.22916666666666666
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.28124999999999994
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.12678571428571428,
      "task_completion": 0.09642857142857142,
      "interest_arousal": 0.13571428571428573,
      "efficiency": 0.044642857142857144,
      "dialogue_overall": 1.2339285714285713
    }
  },
  {
    "conv_id": "kbrd_opendialkg_b233cfc4-6657-42d8-9a28-0a464de24a87",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.1125,
          "interestingness": 0.36250000000000004
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.16666666666666669,
          "interestingness": 0.9041666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.05
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.12000000000000002,
      "task_completion": 0.25000000000000006,
      "interest_arousal": 0.19500000000000006,
      "efficiency": 0.10250000000000001,
      "dialogue_overall": 1.185
    }
  },
  {
    "conv_id": "kbrd_opendialkg_b42a6fee-371d-4c75-91c2-013557e2bf55",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.21250000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.14166666666666666,
          "interestingness": 0.40833333333333327
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.025
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.21750000000000003,
      "task_completion": 0.15250000000000002,
      "interest_arousal": 0.24750000000000005,
      "efficiency": 0.039999999999999994,
      "dialogue_overall": 1.2274999999999998
    }
  },
  {
    "conv_id": "kbrd_redial_b42a6fee-371d-4c75-91c2-013557e2bf55",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5666666666666668,
          "interestingness": 0.7833333333333334
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.026785714285714288,
          "interestingness": 0.19821428571428565
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.021875000000000002,
          "interestingness": 0.3609375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.2625,
          "interestingness": 0.5232142857142856
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.08000000000000002,
      "task_completion": 0.14500000000000005,
      "interest_arousal": 0.17650000000000007,
      "efficiency": 0.014500000000000002,
      "dialogue_overall": 0.958
    }
  },
  {
    "conv_id": "kbrd_opendialkg_b695cfe5-222c-4533-b42f-5fb410434834",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.1875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.3541666666666667,
          "interestingness": 0.9874999999999998
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.025
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.17000000000000004,
      "task_completion": 0.25000000000000006,
      "interest_arousal": 0.19500000000000006,
      "efficiency": 0.13,
      "dialogue_overall": 1.2449999999999999
    }
  },
  {
    "conv_id": "barcor_opendialkg_b93eb28a-92a4-4f49-9d5c-ef7bc57f4153",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9604166666666668,
          "interestingness": 0.7000000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.49375000000000013,
          "interestingness": 0.29375000000000007
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.540625,
      "task_completion": 0.2640625,
      "interest_arousal": 0.46875,
      "efficiency": 0.196875,
      "dialogue_overall": 1.5343749999999996
    }
  },
  {
    "conv_id": "chatgpt_redial_b93eb28a-92a4-4f49-9d5c-ef7bc57f4153",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3291666666666667,
          "interestingness": 0.7708333333333334
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6083333333333334,
          "interestingness": 0.2791666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.17708333333333337,
      "task_completion": 0.1895833333333333,
      "interest_arousal": 0.21666666666666667,
      "efficiency": 0.08124999999999999,
      "dialogue_overall": 1.3625
    }
  },
  {
    "conv_id": "barcor_redial_bb4f8cc1-fbfc-4990-83e6-abb3541ee47d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0812500000000003,
          "interestingness": 1.225
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.29750000000000004,
          "interestingness": 0.35500000000000015
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5499999999999999,
          "interestingness": 1.2249999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.6,
          "interestingness": 0.7125000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.461111111111111,
      "task_completion": 0.5263888888888889,
      "interest_arousal": 0.40972222222222227,
      "efficiency": 0.17222222222222222,
      "dialogue_overall": 1.6708333333333334
    }
  },
  {
    "conv_id": "unicrs_opendialkg_bb4f8cc1-fbfc-4990-83e6-abb3541ee47d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7124999999999999,
          "interestingness": 0.375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.275,
      "task_completion": 0.0875,
      "interest_arousal": 0.41250000000000003,
      "efficiency": 0.0,
      "dialogue_overall": 1.2625000000000002
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_bd484356-9d60-4d40-aef8-43c9289be3f1",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.678125,
          "interestingness": 0.575
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7925000000000002,
          "interestingness": 0.81125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.8949999999999999,
          "interestingness": 0.18000000000000002
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6432291666666666,
      "task_completion": 0.5026041666666666,
      "interest_arousal": 0.41718749999999993,
      "efficiency": 0.11093750000000001,
      "dialogue_overall": 1.7963541666666667
    }
  },
  {
    "conv_id": "chatgpt_redial_bfa4589c-b896-4fd4-a76b-d960d7800060",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3583333333333334,
          "interestingness": 0.175
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5625,
          "interestingness": 0.28750000000000003
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.20625,
          "interestingness": 0.9062500000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5541666666666667,
      "task_completion": 0.09791666666666667,
      "interest_arousal": 0.27083333333333337,
      "efficiency": 0.029166666666666664,
      "dialogue_overall": 1.5104166666666667
    }
  },
  {
    "conv_id": "crbcrs_redial_bfa4589c-b896-4fd4-a76b-d960d7800060",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.15416666666666667,
          "interestingness": 0.6708333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5125000000000001,
          "interestingness": 1.0541666666666665
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.10416666666666667,
          "interestingness": 0.14166666666666666
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.15
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.09166666666666666,
          "interestingness": 0.7541666666666668
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2333333333333334,
      "task_completion": 0.11000000000000001,
      "interest_arousal": 0.21749999999999997,
      "efficiency": 0.010833333333333334,
      "dialogue_overall": 1.1416666666666666
    }
  },
  {
    "conv_id": "barcor_opendialkg_c19d1b0d-90e5-47c1-9e9d-f11a0f5add8c",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0125000000000002,
          "interestingness": 0.7499999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.18125000000000002,
          "interestingness": 0.15312500000000004
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.2541666666666667,
          "interestingness": 0.17083333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.33125000000000004,
      "task_completion": 0.1578125,
      "interest_arousal": 0.22968750000000004,
      "efficiency": 0.0625,
      "dialogue_overall": 0.9765625
    }
  },
  {
    "conv_id": "barcor_redial_c19d1b0d-90e5-47c1-9e9d-f11a0f5add8c",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.54375,
          "interestingness": 0.8375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.10500000000000001,
          "interestingness": 0.4325000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.08125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.1125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3625,
      "task_completion": 0.24250000000000005,
      "interest_arousal": 0.19625,
      "efficiency": 0.065,
      "dialogue_overall": 1.1375
    }
  },
  {
    "conv_id": "kbrd_opendialkg_c22c525c-d07b-4efd-8657-4e6e2292d742",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.2750000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.025,
      "task_completion": 0.05,
      "interest_arousal": 0.125,
      "efficiency": 0.0,
      "dialogue_overall": 0.7000000000000001
    }
  },
  {
    "conv_id": "kbrd_redial_c22c525c-d07b-4efd-8657-4e6e2292d742",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.1541666666666663,
          "interestingness": 0.7875000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.0666666666666667,
      "task_completion": 0.6791666666666666,
      "interest_arousal": 0.875,
      "efficiency": 0.7291666666666666,
      "dialogue_overall": 2.5458333333333334
    }
  },
  {
    "conv_id": "unicrs_opendialkg_c268bf13-4dcf-43a0-9876-6e3b6c4fed2d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.75,
          "interestingness": 0.5125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4375,
      "task_completion": 0.19999999999999998,
      "interest_arousal": 0.46249999999999997,
      "efficiency": 0.0625,
      "dialogue_overall": 1.65
    }
  },
  {
    "conv_id": "unicrs_redial_c268bf13-4dcf-43a0-9876-6e3b6c4fed2d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.4708333333333334,
          "interestingness": 0.5916666666666668
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.9791666666666667,
      "task_completion": 0.4041666666666666,
      "interest_arousal": 0.675,
      "efficiency": 0.6958333333333335,
      "dialogue_overall": 2.5083333333333333
    }
  },
  {
    "conv_id": "barcor_opendialkg_c3e6f16f-5f9e-44e4-b874-025600a661e1",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.45,
          "interestingness": 1.2625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5625,
          "interestingness": 0.4125000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.21666666666666676,
          "interestingness": 0.7666666666666667
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.175,
          "interestingness": 1.175
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.14375000000000002,
          "interestingness": 0.728125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.23653846153846156,
      "task_completion": 0.20576923076923082,
      "interest_arousal": 0.3298076923076924,
      "efficiency": 0.01730769230769231,
      "dialogue_overall": 1.3740384615384613
    }
  },
  {
    "conv_id": "barcor_redial_c3e6f16f-5f9e-44e4-b874-025600a661e1",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.4375,
          "interestingness": 0.7875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.12083333333333332,
          "interestingness": 0.4458333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.18,
      "task_completion": 0.12499999999999999,
      "interest_arousal": 0.23000000000000004,
      "efficiency": 0.0325,
      "dialogue_overall": 1.5699999999999998
    }
  },
  {
    "conv_id": "barcor_redial_c7fd8c1a-1d1d-468c-990f-27deeb010d57",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7000000000000002,
          "interestingness": 0.9749999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.020833333333333332,
          "interestingness": 0.25
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.3,
          "interestingness": 0.7500000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.225,
          "interestingness": 0.9624999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4291666666666667,
      "task_completion": 0.47291666666666665,
      "interest_arousal": 0.2666666666666667,
      "efficiency": 0.09583333333333334,
      "dialogue_overall": 1.5770833333333336
    }
  },
  {
    "conv_id": "crbcrs_redial_c7fd8c1a-1d1d-468c-990f-27deeb010d57",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.17500000000000002,
          "interestingness": 0.8416666666666666
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.20416666666666666,
          "interestingness": 0.64375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.22187500000000002,
          "interestingness": 0.5281250000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2,
      "task_completion": 0.12211538461538461,
      "interest_arousal": 0.2326923076923077,
      "efficiency": 0.010576923076923078,
      "dialogue_overall": 1.2221153846153845
    }
  },
  {
    "conv_id": "barcor_opendialkg_c8359853-2e71-45df-b078-196b7353ce58",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.11875000000000002,
          "interestingness": 0.07187500000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.018750000000000003,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.10000000000000002,
          "interestingness": 0.30000000000000004
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.13281249999999997,
      "task_completion": 0.07656250000000002,
      "interest_arousal": 0.1328125,
      "efficiency": 0.004687500000000001,
      "dialogue_overall": 0.8999999999999999
    }
  },
  {
    "conv_id": "barcor_redial_c884bc18-4f2d-4bbe-a8ea-05779fb05c4b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3500000000000001,
          "interestingness": 0.6875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.575,
          "interestingness": 0.6
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.4375,
          "interestingness": 0.3083333333333333
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.125,
          "interestingness": 0.075
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.39375000000000004,
      "task_completion": 0.25208333333333327,
      "interest_arousal": 0.16458333333333333,
      "efficiency": 0.020833333333333336,
      "dialogue_overall": 1.1041666666666665
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_c8359853-2e71-45df-b078-196b7353ce58",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6708333333333334,
          "interestingness": 0.5625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.0425,
          "interestingness": 0.9337500000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8548076923076926,
      "task_completion": 0.825,
      "interest_arousal": 0.7721153846153846,
      "efficiency": 0.46153846153846156,
      "dialogue_overall": 2.3355769230769234
    }
  },
  {
    "conv_id": "chatgpt_redial_ca8170c0-d8ef-4fc1-8fc4-c89d262317e2",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.29,
          "interestingness": 0.19500000000000003
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.37750000000000006,
          "interestingness": 0.37000000000000005
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.54,
          "interestingness": 0.19375000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.40150000000000013,
      "task_completion": 0.12500000000000003,
      "interest_arousal": 0.11050000000000001,
      "efficiency": 0.008000000000000002,
      "dialogue_overall": 1.0835
    }
  },
  {
    "conv_id": "chatgpt_redial_cd3a90e0-d7d1-4aad-b069-73d74e6f07f0",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.13333333333333333,
          "interestingness": 0.22500000000000003
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5333333333333333,
          "interestingness": 1.0083333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.8500000000000003,
          "interestingness": 0.8583333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.1152777777777776,
      "task_completion": 0.7374999999999999,
      "interest_arousal": 0.7055555555555555,
      "efficiency": 0.46527777777777785,
      "dialogue_overall": 2.409722222222222
    }
  },
  {
    "conv_id": "kbrd_opendialkg_cd3a90e0-d7d1-4aad-b069-73d74e6f07f0",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.025
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.0,
      "task_completion": 0.0,
      "interest_arousal": 0.0125,
      "efficiency": 0.0,
      "dialogue_overall": 0.7124999999999999
    }
  },
  {
    "conv_id": "barcor_opendialkg_cd6db7f7-d485-4e80-8b56-c941fb1dd904",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.21250000000000005,
          "interestingness": 0.44375000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.049999999999999996,
      "task_completion": 0.08750000000000001,
      "interest_arousal": 0.3499999999999999,
      "efficiency": 0.09375,
      "dialogue_overall": 1.0375
    }
  },
  {
    "conv_id": "barcor_redial_cd6db7f7-d485-4e80-8b56-c941fb1dd904",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.06249999999999999,
          "interestingness": 0.21250000000000008
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.03125,
      "task_completion": 0.0,
      "interest_arousal": 0.12500000000000003,
      "efficiency": 0.0,
      "dialogue_overall": 0.89375
    }
  },
  {
    "conv_id": "kbrd_redial_d3428007-c9e5-4b78-b92e-97d92fc77632",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.4416666666666667,
          "interestingness": 0.775
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.06874999999999999,
          "interestingness": 0.8312499999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.08750000000000001,
          "interestingness": 0.5625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.31250000000000006
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.19204545454545455,
      "task_completion": 0.1931818181818182,
      "interest_arousal": 0.1795454545454545,
      "efficiency": 0.04204545454545455,
      "dialogue_overall": 1.2727272727272727
    }
  },
  {
    "conv_id": "kbrd_opendialkg_d847452b-5b73-4cbf-a70f-e625c6cc0465",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.19999999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.1791666666666667,
          "interestingness": 0.6833333333333335
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.17187499999999997,
      "task_completion": 0.18125,
      "interest_arousal": 0.4000000000000001,
      "efficiency": 0.209375,
      "dialogue_overall": 1.1656250000000001
    }
  },
  {
    "conv_id": "kbrd_redial_d847452b-5b73-4cbf-a70f-e625c6cc0465",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.29583333333333334,
          "interestingness": 0.44166666666666665
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.06249999999999999,
          "interestingness": 0.45625000000000004
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.28750000000000003
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.275
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.22321428571428573,
      "task_completion": 0.15178571428571427,
      "interest_arousal": 0.2464285714285714,
      "efficiency": 0.05,
      "dialogue_overall": 1.4303571428571427
    }
  },
  {
    "conv_id": "unicrs_opendialkg_d8ab6267-5fa4-4405-806b-1ea1679c8e21",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5625000000000001,
          "interestingness": 0.6375000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.07500000000000001,
          "interestingness": 0.39999999999999997
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.1375,
          "interestingness": 0.30000000000000004
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.7875,
          "interestingness": 0.9562500000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5250000000000001,
          "interestingness": 0.4375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5250000000000001,
      "task_completion": 0.4587500000000001,
      "interest_arousal": 0.36249999999999993,
      "efficiency": 0.10875000000000003,
      "dialogue_overall": 1.4799999999999998
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_d8d3fc84-78df-497a-b8de-8044cefc4bff",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.1,
          "interestingness": 0.8218750000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.46875,
          "interestingness": 0.8875
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.41250000000000003,
          "interestingness": 0.425
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.4749999999999999,
          "interestingness": 0.4625000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6078125,
      "task_completion": 0.26249999999999996,
      "interest_arousal": 0.3515625,
      "efficiency": 0.14375,
      "dialogue_overall": 1.45
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_db4dac93-7452-4c25-bf2e-7da5195b0198",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7291666666666667,
          "interestingness": 0.975
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.125,
          "interestingness": 1.75
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.97,
          "interestingness": 0.84125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.9812500000000001,
          "interestingness": 0.28125000000000006
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.14375,
          "interestingness": 1.7062500000000003
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.5833333333333334,
          "interestingness": 0.7666666666666668
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.1875,
          "interestingness": 0.16666666666666666
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.1916666666666667,
          "interestingness": 0.049999999999999996
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6464285714285715,
      "task_completion": 0.2803571428571428,
      "interest_arousal": 0.3366071428571428,
      "efficiency": 0.12589285714285714,
      "dialogue_overall": 1.7183035714285713
    }
  },
  {
    "conv_id": "kbrd_opendialkg_dfc62638-0660-4413-81d4-75bef5ca0745",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.1625,
          "interestingness": 0.5375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7833333333333334,
          "interestingness": 1.8541666666666672
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.12499999999999999,
          "interestingness": 0.3125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.11666666666666665,
          "interestingness": 0.07083333333333333
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6125,
          "interestingness": 0.95
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.54375,
          "interestingness": 0.8125000000000001
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.7,
          "interestingness": 0.9375000000000001
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.575
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.11875,
          "interestingness": 0.8937499999999999
        }
      },
      {
        "turn_ind": 19,
        "turn_level_pred": {
          "relevance": 0.6000000000000001,
          "interestingness": 0.85
        }
      },
      {
        "turn_ind": 21,
        "turn_level_pred": {
          "relevance": 0.03125,
          "interestingness": 0.58125
        }
      },
      {
        "turn_ind": 23,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.35000000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3977272727272727,
      "task_completion": 0.34829545454545463,
      "interest_arousal": 0.3914772727272728,
      "efficiency": 0.08920454545454545,
      "dialogue_overall": 1.3250000000000002
    }
  },
  {
    "conv_id": "crbcrs_redial_db4dac93-7452-4c25-bf2e-7da5195b0198",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.39375000000000004,
          "interestingness": 0.9062500000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.1791666666666667,
          "interestingness": 0.5541666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.15000000000000002,
          "interestingness": 0.32500000000000007
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.2625,
          "interestingness": 0.86875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.12187500000000001,
          "interestingness": 0.725
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1732142857142857,
      "task_completion": 0.1616071428571429,
      "interest_arousal": 0.30000000000000004,
      "efficiency": 0.02053571428571429,
      "dialogue_overall": 1.2348214285714285
    }
  },
  {
    "conv_id": "kbrd_redial_dfc62638-0660-4413-81d4-75bef5ca0745",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.22500000000000003,
          "interestingness": 0.9375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.553125,
          "interestingness": 1.528125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.225,
          "interestingness": 0.7687499999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.15625,
          "interestingness": 1.5250000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.275,
          "interestingness": 1.4749999999999999
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.7062500000000002,
          "interestingness": 0.8374999999999999
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 1.7291666666666672,
          "interestingness": 1.4666666666666663
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.24999999999999997,
          "interestingness": 0.83125
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.7
        }
      },
      {
        "turn_ind": 19,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.3875
        }
      },
      {
        "turn_ind": 21,
        "turn_level_pred": {
          "relevance": 0.25833333333333336,
          "interestingness": 1.304166666666667
        }
      },
      {
        "turn_ind": 23,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.7375
        }
      },
      {
        "turn_ind": 25,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.575
        }
      },
      {
        "turn_ind": 27,
        "turn_level_pred": {
          "relevance": 0.10000000000000002,
          "interestingness": 0.18750000000000006
        }
      },
      {
        "turn_ind": 29,
        "turn_level_pred": {
          "relevance": 0.19166666666666668,
          "interestingness": 0.6458333333333333
        }
      },
      {
        "turn_ind": 31,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.6124999999999999
        }
      },
      {
        "turn_ind": 33,
        "turn_level_pred": {
          "relevance": 0.28750000000000003,
          "interestingness": 1.0125
        }
      },
      {
        "turn_ind": 35,
        "turn_level_pred": {
          "relevance": 0.8333333333333333,
          "interestingness": 0.7666666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.40625,
      "task_completion": 0.3746527777777778,
      "interest_arousal": 0.27465277777777775,
      "efficiency": 0.07812499999999999,
      "dialogue_overall": 1.4458333333333333
    }
  },
  {
    "conv_id": "chatgpt_redial_d8d3fc84-78df-497a-b8de-8044cefc4bff",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.42916666666666664,
          "interestingness": 0.5791666666666666
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8562500000000001,
          "interestingness": 1.525
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.8937500000000002,
          "interestingness": 0.7112500000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.485,
          "interestingness": 0.8224999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.095,
      "task_completion": 1.0175,
      "interest_arousal": 0.7425,
      "efficiency": 0.37625000000000003,
      "dialogue_overall": 2.50125
    }
  },
  {
    "conv_id": "barcor_redial_e2ee45c9-4974-44be-99a7-e4f04d1f7fbe",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.8875000000000002,
          "interestingness": 1.1624999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9833333333333335,
          "interestingness": 0.7833333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.734375,
      "task_completion": 0.6218750000000001,
      "interest_arousal": 0.4031249999999999,
      "efficiency": 0.26875,
      "dialogue_overall": 2.196875
    }
  },
  {
    "conv_id": "barcor_redial_e32c7ae6-22ed-4cf3-8689-a9b8197c5faf",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.525,
          "interestingness": 0.46249999999999997
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.76875,
          "interestingness": 0.775
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.9916666666666667,
          "interestingness": 0.7583333333333333
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.2375,
          "interestingness": 0.8374999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.125
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.2,
          "interestingness": 1.3749999999999998
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.0375,
          "interestingness": 0.275
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.6124999999999999,
          "interestingness": 0.6625000000000001
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.41250000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4794642857142858,
      "task_completion": 0.45357142857142857,
      "interest_arousal": 0.32767857142857143,
      "efficiency": 0.09375,
      "dialogue_overall": 1.573214285714286
    }
  },
  {
    "conv_id": "unicrs_opendialkg_e32c7ae6-22ed-4cf3-8689-a9b8197c5faf",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6000000000000001,
          "interestingness": 0.11250000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.3625,
          "interestingness": 0.20625000000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.48125,
          "interestingness": 0.35625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.44583333333333336,
          "interestingness": 0.7833333333333334
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.10000000000000002,
          "interestingness": 0.4937500000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1431818181818182,
      "task_completion": 0.13636363636363638,
      "interest_arousal": 0.13977272727272727,
      "efficiency": 0.005681818181818183,
      "dialogue_overall": 0.9738636363636365
    }
  },
  {
    "conv_id": "kbrd_opendialkg_e3bf31c7-0612-4a9b-b2e2-b1fb5eaf5679",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.05
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.029166666666666667,
          "interestingness": 0.08333333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.037500000000000006
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.12500000000000003,
      "task_completion": 0.09,
      "interest_arousal": 0.08000000000000002,
      "efficiency": 0.0,
      "dialogue_overall": 0.895
    }
  },
  {
    "conv_id": "unicrs_redial_e3bf31c7-0612-4a9b-b2e2-b1fb5eaf5679",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5624999999999999,
          "interestingness": 0.9500000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.3624999999999998,
          "interestingness": 1.270833333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05625,
          "interestingness": 0.45
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.7625000000000001,
      "task_completion": 0.8821428571428571,
      "interest_arousal": 0.44107142857142856,
      "efficiency": 0.46428571428571436,
      "dialogue_overall": 2.435714285714286
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_e50ebfee-e9e7-48f1-bffe-f785fe154641",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.228125,
          "interestingness": 0.54375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.11125000000000002,
          "interestingness": 0.5275000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.06875,
          "interestingness": 1.375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.8025,
          "interestingness": 0.9275
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.0895833333333336,
      "task_completion": 0.6491666666666666,
      "interest_arousal": 0.67125,
      "efficiency": 0.41583333333333333,
      "dialogue_overall": 2.4845833333333336
    }
  },
  {
    "conv_id": "chatgpt_redial_e50ebfee-e9e7-48f1-bffe-f785fe154641",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.14687500000000003,
          "interestingness": 0.415625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.14375000000000002,
          "interestingness": 0.36875
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.7325000000000002,
          "interestingness": 0.66
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.2437499999999997,
      "task_completion": 0.6541666666666666,
      "interest_arousal": 0.7182291666666665,
      "efficiency": 0.5234375,
      "dialogue_overall": 2.6395833333333334
    }
  },
  {
    "conv_id": "kbrd_redial_e7eb4480-6951-4582-91ad-1d19ead970bb",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.27916666666666673,
          "interestingness": 1.0375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7125,
          "interestingness": 0.5250000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.1375,
          "interestingness": 0.8250000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.03333333333333333,
          "interestingness": 0.3208333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.10625000000000001,
      "task_completion": 0.16718750000000002,
      "interest_arousal": 0.18750000000000003,
      "efficiency": 0.0125,
      "dialogue_overall": 1.009375
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_e93bad92-7864-42b6-99ed-da1cd32e1aa1",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.07083333333333333,
          "interestingness": 0.13333333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.1,
          "interestingness": 1.8250000000000004
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.125,
          "interestingness": 0.53375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.3990384615384612,
          "interestingness": 1.4317307692307693
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.4525000000000001,
          "interestingness": 1.1987500000000002
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.15,
          "interestingness": 0.7375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.0269230769230768,
      "task_completion": 0.8900641025641025,
      "interest_arousal": 0.7118589743589744,
      "efficiency": 0.27884615384615385,
      "dialogue_overall": 2.4974358974358974
    }
  },
  {
    "conv_id": "crbcrs_redial_e2ee45c9-4974-44be-99a7-e4f04d1f7fbe",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9874999999999998,
          "interestingness": 1.475
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.35625,
          "interestingness": 0.45625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2625,
      "task_completion": 0.19583333333333336,
      "interest_arousal": 0.23333333333333336,
      "efficiency": 0.14583333333333334,
      "dialogue_overall": 1.6125000000000003
    }
  },
  {
    "conv_id": "crbcrs_redial_e93bad92-7864-42b6-99ed-da1cd32e1aa1",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.25250000000000006,
          "interestingness": 0.3975
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4458333333333333,
          "interestingness": 0.9916666666666669
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.04375,
          "interestingness": 0.146875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.15312499999999998,
      "task_completion": 0.16979166666666667,
      "interest_arousal": 0.20208333333333334,
      "efficiency": 0.04479166666666667,
      "dialogue_overall": 1.359375
    }
  },
  {
    "conv_id": "kbrd_opendialkg_e7eb4480-6951-4582-91ad-1d19ead970bb",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.06875,
          "interestingness": 0.5125000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.24375000000000005,
          "interestingness": 0.80625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.4083333333333334,
          "interestingness": 0.5625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.21785714285714283,
      "task_completion": 0.1875,
      "interest_arousal": 0.2767857142857143,
      "efficiency": 0.04464285714285715,
      "dialogue_overall": 1.1714285714285715
    }
  },
  {
    "conv_id": "crbcrs_redial_ee17753c-54f9-4ed7-abd2-2356d171ee79",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.20625000000000004,
          "interestingness": 0.50625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.09999999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.06249999999999999,
      "task_completion": 0.03333333333333333,
      "interest_arousal": 0.07916666666666666,
      "efficiency": 0.029166666666666667,
      "dialogue_overall": 1.0791666666666664
    }
  },
  {
    "conv_id": "unicrs_opendialkg_ee17753c-54f9-4ed7-abd2-2356d171ee79",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.175
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.025,
      "task_completion": 0.0,
      "interest_arousal": 0.05,
      "efficiency": 0.0,
      "dialogue_overall": 0.7374999999999999
    }
  },
  {
    "conv_id": "kbrd_opendialkg_f0c0ae40-8615-4122-86e4-d956f3db4b74",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.25416666666666665,
          "interestingness": 0.4625000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.10312500000000002,
      "task_completion": 0.07812500000000001,
      "interest_arousal": 0.14062500000000003,
      "efficiency": 0.015625,
      "dialogue_overall": 0.91875
    }
  },
  {
    "conv_id": "kbrd_redial_f0c0ae40-8615-4122-86e4-d956f3db4b74",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.4125,
          "interestingness": 1.23125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.017499999999999998,
          "interestingness": 0.16499999999999998
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.6124999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.36249999999999993,
          "interestingness": 0.5458333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1659090909090909,
      "task_completion": 0.11022727272727273,
      "interest_arousal": 0.13749999999999996,
      "efficiency": 0.03181818181818182,
      "dialogue_overall": 1.0227272727272727
    }
  },
  {
    "conv_id": "kbrd_redial_f15ea9e8-80bc-4c29-ab3b-a34d6e28d40a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9124999999999999,
          "interestingness": 0.7874999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.07083333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.26250000000000007
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.028125,
          "interestingness": 0.375
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.6374999999999998
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.1666666666666667,
          "interestingness": 0.2666666666666667
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.3375000000000001,
          "interestingness": 0.15000000000000002
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1591666666666667,
      "task_completion": 0.09833333333333334,
      "interest_arousal": 0.0775,
      "efficiency": 0.0025,
      "dialogue_overall": 1.01
    }
  },
  {
    "conv_id": "kbrd_opendialkg_f15ea9e8-80bc-4c29-ab3b-a34d6e28d40a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3062500000000001,
          "interestingness": 0.50625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7166666666666668,
          "interestingness": 0.8708333333333335
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.058333333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2013888888888889,
      "task_completion": 0.3388888888888888,
      "interest_arousal": 0.16111111111111112,
      "efficiency": 0.03888888888888888,
      "dialogue_overall": 0.7986111111111113
    }
  },
  {
    "conv_id": "crbcrs_redial_f321a7c9-c1d0-49de-bfc8-1fc3258e726a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.03333333333333333,
          "interestingness": 0.45416666666666666
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.6375000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.14000000000000004,
      "task_completion": 0.0675,
      "interest_arousal": 0.22250000000000006,
      "efficiency": 0.027500000000000004,
      "dialogue_overall": 1.1449999999999998
    }
  },
  {
    "conv_id": "barcor_redial_f3bf1692-0008-4528-874b-e336583b143a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.075,
          "interestingness": 0.825
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.725,
          "interestingness": 0.9458333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.29375,
          "interestingness": 0.30000000000000004
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.525,
          "interestingness": 0.4125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.45000000000000007,
          "interestingness": 0.20000000000000004
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.6125,
          "interestingness": 0.5218750000000001
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.325,
          "interestingness": 0.725
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.675,
          "interestingness": 1.0
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5595588235294117,
      "task_completion": 0.3066176470588236,
      "interest_arousal": 0.3360294117647059,
      "efficiency": 0.11544117647058824,
      "dialogue_overall": 1.3654411764705885
    }
  },
  {
    "conv_id": "chatgpt_redial_f45e0dce-9e70-4f75-a952-74ebe83ffc49",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.27083333333333337,
          "interestingness": 0.9416666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.1625,
          "interestingness": 1.3
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.165,
          "interestingness": 0.7724999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.3761363636363635,
          "interestingness": 0.9011363636363635
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.9975000000000002,
      "task_completion": 0.7600000000000001,
      "interest_arousal": 0.5055000000000001,
      "efficiency": 0.247,
      "dialogue_overall": 2.437
    }
  },
  {
    "conv_id": "kbrd_opendialkg_f4e52cb8-a5e7-42be-8294-b61cdfcdf83d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.12499999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.08124999999999999,
          "interestingness": 0.5718749999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.3575000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.10340909090909091,
      "task_completion": 0.07840909090909091,
      "interest_arousal": 0.1227272727272727,
      "efficiency": 0.0125,
      "dialogue_overall": 0.8613636363636362
    }
  },
  {
    "conv_id": "crbcrs_redial_f45e0dce-9e70-4f75-a952-74ebe83ffc49",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0375,
          "interestingness": 0.9625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.4000000000000001,
          "interestingness": 1.18125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5812500000000002,
          "interestingness": 0.8375000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5208333333333334,
      "task_completion": 0.55,
      "interest_arousal": 0.2791666666666667,
      "efficiency": 0.28124999999999994,
      "dialogue_overall": 2.0854166666666667
    }
  },
  {
    "conv_id": "kbrd_redial_f4e52cb8-a5e7-42be-8294-b61cdfcdf83d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.21250000000000002,
          "interestingness": 0.7625000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7458333333333333,
          "interestingness": 0.5666666666666668
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.25625000000000003
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.20000000000000004,
          "interestingness": 0.8375000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.2708333333333333,
          "interestingness": 0.5875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.21590909090909088,
      "task_completion": 0.16704545454545455,
      "interest_arousal": 0.09431818181818181,
      "efficiency": 0.009090909090909092,
      "dialogue_overall": 1.1215909090909089
    }
  },
  {
    "conv_id": "kbrd_opendialkg_f58c432b-a80a-4879-bb36-890e05e349fa",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.018750000000000003,
          "interestingness": 0.20625000000000004
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.025,
      "task_completion": 0.0125,
      "interest_arousal": 0.11875000000000001,
      "efficiency": 0.0,
      "dialogue_overall": 0.7375
    }
  },
  {
    "conv_id": "kbrd_redial_f58c432b-a80a-4879-bb36-890e05e349fa",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3875,
          "interestingness": 0.9749999999999998
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.12499999999999999,
      "task_completion": 0.0625,
      "interest_arousal": 0.5000000000000001,
      "efficiency": 0.05,
      "dialogue_overall": 1.7125
    }
  },
  {
    "conv_id": "barcor_opendialkg_f6918ed5-7797-4d0c-b968-0373b08ff172",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.03125,
          "interestingness": 0.7187499999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.37499999999999994,
          "interestingness": 0.6708333333333334
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.11875,
          "interestingness": 0.48125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.13928571428571426,
      "task_completion": 0.16428571428571428,
      "interest_arousal": 0.14821428571428572,
      "efficiency": 0.00892857142857143,
      "dialogue_overall": 1.2553571428571426
    }
  },
  {
    "conv_id": "barcor_redial_f6918ed5-7797-4d0c-b968-0373b08ff172",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0125000000000002,
          "interestingness": 1.15
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.925,
          "interestingness": 0.8625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5833333333333333,
          "interestingness": 0.925
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.13749999999999998
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.58125,
      "task_completion": 0.4541666666666667,
      "interest_arousal": 0.4145833333333334,
      "efficiency": 0.15000000000000002,
      "dialogue_overall": 1.7958333333333334
    }
  },
  {
    "conv_id": "chatgpt_redial_fa1ba55e-a982-4cd8-8d2f-b8bf9d34e211",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.04750000000000001,
          "interestingness": 0.17250000000000004
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.13500000000000004,
          "interestingness": 0.6162500000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.25,
          "interestingness": 0.6312500000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.5262500000000001,
          "interestingness": 0.62
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.12916666666666665,
          "interestingness": 0.5750000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8041666666666667,
      "task_completion": 0.6495833333333332,
      "interest_arousal": 0.5420833333333334,
      "efficiency": 0.33125000000000004,
      "dialogue_overall": 2.30875
    }
  },
  {
    "conv_id": "unicrs_redial_f8d830f0-44b3-4d5b-9a84-a70cf096ee22",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5333333333333334,
          "interestingness": 0.3666666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.08750000000000001,
          "interestingness": 0.475
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.225
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.09999999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.11406249999999998,
      "task_completion": 0.07031250000000003,
      "interest_arousal": 0.04843750000000001,
      "efficiency": 0.003125,
      "dialogue_overall": 1.2046875
    }
  },
  {
    "conv_id": "crbcrs_redial_fb3bac98-374d-4cc1-b20d-653d477aa7a3",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6624999999999999,
          "interestingness": 0.7062499999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7875000000000002,
          "interestingness": 1.2812500000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.30000000000000004,
          "interestingness": 1.1874999999999998
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4625000000000001,
      "task_completion": 0.4000000000000001,
      "interest_arousal": 0.6475,
      "efficiency": 0.20750000000000005,
      "dialogue_overall": 1.7675
    }
  },
  {
    "conv_id": "kbrd_opendialkg_fc8625ab-7096-4261-9dfd-e0d0cc6f4a36",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.004166666666666667,
          "interestingness": 0.029166666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.3041666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.05
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.17500000000000002,
          "interestingness": 0.7374999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.049999999999999996,
          "interestingness": 0.3875
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.5583333333333333,
          "interestingness": 1.0208333333333335
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.20000000000000007,
          "interestingness": 0.50625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.07,
      "task_completion": 0.054166666666666655,
      "interest_arousal": 0.04416666666666665,
      "efficiency": 0.0,
      "dialogue_overall": 0.7508333333333334
    }
  },
  {
    "conv_id": "chatgpt_redial_fd33ea0d-55d6-44f8-9b79-76ea73a8c83d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.4458333333333333,
          "interestingness": 1.0
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.375,
          "interestingness": 1.6500000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.70375,
          "interestingness": 1.26625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.7937500000000002,
          "interestingness": 0.88125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.8625,
          "interestingness": 0.98125
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.225
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.729891304347826,
      "task_completion": 0.7934782608695652,
      "interest_arousal": 0.5396739130434782,
      "efficiency": 0.2472826086956522,
      "dialogue_overall": 2.1972826086956525
    }
  },
  {
    "conv_id": "unicrs_redial_fb3bac98-374d-4cc1-b20d-653d477aa7a3",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.41250000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.025,
      "task_completion": 0.0,
      "interest_arousal": 0.21250000000000002,
      "efficiency": 0.0,
      "dialogue_overall": 0.9125
    }
  },
  {
    "conv_id": "crbcrs_redial_fd33ea0d-55d6-44f8-9b79-76ea73a8c83d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2093749999999999,
          "interestingness": 0.971875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.0694444444444444,
          "interestingness": 1.0402777777777776
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.2625,
          "interestingness": 0.2833333333333334
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.21875000000000006,
          "interestingness": 0.51875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.09999999999999999,
          "interestingness": 0.5249999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5994047619047618,
      "task_completion": 0.35952380952380947,
      "interest_arousal": 0.3333333333333333,
      "efficiency": 0.1261904761904762,
      "dialogue_overall": 1.761904761904762
    }
  },
  {
    "conv_id": "unicrs_redial_00cdd046-79d7-44ba-8686-c60271701e8a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.1125,
          "interestingness": 0.625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7541666666666667,
          "interestingness": 1.1541666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.1375,
          "interestingness": 0.37500000000000006
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.17500000000000002,
          "interestingness": 0.4375
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.12083333333333332,
          "interestingness": 0.23750000000000002
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2011363636363636,
      "task_completion": 0.27954545454545454,
      "interest_arousal": 0.2693181818181818,
      "efficiency": 0.12613636363636363,
      "dialogue_overall": 1.3125
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_00cdd046-79d7-44ba-8686-c60271701e8a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.11666666666666665,
          "interestingness": 0.2833333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7166666666666667,
          "interestingness": 0.8083333333333335
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6375000000000001,
          "interestingness": 1.6312499999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.2912499999999998,
          "interestingness": 0.9775
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3875,
          "interestingness": 0.8749999999999999
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.12499999999999999,
          "interestingness": 0.4375
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.25625,
          "interestingness": 0.5499999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5587962962962962,
      "task_completion": 0.3245370370370371,
      "interest_arousal": 0.3722222222222222,
      "efficiency": 0.12685185185185185,
      "dialogue_overall": 1.6300925925925926
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_016264e2-c112-459a-ab52-072e02f8747b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9083333333333334,
          "interestingness": 1.0458333333333332
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9137500000000001,
          "interestingness": 1.1675000000000004
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.09999999999999999,
          "interestingness": 0.4000000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.4749999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.8979166666666667,
          "interestingness": 0.225
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6648148148148149,
      "task_completion": 0.3032407407407408,
      "interest_arousal": 0.3361111111111111,
      "efficiency": 0.12407407407407407,
      "dialogue_overall": 1.6226851851851851
    }
  },
  {
    "conv_id": "unicrs_redial_016264e2-c112-459a-ab52-072e02f8747b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.07500000000000001,
          "interestingness": 1.1124999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.3708333333333334,
          "interestingness": 0.4208333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.0624999999999998,
          "interestingness": 0.7375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8875000000000001,
          "interestingness": 0.5
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.05,
          "interestingness": 0.5874999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3267857142857142,
      "task_completion": 0.19642857142857142,
      "interest_arousal": 0.1839285714285714,
      "efficiency": 0.03035714285714286,
      "dialogue_overall": 1.1053571428571427
    }
  },
  {
    "conv_id": "kbrd_opendialkg_02e94613-4209-461c-8b12-22f5021262eb",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.4625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6083333333333333,
          "interestingness": 0.7833333333333332
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.37500000000000006,
          "interestingness": 1.05
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.019642857142857146,
          "interestingness": 0.12142857142857143
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.30000000000000004
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.09903846153846153,
      "task_completion": 0.07788461538461539,
      "interest_arousal": 0.08269230769230768,
      "efficiency": 0.02403846153846154,
      "dialogue_overall": 0.9153846153846154
    }
  },
  {
    "conv_id": "crbcrs_redial_02e94613-4209-461c-8b12-22f5021262eb",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.33125000000000004,
          "interestingness": 0.8874999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.01875,
          "interestingness": 0.971875
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.15,
          "interestingness": 0.775
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.3375,
          "interestingness": 1.0875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0375,
          "interestingness": 0.4541666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.0854166666666667,
      "task_completion": 0.07291666666666667,
      "interest_arousal": 0.20520833333333335,
      "efficiency": 0.024999999999999998,
      "dialogue_overall": 1.0625
    }
  },
  {
    "conv_id": "kbrd_redial_04ed4d35-af19-44ac-91b1-fcc3fb857a5f",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7250000000000001,
          "interestingness": 0.7937500000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4625,
          "interestingness": 0.6625000000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5656249999999999,
          "interestingness": 0.875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.3125,
          "interestingness": 1.0375
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3750000000000001,
          "interestingness": 0.74375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.44545454545454544,
      "task_completion": 0.42840909090909085,
      "interest_arousal": 0.37386363636363634,
      "efficiency": 0.16136363636363635,
      "dialogue_overall": 1.5215909090909092
    }
  },
  {
    "conv_id": "crbcrs_redial_04ed4d35-af19-44ac-91b1-fcc3fb857a5f",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.05625,
          "interestingness": 1.10625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.004166666666666667,
          "interestingness": 0.09166666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.10000000000000002,
          "interestingness": 0.74375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.13749999999999998,
          "interestingness": 0.9958333333333332
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6375,
          "interestingness": 1.0062499999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2580357142857143,
      "task_completion": 0.2696428571428572,
      "interest_arousal": 0.20000000000000004,
      "efficiency": 0.08839285714285713,
      "dialogue_overall": 1.2276785714285716
    }
  },
  {
    "conv_id": "unicrs_redial_06083840-16c8-440b-9866-23a77335e554",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.43124999999999997,
          "interestingness": 1.04375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.4125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.39583333333333337
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {}
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6374999999999998,
          "interestingness": 0.6124999999999998
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.6083333333333334,
          "interestingness": 0.5666666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.18875000000000006,
      "task_completion": 0.09875000000000002,
      "interest_arousal": 0.11500000000000003,
      "efficiency": 0.04125000000000001,
      "dialogue_overall": 1.1500000000000001
    }
  },
  {
    "conv_id": "barcor_opendialkg_06083840-16c8-440b-9866-23a77335e554",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3541666666666667,
          "interestingness": 0.9083333333333334
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6000000000000001,
          "interestingness": 1.075
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.008333333333333333,
          "interestingness": 0.13750000000000004
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.29375,
          "interestingness": 0.9062500000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.2687500000000003,
          "interestingness": 1.43125
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 1.0125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.321875,
      "task_completion": 0.39583333333333337,
      "interest_arousal": 0.30000000000000004,
      "efficiency": 0.04375,
      "dialogue_overall": 1.2104166666666667
    }
  },
  {
    "conv_id": "kbrd_redial_0b094345-3f4b-4774-bc32-49c8395aa141",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.5750000000000002,
          "interestingness": 1.2874999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.09999999999999999,
          "interestingness": 0.1875
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.029166666666666667,
          "interestingness": 0.09999999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.25
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.034375,
          "interestingness": 0.4062500000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1977272727272727,
      "task_completion": 0.1159090909090909,
      "interest_arousal": 0.16477272727272724,
      "efficiency": 0.01931818181818182,
      "dialogue_overall": 1.0931818181818183
    }
  },
  {
    "conv_id": "crbcrs_redial_0b094345-3f4b-4774-bc32-49c8395aa141",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.3125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.225,
          "interestingness": 0.7937500000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.4,
          "interestingness": 0.96875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.03125,
          "interestingness": 0.03125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.30000000000000004,
          "interestingness": 0.83125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.044318181818181826,
      "task_completion": 0.0375,
      "interest_arousal": 0.09204545454545454,
      "efficiency": 0.012500000000000002,
      "dialogue_overall": 0.8920454545454546
    }
  },
  {
    "conv_id": "unicrs_opendialkg_0f6a6f54-84a4-4b37-98bf-2bc560f39de7",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.925,
          "interestingness": 0.325
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8874999999999998,
          "interestingness": 0.23750000000000004
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.19583333333333336,
          "interestingness": 0.6666666666666666
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.07916666666666666,
          "interestingness": 0.6958333333333333
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6375000000000001,
          "interestingness": 0.5625000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.18055555555555555,
      "task_completion": 0.0625,
      "interest_arousal": 0.17500000000000002,
      "efficiency": 0.0,
      "dialogue_overall": 0.9930555555555557
    }
  },
  {
    "conv_id": "chatgpt_redial_0f6a6f54-84a4-4b37-98bf-2bc560f39de7",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.24583333333333335,
          "interestingness": 0.3083333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.22875,
          "interestingness": 1.0787499999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.7500000000000001,
          "interestingness": 0.7250000000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8340909090909091,
          "interestingness": 0.805681818181818
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.15833333333333333,
          "interestingness": 0.20833333333333337
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8151785714285714,
      "task_completion": 0.5200892857142857,
      "interest_arousal": 0.48928571428571427,
      "efficiency": 0.24910714285714283,
      "dialogue_overall": 2.132589285714286
    }
  },
  {
    "conv_id": "kbrd_redial_1371d38a-649b-4c5a-9c1f-c2ce5a117555",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0175,
          "interestingness": 0.9400000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.06874999999999999,
          "interestingness": 0.19375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0375,
          "interestingness": 0.1958333333333334
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.43749999999999994,
          "interestingness": 1.2500000000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.27083333333333337,
          "interestingness": 0.8624999999999999
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.4729166666666667,
          "interestingness": 0.34166666666666673
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.12500000000000003,
      "task_completion": 0.11312500000000002,
      "interest_arousal": 0.09000000000000001,
      "efficiency": 0.005,
      "dialogue_overall": 0.91375
    }
  },
  {
    "conv_id": "kbrd_opendialkg_185f7406-2f1c-4211-ae0f-0d940ca141ec",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3000000000000001,
          "interestingness": 0.8250000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.008333333333333333,
          "interestingness": 0.3375000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.03214285714285715,
          "interestingness": 0.16964285714285718
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.06875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.024999999999999998,
          "interestingness": 0.146875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.05367647058823529,
      "task_completion": 0.0463235294117647,
      "interest_arousal": 0.06470588235294117,
      "efficiency": 0.004411764705882353,
      "dialogue_overall": 0.7411764705882354
    }
  },
  {
    "conv_id": "unicrs_opendialkg_185f7406-2f1c-4211-ae0f-0d940ca141ec",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.475
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.15000000000000002,
          "interestingness": 0.63125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.16874999999999998,
          "interestingness": 0.66875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.03333333333333333,
          "interestingness": 0.2
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.13749999999999998,
          "interestingness": 0.2750000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.11249999999999999,
      "task_completion": 0.075,
      "interest_arousal": 0.12916666666666665,
      "efficiency": 0.011111111111111112,
      "dialogue_overall": 0.9027777777777778
    }
  },
  {
    "conv_id": "barcor_redial_19dbea4f-c8a0-45fa-8b77-c96bdc3e7e37",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.1624999999999999,
          "interestingness": 1.35
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.1375,
          "interestingness": 1.7125000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.9083333333333333,
          "interestingness": 0.47916666666666663
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.6,
          "interestingness": 1.175
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.7374999999999999,
          "interestingness": 0.8250000000000001
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.7687499999999999,
          "interestingness": 1.16875
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.3875
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.9374999999999999,
          "interestingness": 1.275
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5477272727272726,
      "task_completion": 0.4943181818181818,
      "interest_arousal": 0.4204545454545454,
      "efficiency": 0.10000000000000002,
      "dialogue_overall": 1.8261363636363634
    }
  },
  {
    "conv_id": "kbrd_redial_19dbea4f-c8a0-45fa-8b77-c96bdc3e7e37",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.5374999999999999,
          "interestingness": 1.1875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7625,
          "interestingness": 0.7124999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.2041666666666666,
          "interestingness": 1.2874999999999996
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.08750000000000002,
          "interestingness": 0.7124999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.15625,
          "interestingness": 0.7000000000000002
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.14583333333333331
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.284375,
      "task_completion": 0.18541666666666673,
      "interest_arousal": 0.19583333333333336,
      "efficiency": 0.09895833333333333,
      "dialogue_overall": 1.4322916666666665
    }
  },
  {
    "conv_id": "chatgpt_redial_1cb9615d-e2b0-43ac-ac12-9b3313111f37",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7550000000000001,
          "interestingness": 0.6249999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.0874999999999997,
          "interestingness": 1.55625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.20833333333333334,
          "interestingness": 0.35208333333333336
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.4874999999999998,
          "interestingness": 1.3125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.8083333333333333,
          "interestingness": 1.1791666666666665
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.3791666666666667,
          "interestingness": 0.17916666666666667
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.7916666666666667,
          "interestingness": 0.5499999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5564516129032259,
      "task_completion": 0.37943548387096776,
      "interest_arousal": 0.32943548387096777,
      "efficiency": 0.1899193548387097,
      "dialogue_overall": 1.958467741935484
    }
  },
  {
    "conv_id": "barcor_opendialkg_1cb9615d-e2b0-43ac-ac12-9b3313111f37",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6729166666666667,
          "interestingness": 0.3979166666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6333333333333333,
          "interestingness": 0.775
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {}
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.19999999999999998
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.38749999999999996,
          "interestingness": 1.1312500000000003
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.4416666666666667,
          "interestingness": 0.8291666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.32583333333333336,
      "task_completion": 0.19,
      "interest_arousal": 0.18,
      "efficiency": 0.04,
      "dialogue_overall": 1.2508333333333335
    }
  },
  {
    "conv_id": "chatgpt_redial_1d66da75-4fa9-4176-be34-aa8369db1abc",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2916666666666665,
          "interestingness": 1.0083333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.1125,
          "interestingness": 1.475
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.7385416666666667,
          "interestingness": 1.4947916666666665
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.05,
          "interestingness": 1.6874999999999998
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.459090909090909,
          "interestingness": 0.7761363636363635
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.275,
          "interestingness": 0.5666666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.9318181818181819,
      "task_completion": 0.9242424242424243,
      "interest_arousal": 0.47916666666666663,
      "efficiency": 0.3840909090909091,
      "dialogue_overall": 2.584848484848485
    }
  },
  {
    "conv_id": "kbrd_redial_1d66da75-4fa9-4176-be34-aa8369db1abc",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.135,
          "interestingness": 0.96
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.25833333333333336
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.018750000000000003,
          "interestingness": 0.11250000000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.1,
          "interestingness": 0.65625
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.1625,
          "interestingness": 0.6749999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.31346153846153846,
      "task_completion": 0.2865384615384616,
      "interest_arousal": 0.28076923076923077,
      "efficiency": 0.11538461538461539,
      "dialogue_overall": 1.341346153846154
    }
  },
  {
    "conv_id": "unicrs_opendialkg_1e78e67b-3a06-42dc-bfce-5c3e4e7383df",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.725,
          "interestingness": 0.5249999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5166666666666666,
          "interestingness": 0.6708333333333334
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.46666666666666673,
          "interestingness": 0.7666666666666667
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.05625,
          "interestingness": 0.275
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.0050000000000001,
          "interestingness": 0.9874999999999999
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.5687499999999999,
          "interestingness": 0.95
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.42500000000000004,
          "interestingness": 0.4375000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.23541666666666666,
      "task_completion": 0.18472222222222223,
      "interest_arousal": 0.1958333333333334,
      "efficiency": 0.03194444444444444,
      "dialogue_overall": 1.2958333333333334
    }
  },
  {
    "conv_id": "chatgpt_redial_1e78e67b-3a06-42dc-bfce-5c3e4e7383df",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0166666666666666,
          "interestingness": 0.5333333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.3125,
          "interestingness": 1.6875
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.02125,
          "interestingness": 0.8200000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.1862499999999998,
          "interestingness": 1.105
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.12083333333333332,
          "interestingness": 0.375
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.23500000000000007,
          "interestingness": 0.2425
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.858125,
      "task_completion": 0.6006250000000001,
      "interest_arousal": 0.608125,
      "efficiency": 0.19249999999999998,
      "dialogue_overall": 2.3421875
    }
  },
  {
    "conv_id": "chatgpt_redial_2489b744-c02c-4a2f-8397-9c4e49a22fee",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6250000000000001,
          "interestingness": 0.8166666666666668
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.7375000000000003,
          "interestingness": 1.6875000000000004
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.1738636363636364,
          "interestingness": 0.421590909090909
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.16666666666666669,
          "interestingness": 0.30416666666666664
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.38333333333333336,
          "interestingness": 0.3416666666666666
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.11666666666666665,
          "interestingness": 0.42916666666666664
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.5333333333333333,
          "interestingness": 0.41250000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.599537037037037,
      "task_completion": 0.3060185185185185,
      "interest_arousal": 0.2740740740740741,
      "efficiency": 0.07592592592592592,
      "dialogue_overall": 1.4162037037037039
    }
  },
  {
    "conv_id": "barcor_opendialkg_2489b744-c02c-4a2f-8397-9c4e49a22fee",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9125000000000001,
          "interestingness": 0.9249999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.37916666666666676,
          "interestingness": 0.9833333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.38125,
          "interestingness": 0.9125000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.16250000000000003,
          "interestingness": 0.5812499999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.06875,
          "interestingness": 0.4125
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.03125,
          "interestingness": 0.23750000000000004
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.05
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.125,
          "interestingness": 0.07500000000000001
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.16875,
          "interestingness": 0.5
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.27058823529411763,
      "task_completion": 0.1426470588235294,
      "interest_arousal": 0.20514705882352943,
      "efficiency": 0.031617647058823535,
      "dialogue_overall": 1.1007352941176471
    }
  },
  {
    "conv_id": "chatgpt_redial_2955c260-0ba9-414c-8980-bf8bf054900e",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.3333333333333333,
          "interestingness": 1.05
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9708333333333334,
          "interestingness": 0.7708333333333334
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.2375,
          "interestingness": 1.7312500000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8041666666666667,
          "interestingness": 0.6729166666666667
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.7291666666666667,
          "interestingness": 0.8375
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.009375,
          "interestingness": 0.8187500000000001
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.12916666666666668,
          "interestingness": 0.30416666666666664
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5995833333333334,
      "task_completion": 0.41791666666666666,
      "interest_arousal": 0.3966666666666667,
      "efficiency": 0.10750000000000001,
      "dialogue_overall": 1.7466666666666668
    }
  },
  {
    "conv_id": "unicrs_opendialkg_2955c260-0ba9-414c-8980-bf8bf054900e",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.1,
          "interestingness": 0.15
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.30625,
          "interestingness": 0.6125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.40625000000000006,
          "interestingness": 0.3125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.4312500000000001,
          "interestingness": 0.4000000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.15,
          "interestingness": 0.3083333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.29874999999999996,
      "task_completion": 0.28375000000000006,
      "interest_arousal": 0.20500000000000007,
      "efficiency": 0.02,
      "dialogue_overall": 1.0425
    }
  },
  {
    "conv_id": "kbrd_opendialkg_2ab8e8ba-41db-4834-9ac3-a659c96697ef",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.10000000000000002,
          "interestingness": 0.43124999999999997
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5979166666666667,
          "interestingness": 1.2375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.0875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.03125,
          "interestingness": 0.13125000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.12583333333333335,
      "task_completion": 0.10083333333333333,
      "interest_arousal": 0.1325,
      "efficiency": 0.04416666666666667,
      "dialogue_overall": 0.9091666666666669
    }
  },
  {
    "conv_id": "unicrs_redial_2ab8e8ba-41db-4834-9ac3-a659c96697ef",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.36875,
          "interestingness": 0.9249999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.5416666666666663,
          "interestingness": 1.5541666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.475
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.4375000000000001,
          "interestingness": 0.7374999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {}
      }
    ],
    "dial_level_pred": {
      "understanding": 0.7125,
      "task_completion": 0.5285714285714287,
      "interest_arousal": 0.5785714285714285,
      "efficiency": 0.4089285714285714,
      "dialogue_overall": 1.8785714285714286
    }
  },
  {
    "conv_id": "unicrs_redial_2cbd2fc1-aaeb-4678-a064-d1b780295836",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7041666666666667,
          "interestingness": 0.4041666666666666
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.16250000000000003
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.018750000000000003,
          "interestingness": 0.1375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.09999999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.029166666666666667,
          "interestingness": 0.07916666666666666
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.12159090909090908,
      "task_completion": 0.08977272727272727,
      "interest_arousal": 0.07272727272727271,
      "efficiency": 0.02613636363636364,
      "dialogue_overall": 0.9329545454545456
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_2e180e37-b63b-42d2-8141-2996edbab658",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.03333333333333333,
          "interestingness": 0.23750000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6275,
          "interestingness": 0.6637500000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.2874999999999999,
          "interestingness": 1.6124999999999998
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.73,
          "interestingness": 0.72375
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.13625,
          "interestingness": 0.09125000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.29285714285714287,
      "task_completion": 0.18535714285714286,
      "interest_arousal": 0.21857142857142858,
      "efficiency": 0.025714285714285717,
      "dialogue_overall": 1.3928571428571428
    }
  },
  {
    "conv_id": "kbrd_opendialkg_2e180e37-b63b-42d2-8141-2996edbab658",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.22500000000000006,
          "interestingness": 0.6374999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.029166666666666667,
          "interestingness": 0.19583333333333336
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.05
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.490625
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.46249999999999997,
          "interestingness": 0.45000000000000007
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.11125000000000002,
      "task_completion": 0.08750000000000001,
      "interest_arousal": 0.11625000000000002,
      "efficiency": 0.021249999999999998,
      "dialogue_overall": 0.8637499999999999
    }
  },
  {
    "conv_id": "unicrs_opendialkg_337ec03b-5961-4de8-9209-b2e36f3dd174",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.575,
          "interestingness": 0.575
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.2125,
          "interestingness": 0.7875000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.06250000000000001,
          "interestingness": 0.6625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.22500000000000003,
          "interestingness": 0.225
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.15000000000000005,
          "interestingness": 0.6812499999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.24305555555555555,
      "task_completion": 0.14444444444444443,
      "interest_arousal": 0.19305555555555556,
      "efficiency": 0.006944444444444445,
      "dialogue_overall": 1.1249999999999998
    }
  },
  {
    "conv_id": "barcor_opendialkg_337ec03b-5961-4de8-9209-b2e36f3dd174",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.8249999999999998,
          "interestingness": 0.9562499999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5937500000000001,
          "interestingness": 0.55625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.07500000000000001,
          "interestingness": 0.08125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.03125,
          "interestingness": 0.5375000000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.4333333333333334,
          "interestingness": 0.5666666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.44519230769230766,
      "task_completion": 0.3307692307692308,
      "interest_arousal": 0.3490384615384616,
      "efficiency": 0.11730769230769231,
      "dialogue_overall": 1.1576923076923076
    }
  },
  {
    "conv_id": "chatgpt_redial_3795bb9f-6f60-4c48-8ee4-f18658e93225",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.835,
          "interestingness": 0.6675
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.276785714285714,
          "interestingness": 0.8535714285714285
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.9625,
          "interestingness": 1.0875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.5375000000000001,
          "interestingness": 0.80125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.19583333333333333,
          "interestingness": 0.4833333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5408653846153846,
      "task_completion": 0.40192307692307705,
      "interest_arousal": 0.28173076923076923,
      "efficiency": 0.1360576923076923,
      "dialogue_overall": 1.5490384615384618
    }
  },
  {
    "conv_id": "kbrd_opendialkg_3795bb9f-6f60-4c48-8ee4-f18658e93225",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.03333333333333333,
          "interestingness": 0.3708333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.15833333333333335,
          "interestingness": 0.6624999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.26250000000000007
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.06875,
          "interestingness": 0.18125000000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.08500000000000002,
          "interestingness": 0.24000000000000002
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.02053571428571429,
      "task_completion": 0.02410714285714286,
      "interest_arousal": 0.04821428571428571,
      "efficiency": 0.0026785714285714286,
      "dialogue_overall": 0.7133928571428573
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_38d10608-4472-47b4-b453-61596745aa06",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.08,
          "interestingness": 0.7124999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.69375,
          "interestingness": 1.2125000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.8112499999999998,
          "interestingness": 0.67375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8299999999999998,
          "interestingness": 0.675
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.2625,
          "interestingness": 1.1500000000000001
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.037500000000000006
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.25000000000000006,
          "interestingness": 0.32916666666666666
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5796428571428571,
      "task_completion": 0.4,
      "interest_arousal": 0.29000000000000004,
      "efficiency": 0.08214285714285714,
      "dialogue_overall": 1.7746428571428574
    }
  },
  {
    "conv_id": "crbcrs_redial_38d10608-4472-47b4-b453-61596745aa06",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.39374999999999993
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.59375,
          "interestingness": 0.975
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.23750000000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.30000000000000004,
          "interestingness": 1.05
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.28750000000000003,
          "interestingness": 0.7625
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.14166666666666666
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.22499999999999998
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.08214285714285714,
      "task_completion": 0.033035714285714286,
      "interest_arousal": 0.08392857142857142,
      "efficiency": 0.019642857142857146,
      "dialogue_overall": 0.9294642857142857
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_39db65a4-2e70-4b3d-b60c-7fd8bc9efa56",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.10416666666666666,
          "interestingness": 0.20416666666666666
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.18333333333333332,
          "interestingness": 0.25000000000000006
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.0166666666666666,
          "interestingness": 0.9874999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.9812500000000001,
          "interestingness": 1.1749999999999998
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3541666666666667,
          "interestingness": 0.4083333333333334
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.16666666666666669,
          "interestingness": 0.575
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6183823529411764,
      "task_completion": 0.5522058823529412,
      "interest_arousal": 0.5720588235294117,
      "efficiency": 0.1698529411764706,
      "dialogue_overall": 1.7536764705882353
    }
  },
  {
    "conv_id": "unicrs_redial_39db65a4-2e70-4b3d-b60c-7fd8bc9efa56",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5333333333333332,
          "interestingness": 0.45
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.11249999999999999,
          "interestingness": 0.4416666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.15
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.7625000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.15
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.10833333333333332,
      "task_completion": 0.07083333333333335,
      "interest_arousal": 0.17222222222222225,
      "efficiency": 0.004166666666666667,
      "dialogue_overall": 0.8902777777777778
    }
  },
  {
    "conv_id": "kbrd_redial_3d50a5ae-4ff9-4f35-be68-6c19857be239",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.28750000000000003
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0375,
          "interestingness": 0.35625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.015,
          "interestingness": 0.24000000000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.1875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.38125,
          "interestingness": 0.6250000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.10937500000000001,
      "task_completion": 0.10729166666666666,
      "interest_arousal": 0.10312500000000001,
      "efficiency": 0.015625,
      "dialogue_overall": 1.1
    }
  },
  {
    "conv_id": "crbcrs_redial_3d50a5ae-4ff9-4f35-be68-6c19857be239",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.23125,
          "interestingness": 0.8062499999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4375,
          "interestingness": 0.85
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.03125,
          "interestingness": 0.3687499999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.3875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.32916666666666666,
          "interestingness": 1.1999999999999997
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.10000000000000003,
      "task_completion": 0.10250000000000004,
      "interest_arousal": 0.24875000000000003,
      "efficiency": 0.04500000000000001,
      "dialogue_overall": 1.1487500000000002
    }
  },
  {
    "conv_id": "kbrd_opendialkg_3e77aa7d-1ff9-4b2c-a85d-2e06f45b0c80",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.13333333333333333,
          "interestingness": 0.525
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.30000000000000004
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.3875,
          "interestingness": 0.9
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6666666666666667,
          "interestingness": 0.6
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.33125000000000004,
      "task_completion": 0.35750000000000004,
      "interest_arousal": 0.22250000000000006,
      "efficiency": 0.030000000000000002,
      "dialogue_overall": 1.08125
    }
  },
  {
    "conv_id": "unicrs_redial_3e77aa7d-1ff9-4b2c-a85d-2e06f45b0c80",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3,
          "interestingness": 0.17500000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.17916666666666664,
          "interestingness": 0.7041666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.11249999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.4
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.1375,
          "interestingness": 0.6499999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3625,
      "task_completion": 0.25357142857142856,
      "interest_arousal": 0.17857142857142855,
      "efficiency": 0.09642857142857143,
      "dialogue_overall": 1.2
    }
  },
  {
    "conv_id": "chatgpt_redial_432bc2e1-fd63-44fb-ae9e-4b7924b94442",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.3458333333333334,
          "interestingness": 1.0083333333333335
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.1791666666666663,
          "interestingness": 0.9270833333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.6374999999999997,
          "interestingness": 0.7124999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8083333333333335,
          "interestingness": 0.6291666666666667
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.9875,
          "interestingness": 0.7041666666666666
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.0875,
          "interestingness": 0.22916666666666669
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.7670454545454545,
      "task_completion": 0.8255681818181817,
      "interest_arousal": 0.37954545454545463,
      "efficiency": 0.20170454545454544,
      "dialogue_overall": 2.165909090909091
    }
  },
  {
    "conv_id": "barcor_redial_432bc2e1-fd63-44fb-ae9e-4b7924b94442",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.4750000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4416666666666667,
          "interestingness": 0.5708333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.18125000000000005,
          "interestingness": 0.6250000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.7083333333333334,
          "interestingness": 1.1458333333333333
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5208333333333334,
          "interestingness": 0.6124999999999999
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.3875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.24807692307692308,
      "task_completion": 0.1432692307692308,
      "interest_arousal": 0.25384615384615383,
      "efficiency": 0.0028846153846153848,
      "dialogue_overall": 1.0115384615384615
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_46b1ce29-95f1-458e-9c36-d459af3c161b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.4333333333333334,
          "interestingness": 0.3208333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.74875,
          "interestingness": 0.8325000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.35125000000000006,
          "interestingness": 0.7412500000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.7675000000000001,
          "interestingness": 0.97
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.2625,
          "interestingness": 0.0975
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.3
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.5208333333333334,
          "interestingness": 0.024999999999999998
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.7294871794871794,
      "task_completion": 0.503525641025641,
      "interest_arousal": 0.3858974358974359,
      "efficiency": 0.18397435897435896,
      "dialogue_overall": 2.120833333333333
    }
  },
  {
    "conv_id": "unicrs_opendialkg_46e03658-4fbd-4d85-9954-5f8e97c9810c",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.1
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.05625,
          "interestingness": 0.14375000000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05625,
          "interestingness": 0.11250000000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.08750000000000001,
          "interestingness": 0.41875000000000007
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.42916666666666664,
          "interestingness": 0.6958333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.030000000000000002,
      "task_completion": 0.030000000000000002,
      "interest_arousal": 0.04875000000000001,
      "efficiency": 0.00625,
      "dialogue_overall": 0.69625
    }
  },
  {
    "conv_id": "unicrs_redial_475e30ff-2ac0-4c7d-9bc7-1bf1d4e1e5ee",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.8083333333333333,
          "interestingness": 0.8208333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.3875,
          "interestingness": 0.5375000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.18750000000000006,
          "interestingness": 0.5874999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.22500000000000003,
          "interestingness": 0.22812500000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6499999999999999,
          "interestingness": 0.6083333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.24910714285714283,
      "task_completion": 0.17500000000000002,
      "interest_arousal": 0.2294642857142857,
      "efficiency": 0.06160714285714286,
      "dialogue_overall": 1.124107142857143
    }
  },
  {
    "conv_id": "crbcrs_redial_475e30ff-2ac0-4c7d-9bc7-1bf1d4e1e5ee",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6666666666666666,
          "interestingness": 1.15
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4,
          "interestingness": 0.475
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.30624999999999997
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.11875000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.39999999999999997,
          "interestingness": 0.47500000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.17708333333333337,
      "task_completion": 0.10312500000000002,
      "interest_arousal": 0.1947916666666667,
      "efficiency": 0.04270833333333334,
      "dialogue_overall": 1.1145833333333335
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_47ab6b6f-5b0e-4e9f-8797-3e15b9f92c10",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0916666666666666,
          "interestingness": 0.8000000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.7,
          "interestingness": 0.8875000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.5250000000000001,
          "interestingness": 0.9249999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8791666666666667,
          "interestingness": 0.953125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.9275,
          "interestingness": 0.7249999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.9447916666666668,
      "task_completion": 0.7187500000000001,
      "interest_arousal": 0.573263888888889,
      "efficiency": 0.20347222222222222,
      "dialogue_overall": 2.4072916666666666
    }
  },
  {
    "conv_id": "barcor_redial_48bbf1fb-f2f3-4e95-8e0c-dee1f46d3a02",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.25000000000000006,
          "interestingness": 0.3
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.1,
          "interestingness": 0.4375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.26250000000000007
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.075
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1732142857142857,
      "task_completion": 0.14821428571428574,
      "interest_arousal": 0.20000000000000004,
      "efficiency": 0.06250000000000001,
      "dialogue_overall": 1.2499999999999998
    }
  },
  {
    "conv_id": "kbrd_redial_48bbf1fb-f2f3-4e95-8e0c-dee1f46d3a02",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0375,
          "interestingness": 0.09166666666666666
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.004166666666666667,
          "interestingness": 0.0375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.1625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.14375000000000002,
          "interestingness": 0.7562500000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.26875000000000004,
          "interestingness": 0.60625
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.7437500000000001,
          "interestingness": 0.8
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.31,
      "task_completion": 0.24916666666666668,
      "interest_arousal": 0.30250000000000005,
      "efficiency": 0.08333333333333334,
      "dialogue_overall": 1.315
    }
  },
  {
    "conv_id": "barcor_redial_4a880a3b-9af1-4d5b-935d-02c9d2907c42",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7875000000000001,
          "interestingness": 1.3499999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6,
          "interestingness": 0.6343750000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.3500000000000001,
          "interestingness": 0.9624999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.84375,
          "interestingness": 0.88125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.8250000000000001,
          "interestingness": 0.575
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.2875000000000001,
          "interestingness": 0.45000000000000007
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8374999999999999,
      "task_completion": 0.7306818181818181,
      "interest_arousal": 0.4806818181818182,
      "efficiency": 0.3522727272727273,
      "dialogue_overall": 2.4863636363636368
    }
  },
  {
    "conv_id": "crbcrs_redial_4a880a3b-9af1-4d5b-935d-02c9d2907c42",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.18125000000000002,
          "interestingness": 0.8624999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.24583333333333335,
          "interestingness": 0.625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.38125,
          "interestingness": 0.93125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.049999999999999996,
          "interestingness": 0.475
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.15000000000000002
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.16022727272727277,
      "task_completion": 0.1068181818181818,
      "interest_arousal": 0.2056818181818182,
      "efficiency": 0.06136363636363638,
      "dialogue_overall": 1.4749999999999999
    }
  },
  {
    "conv_id": "kbrd_redial_4e45c938-f909-4f8e-94f0-e700bd15e249",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.30625,
          "interestingness": 0.9124999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.2
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.5791666666666667
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.9125000000000001,
          "interestingness": 1.38125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.2
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.24374999999999997,
          "interestingness": 0.69375
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.3708333333333334,
          "interestingness": 0.17083333333333336
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.9375000000000001,
          "interestingness": 0.1375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.21083333333333337,
      "task_completion": 0.07833333333333332,
      "interest_arousal": 0.21666666666666667,
      "efficiency": 0.021666666666666667,
      "dialogue_overall": 1.0450000000000002
    }
  },
  {
    "conv_id": "crbcrs_redial_4e45c938-f909-4f8e-94f0-e700bd15e249",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.03333333333333333,
          "interestingness": 0.5625000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.018750000000000003,
          "interestingness": 0.25625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.020833333333333332,
          "interestingness": 0.3125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.1125,
          "interestingness": 0.8999999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.018750000000000003,
          "interestingness": 0.3437499999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.016666666666666666,
      "task_completion": 0.009375,
      "interest_arousal": 0.06562500000000002,
      "efficiency": 0.004166666666666667,
      "dialogue_overall": 0.7010416666666667
    }
  },
  {
    "conv_id": "kbrd_redial_4fa22efa-db55-4f50-a247-a0aa13f7b1ba",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.1375,
          "interestingness": 0.9624999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.15000000000000002,
          "interestingness": 0.775
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.9583333333333333,
          "interestingness": 1.0374999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.10416666666666666,
          "interestingness": 0.5375000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.43750000000000006
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.1249999999999998,
          "interestingness": 1.2833333333333332
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.11250000000000002
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.525
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.19642857142857145,
      "task_completion": 0.21249999999999997,
      "interest_arousal": 0.25535714285714284,
      "efficiency": 0.07767857142857143,
      "dialogue_overall": 1.2169642857142857
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_4fa22efa-db55-4f50-a247-a0aa13f7b1ba",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.47916666666666674,
          "interestingness": 0.4750000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8662500000000002,
          "interestingness": 0.92625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.39999999999999997,
          "interestingness": 1.0562500000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.9425,
          "interestingness": 1.3549999999999998
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.94375,
          "interestingness": 1.10375
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.3666666666666667,
          "interestingness": 0.7416666666666667
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.25000000000000006,
          "interestingness": 0.4166666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5613636363636364,
      "task_completion": 0.3394886363636364,
      "interest_arousal": 0.4494318181818182,
      "efficiency": 0.22642045454545456,
      "dialogue_overall": 2.169318181818182
    }
  },
  {
    "conv_id": "chatgpt_redial_5391f846-74c1-474b-8d7c-dc4bb72ba1a5",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.26562500000000006,
          "interestingness": 0.08437500000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.75,
          "interestingness": 0.6874999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6625000000000001,
          "interestingness": 1.2937500000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.075,
          "interestingness": 1.3624999999999998
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.25937499999999997,
          "interestingness": 0.515625
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.12187500000000001,
          "interestingness": 0.146875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.21171875,
      "task_completion": 0.23828125,
      "interest_arousal": 0.2125,
      "efficiency": 0.07265624999999999,
      "dialogue_overall": 1.0359375
    }
  },
  {
    "conv_id": "barcor_opendialkg_5391f846-74c1-474b-8d7c-dc4bb72ba1a5",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6499999999999999,
          "interestingness": 0.5225
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5374999999999999,
          "interestingness": 0.5041666666666668
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.4,
          "interestingness": 0.7124999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.32499999999999996,
          "interestingness": 0.42500000000000004
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5125,
          "interestingness": 0.49999999999999994
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.19374999999999998,
          "interestingness": 0.6125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.41160714285714284,
      "task_completion": 0.26785714285714285,
      "interest_arousal": 0.28928571428571437,
      "efficiency": 0.09910714285714287,
      "dialogue_overall": 1.2348214285714285
    }
  },
  {
    "conv_id": "unicrs_redial_580e55b2-d4bf-4f9b-8413-0a4e343ef741",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0375,
          "interestingness": 0.7937500000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.75,
          "interestingness": 0.7291666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.4375,
          "interestingness": 0.42500000000000004
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.3958333333333333,
          "interestingness": 0.65
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5625000000000001,
          "interestingness": 0.36249999999999993
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2975,
      "task_completion": 0.20625000000000004,
      "interest_arousal": 0.27125,
      "efficiency": 0.08375,
      "dialogue_overall": 1.38625
    }
  },
  {
    "conv_id": "kbrd_opendialkg_580e55b2-d4bf-4f9b-8413-0a4e343ef741",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.17500000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0525,
          "interestingness": 0.24250000000000005
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.13125000000000003
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.02,
          "interestingness": 0.5975000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.08083333333333334,
      "task_completion": 0.07,
      "interest_arousal": 0.10916666666666665,
      "efficiency": 0.0175,
      "dialogue_overall": 0.8500000000000001
    }
  },
  {
    "conv_id": "barcor_opendialkg_5848368c-44f1-4c4c-a0fa-0334b82287c6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.36250000000000004
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.375,
          "interestingness": 0.48124999999999996
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.04583333333333333,
          "interestingness": 0.19583333333333336
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.3416666666666667,
          "interestingness": 1.1833333333333331
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.1375,
          "interestingness": 1.0062499999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.14545454545454545,
      "task_completion": 0.11363636363636365,
      "interest_arousal": 0.1715909090909091,
      "efficiency": 0.00681818181818182,
      "dialogue_overall": 0.9590909090909091
    }
  },
  {
    "conv_id": "kbrd_redial_5848368c-44f1-4c4c-a0fa-0334b82287c6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.016666666666666666,
          "interestingness": 0.17916666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.49375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.4000000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.36250000000000004,
          "interestingness": 0.2333333333333333
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.7208333333333332,
          "interestingness": 0.6208333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.11770833333333333,
      "task_completion": 0.05520833333333333,
      "interest_arousal": 0.07291666666666667,
      "efficiency": 0.0010416666666666667,
      "dialogue_overall": 0.8916666666666666
    }
  },
  {
    "conv_id": "kbrd_opendialkg_5b6e2618-9bc2-48c1-9172-aa2043b71b60",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.3875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.20416666666666666,
          "interestingness": 1.0166666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.3875,
          "interestingness": 0.5666666666666668
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.08125,
          "interestingness": 0.325
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.21625000000000005,
      "task_completion": 0.21250000000000008,
      "interest_arousal": 0.2512500000000001,
      "efficiency": 0.12375000000000001,
      "dialogue_overall": 1.0975000000000001
    }
  },
  {
    "conv_id": "barcor_opendialkg_5b6e2618-9bc2-48c1-9172-aa2043b71b60",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3725000000000001,
          "interestingness": 0.43000000000000005
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5333333333333333,
          "interestingness": 0.4208333333333334
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8437500000000001,
          "interestingness": 0.8624999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5125,
          "interestingness": 0.6416666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5544642857142857,
      "task_completion": 0.3973214285714286,
      "interest_arousal": 0.46428571428571425,
      "efficiency": 0.14107142857142857,
      "dialogue_overall": 1.4687500000000002
    }
  },
  {
    "conv_id": "barcor_redial_62ed5d7b-16c7-48f2-9731-38c3061f31b4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.175,
          "interestingness": 1.2874999999999996
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.7375000000000003,
          "interestingness": 1.5749999999999997
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.2291666666666665,
          "interestingness": 1.0958333333333332
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.1500000000000001,
          "interestingness": 1.3625000000000003
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5625,
          "interestingness": 0.5375
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.525,
          "interestingness": 0.9374999999999999
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.17500000000000002,
          "interestingness": 0.2
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.1444444444444444,
      "task_completion": 1.1152777777777776,
      "interest_arousal": 0.5361111111111111,
      "efficiency": 0.3833333333333333,
      "dialogue_overall": 2.504166666666667
    }
  },
  {
    "conv_id": "kbrd_opendialkg_62ed5d7b-16c7-48f2-9731-38c3061f31b4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.12499999999999999,
          "interestingness": 0.425
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4083333333333334,
          "interestingness": 1.4333333333333331
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.18750000000000003
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.0
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.09375000000000001,
          "interestingness": 0.175
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.08611111111111111,
      "task_completion": 0.05277777777777777,
      "interest_arousal": 0.12638888888888888,
      "efficiency": 0.016666666666666666,
      "dialogue_overall": 0.826388888888889
    }
  },
  {
    "conv_id": "barcor_opendialkg_635f6ec4-dad3-4c4c-914b-3ec9ee18c636",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3125000000000001,
          "interestingness": 0.5375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.14375000000000002,
          "interestingness": 0.58125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.06249999999999999,
          "interestingness": 0.39999999999999997
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.15833333333333333,
          "interestingness": 0.47500000000000003
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3125,
          "interestingness": 0.5375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.16250000000000003,
      "task_completion": 0.13295454545454546,
      "interest_arousal": 0.14886363636363636,
      "efficiency": 0.027272727272727275,
      "dialogue_overall": 1.0613636363636363
    }
  },
  {
    "conv_id": "barcor_redial_635f6ec4-dad3-4c4c-914b-3ec9ee18c636",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9125000000000001,
          "interestingness": 1.1
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.9125000000000003,
          "interestingness": 1.7125000000000004
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.3333333333333334,
          "interestingness": 0.275
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.25625000000000003,
          "interestingness": 0.36250000000000004
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.11249999999999999,
          "interestingness": 0.45
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.1,
          "interestingness": 0.3500000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4833333333333334,
      "task_completion": 0.19861111111111115,
      "interest_arousal": 0.2347222222222222,
      "efficiency": 0.10277777777777776,
      "dialogue_overall": 1.3874999999999997
    }
  },
  {
    "conv_id": "crbcrs_redial_6569d24b-b2bb-478c-8159-5e1dccfda5df",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.05
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.11250000000000003,
          "interestingness": 0.6124999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.3125000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.16875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6500000000000001,
          "interestingness": 0.8124999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.121875,
      "task_completion": 0.06249999999999999,
      "interest_arousal": 0.19531250000000003,
      "efficiency": 0.0015625,
      "dialogue_overall": 1.0000000000000002
    }
  },
  {
    "conv_id": "kbrd_redial_6569d24b-b2bb-478c-8159-5e1dccfda5df",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.03333333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.14166666666666666,
          "interestingness": 0.6208333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.15000000000000002,
          "interestingness": 0.4750000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.3791666666666667,
          "interestingness": 0.9458333333333333
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.1875,
          "interestingness": 0.46249999999999997
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.515,
          "interestingness": 0.5875
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.13125000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.07960526315789475,
      "task_completion": 0.08026315789473684,
      "interest_arousal": 0.08947368421052632,
      "efficiency": 0.0006578947368421052,
      "dialogue_overall": 1.0368421052631578
    }
  },
  {
    "conv_id": "unicrs_opendialkg_666fdd8e-fca8-40f5-989a-6ffd8b92056d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6625000000000001,
          "interestingness": 0.8450000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5,
          "interestingness": 0.9625000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.13749999999999998,
          "interestingness": 0.775
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.45,
          "interestingness": 0.7416666666666667
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.4375,
          "interestingness": 0.7583333333333335
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.38846153846153847,
      "task_completion": 0.29134615384615387,
      "interest_arousal": 0.2990384615384616,
      "efficiency": 0.10961538461538461,
      "dialogue_overall": 1.3932692307692305
    }
  },
  {
    "conv_id": "unicrs_redial_666fdd8e-fca8-40f5-989a-6ffd8b92056d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2374999999999998,
          "interestingness": 1.1999999999999997
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.9624999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6,
          "interestingness": 0.8666666666666667
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.1625,
          "interestingness": 0.0875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {}
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6624999999999999,
      "task_completion": 0.4020833333333334,
      "interest_arousal": 0.2979166666666666,
      "efficiency": 0.13125,
      "dialogue_overall": 1.4958333333333336
    }
  },
  {
    "conv_id": "barcor_opendialkg_673d0902-c480-4d9f-b334-24d952872372",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.30625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.05625,
          "interestingness": 0.8375000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.12500000000000003
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.13333333333333333,
          "interestingness": 0.11666666666666668
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.24375000000000002,
          "interestingness": 0.6749999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.13522727272727272,
      "task_completion": 0.05454545454545456,
      "interest_arousal": 0.10113636363636362,
      "efficiency": 0.01931818181818182,
      "dialogue_overall": 0.9795454545454544
    }
  },
  {
    "conv_id": "unicrs_opendialkg_67db60a6-f6b3-4791-8d1c-edc5c9fbeb7a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5875,
          "interestingness": 0.30000000000000004
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.37500000000000006,
          "interestingness": 0.8
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.0291666666666668,
          "interestingness": 1.541666666666667
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.45312499999999994,
          "interestingness": 0.8218749999999998
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.30000000000000004,
          "interestingness": 0.45000000000000007
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.125,
          "interestingness": 0.22499999999999998
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.30833333333333335,
      "task_completion": 0.17708333333333334,
      "interest_arousal": 0.32395833333333335,
      "efficiency": 0.052083333333333336,
      "dialogue_overall": 1.303125
    }
  },
  {
    "conv_id": "chatgpt_redial_67db60a6-f6b3-4791-8d1c-edc5c9fbeb7a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.703125,
          "interestingness": 0.7406250000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.50625,
          "interestingness": 1.8499999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.16625,
          "interestingness": 1.2775
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.2249999999999999,
          "interestingness": 1.5499999999999998
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.008333333333333333,
          "interestingness": 0.3708333333333333
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.2625000000000002,
          "interestingness": 0.4666666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8968750000000001,
      "task_completion": 0.4395833333333333,
      "interest_arousal": 0.5958333333333333,
      "efficiency": 0.27187500000000003,
      "dialogue_overall": 1.9276041666666666
    }
  },
  {
    "conv_id": "barcor_redial_6941de78-6019-4941-bb80-b235a08f599c",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.125,
          "interestingness": 0.75
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4041666666666667,
          "interestingness": 0.5291666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.8000000000000002,
          "interestingness": 1.4000000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.31875000000000003,
          "interestingness": 1.05
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5625000000000001,
          "interestingness": 0.6375000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.46093750000000006,
      "task_completion": 0.2796875,
      "interest_arousal": 0.47031249999999997,
      "efficiency": 0.1046875,
      "dialogue_overall": 1.4421874999999997
    }
  },
  {
    "conv_id": "barcor_opendialkg_6941de78-6019-4941-bb80-b235a08f599c",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.19375000000000003,
          "interestingness": 0.5625000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8625000000000002,
          "interestingness": 1.3208333333333335
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6124999999999999,
          "interestingness": 1.15625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8625,
          "interestingness": 1.2458333333333331
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.1791666666666667,
          "interestingness": 1.0458333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3201923076923077,
      "task_completion": 0.27211538461538465,
      "interest_arousal": 0.44230769230769235,
      "efficiency": 0.10576923076923078,
      "dialogue_overall": 1.3884615384615384
    }
  },
  {
    "conv_id": "kbrd_opendialkg_6e99bf1c-df59-4b94-a6e8-3b52c03eb528",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.275
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.22500000000000003,
          "interestingness": 0.8708333333333332
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.020833333333333332,
          "interestingness": 0.16249999999999998
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.4749999999999999,
          "interestingness": 0.6
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.12499999999999999,
          "interestingness": 0.28750000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.13977272727272727,
      "task_completion": 0.1409090909090909,
      "interest_arousal": 0.1590909090909091,
      "efficiency": 0.018181818181818184,
      "dialogue_overall": 1.0613636363636363
    }
  },
  {
    "conv_id": "unicrs_opendialkg_6e99bf1c-df59-4b94-a6e8-3b52c03eb528",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.275,
          "interestingness": 0.4916666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.21875000000000003,
          "interestingness": 0.5000000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.2750000000000001,
          "interestingness": 0.725
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.75,
          "interestingness": 0.8250000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.07083333333333333,
          "interestingness": 0.42916666666666675
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.1,
          "interestingness": 0.46875000000000006
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.24134615384615385,
      "task_completion": 0.12884615384615386,
      "interest_arousal": 0.16346153846153846,
      "efficiency": 0.007692307692307693,
      "dialogue_overall": 1.1759615384615383
    }
  },
  {
    "conv_id": "chatgpt_redial_6efb3c29-2556-4a71-8500-8f78c5c259a3",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0666666666666667,
          "interestingness": 0.8333333333333334
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.19749999999999998,
          "interestingness": 0.73
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.2750000000000001,
          "interestingness": 0.6012500000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.9229166666666667,
          "interestingness": 0.6166666666666667
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6083333333333333,
          "interestingness": 0.5625000000000001
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.08333333333333333
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.024999999999999998,
          "interestingness": 0.05
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6551470588235293,
      "task_completion": 0.43897058823529417,
      "interest_arousal": 0.3485294117647059,
      "efficiency": 0.1889705882352941,
      "dialogue_overall": 1.938602941176471
    }
  },
  {
    "conv_id": "kbrd_opendialkg_6efb3c29-2556-4a71-8500-8f78c5c259a3",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.4625000000000001,
          "interestingness": 0.525
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.25937499999999997,
          "interestingness": 1.1843750000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.037500000000000006
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.010416666666666668,
          "interestingness": 0.25
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.075
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1701923076923077,
      "task_completion": 0.17980769230769234,
      "interest_arousal": 0.15096153846153848,
      "efficiency": 0.037500000000000006,
      "dialogue_overall": 0.994230769230769
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_6f0b70c6-afa3-40e5-997a-273ef7d59ac4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.665,
          "interestingness": 0.4475
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7412500000000002,
          "interestingness": 0.91375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.51875,
          "interestingness": 1.1425
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.3375,
          "interestingness": 0.37500000000000006
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.7833333333333334,
          "interestingness": 0.7583333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.9594827586206897,
      "task_completion": 0.5461206896551725,
      "interest_arousal": 0.3939655172413793,
      "efficiency": 0.2918103448275862,
      "dialogue_overall": 2.340086206896552
    }
  },
  {
    "conv_id": "kbrd_redial_6f0b70c6-afa3-40e5-997a-273ef7d59ac4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0,
          "interestingness": 0.9749999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4375,
          "interestingness": 1.0375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.09166666666666666,
          "interestingness": 0.3166666666666667
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.14375000000000002,
          "interestingness": 0.8875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.13749999999999998,
          "interestingness": 0.3208333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.17625000000000007,
      "task_completion": 0.16625000000000006,
      "interest_arousal": 0.19750000000000004,
      "efficiency": 0.0175,
      "dialogue_overall": 1.11625
    }
  },
  {
    "conv_id": "kbrd_opendialkg_70231783-4e9e-41b7-af50-addb035383d8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.05
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0725,
          "interestingness": 0.7024999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.0875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.04375,
          "interestingness": 0.171875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.03125,
          "interestingness": 0.0875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1730769230769231,
      "task_completion": 0.09134615384615385,
      "interest_arousal": 0.1278846153846154,
      "efficiency": 0.028846153846153848,
      "dialogue_overall": 0.9548076923076922
    }
  },
  {
    "conv_id": "chatgpt_redial_70231783-4e9e-41b7-af50-addb035383d8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.47750000000000004,
          "interestingness": 0.42250000000000004
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.3937499999999998,
          "interestingness": 0.99875
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5387500000000002,
          "interestingness": 0.4375000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.7916666666666666,
          "interestingness": 0.6416666666666666
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.19166666666666668,
          "interestingness": 0.23333333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6278225806451613,
      "task_completion": 0.407258064516129,
      "interest_arousal": 0.2548387096774193,
      "efficiency": 0.17903225806451611,
      "dialogue_overall": 1.8241935483870968
    }
  },
  {
    "conv_id": "barcor_redial_7077b507-58d2-4e48-ac65-4d93fb500570",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2,
          "interestingness": 0.3375000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5041666666666667,
          "interestingness": 0.8125000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.8125,
          "interestingness": 0.3125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.7249999999999999,
          "interestingness": 0.47500000000000003
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.8875,
          "interestingness": 0.5375000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6232142857142858,
      "task_completion": 0.4660714285714285,
      "interest_arousal": 0.1875,
      "efficiency": 0.12321428571428572,
      "dialogue_overall": 1.6875000000000002
    }
  },
  {
    "conv_id": "kbrd_redial_7077b507-58d2-4e48-ac65-4d93fb500570",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2375,
          "interestingness": 0.74375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8875000000000001,
          "interestingness": 0.85
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.1625,
          "interestingness": 0.1875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.23750000000000002,
          "interestingness": 0.39999999999999997
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5062500000000001,
          "interestingness": 0.328125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3409090909090909,
      "task_completion": 0.3534090909090909,
      "interest_arousal": 0.1875,
      "efficiency": 0.044318181818181826,
      "dialogue_overall": 1.2704545454545455
    }
  },
  {
    "conv_id": "barcor_redial_7188b711-d0aa-4d80-9850-2505ed454355",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.3375000000000001,
          "interestingness": 1.1625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7343750000000001,
          "interestingness": 0.5843750000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.7000000000000001,
          "interestingness": 1.0375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.1625,
          "interestingness": 0.7749999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6375,
          "interestingness": 0.7624999999999998
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5725,
      "task_completion": 0.285,
      "interest_arousal": 0.18375000000000005,
      "efficiency": 0.11,
      "dialogue_overall": 1.445
    }
  },
  {
    "conv_id": "unicrs_opendialkg_7188b711-d0aa-4d80-9850-2505ed454355",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.22500000000000003,
          "interestingness": 0.5125000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.16666666666666666,
          "interestingness": 0.35833333333333334
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.2375000000000003,
          "interestingness": 1.3187499999999996
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.8041666666666667,
          "interestingness": 0.8333333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4499999999999999,
      "task_completion": 0.29545454545454547,
      "interest_arousal": 0.32159090909090904,
      "efficiency": 0.08863636363636364,
      "dialogue_overall": 1.125
    }
  },
  {
    "conv_id": "unicrs_redial_72f4ea64-a29b-46f9-8459-a431f71c47eb",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3500000000000001,
          "interestingness": 0.8124999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5041666666666668,
          "interestingness": 0.675
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.23750000000000004,
          "interestingness": 0.63125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.29375,
          "interestingness": 0.6187499999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6708333333333335,
          "interestingness": 0.7375
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.18750000000000003,
          "interestingness": 0.25
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.13916666666666666,
      "task_completion": 0.13416666666666668,
      "interest_arousal": 0.19583333333333336,
      "efficiency": 0.029166666666666664,
      "dialogue_overall": 1.1591666666666667
    }
  },
  {
    "conv_id": "chatgpt_redial_72f4ea64-a29b-46f9-8459-a431f71c47eb",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5437500000000001,
          "interestingness": 0.8
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8875000000000003,
          "interestingness": 1.070833333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.3875,
          "interestingness": 0.9791666666666666
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.7916666666666665,
          "interestingness": 0.8791666666666667
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.42500000000000004,
          "interestingness": 0.38750000000000007
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6765625000000001,
      "task_completion": 0.51484375,
      "interest_arousal": 0.31328124999999996,
      "efficiency": 0.32968749999999997,
      "dialogue_overall": 2.1039062500000005
    }
  },
  {
    "conv_id": "unicrs_redial_764e8de9-d679-4440-b71c-9e4d0d0b1ac2",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.34374999999999994,
          "interestingness": 1.0812499999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.8875
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.9166666666666667,
          "interestingness": 1.05
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.09999999999999999,
          "interestingness": 0.3000000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.0375,
          "interestingness": 0.7583333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.41,
      "task_completion": 0.40875000000000006,
      "interest_arousal": 0.3787500000000001,
      "efficiency": 0.17375000000000002,
      "dialogue_overall": 1.7175
    }
  },
  {
    "conv_id": "barcor_redial_764e8de9-d679-4440-b71c-9e4d0d0b1ac2",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.7250000000000005,
          "interestingness": 1.5250000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9541666666666666,
          "interestingness": 1.2208333333333332
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.30625,
          "interestingness": 0.31250000000000006
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8187500000000001,
          "interestingness": 0.6625
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.19999999999999998,
          "interestingness": 0.28125
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.11249999999999999,
          "interestingness": 0.5249999999999999
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.2875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.47500000000000003,
      "task_completion": 0.4489583333333333,
      "interest_arousal": 0.32812500000000006,
      "efficiency": 0.2,
      "dialogue_overall": 1.6406249999999998
    }
  },
  {
    "conv_id": "barcor_redial_779d469f-548d-4b16-a7dc-f69c26eb2d1e",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.9500000000000002,
          "interestingness": 1.05
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.4958333333333333,
          "interestingness": 1.3874999999999995
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.25625,
          "interestingness": 1.0125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.1874999999999998,
          "interestingness": 1.6437500000000003
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.33749999999999997
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.94875,
      "task_completion": 0.8324999999999999,
      "interest_arousal": 0.75,
      "efficiency": 0.33625,
      "dialogue_overall": 2.21625
    }
  },
  {
    "conv_id": "unicrs_redial_779d469f-548d-4b16-a7dc-f69c26eb2d1e",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.16875000000000004,
          "interestingness": 0.7999999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.2499999999999998,
          "interestingness": 1.4149999999999998
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.9625,
          "interestingness": 0.6749999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {}
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.955,
          "interestingness": 0.4925
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8416666666666666,
      "task_completion": 0.8075,
      "interest_arousal": 0.5941666666666666,
      "efficiency": 0.38583333333333336,
      "dialogue_overall": 2.1958333333333333
    }
  },
  {
    "conv_id": "unicrs_redial_7816e974-b3fc-4f0b-b19e-00ed097ce7cc",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2499999999999998,
          "interestingness": 0.7041666666666666
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.3,
          "interestingness": 0.4625000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.325
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.5750000000000002,
          "interestingness": 1.0
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.275,
          "interestingness": 0.3375
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.975,
          "interestingness": 1.0083333333333333
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.0625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4034090909090909,
      "task_completion": 0.4568181818181818,
      "interest_arousal": 0.2409090909090909,
      "efficiency": 0.125,
      "dialogue_overall": 1.2431818181818182
    }
  },
  {
    "conv_id": "barcor_opendialkg_78ca5dbe-ded4-42c5-af6f-531d1cd62bc2",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.35625000000000007,
          "interestingness": 0.59375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.27083333333333337,
          "interestingness": 0.9
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.275
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.05625,
          "interestingness": 0.16875000000000004
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.13749999999999998
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.05625,
          "interestingness": 0.31875000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2625,
      "task_completion": 0.22946428571428573,
      "interest_arousal": 0.28928571428571437,
      "efficiency": 0.03125000000000001,
      "dialogue_overall": 1.2160714285714285
    }
  },
  {
    "conv_id": "unicrs_redial_78ca5dbe-ded4-42c5-af6f-531d1cd62bc2",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5791666666666666,
          "interestingness": 1.0666666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9916666666666667,
          "interestingness": 0.9874999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.1375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.025,
          "interestingness": 0.9249999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.7999999999999999,
          "interestingness": 1.0125000000000002
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.2,
          "interestingness": 0.5083333333333333
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.44375000000000003,
          "interestingness": 0.4375000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4366071428571428,
      "task_completion": 0.3883928571428571,
      "interest_arousal": 0.3107142857142857,
      "efficiency": 0.19910714285714287,
      "dialogue_overall": 1.6366071428571427
    }
  },
  {
    "conv_id": "kbrd_redial_7a69c19d-a316-4a9e-98d2-56f9d4ea7b32",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.13,
          "interestingness": 0.8574999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7,
          "interestingness": 0.9125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6625,
          "interestingness": 0.48125000000000007
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.6625000000000001,
          "interestingness": 1.0624999999999998
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3,
          "interestingness": 0.4625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4322916666666667,
      "task_completion": 0.5427083333333333,
      "interest_arousal": 0.49583333333333335,
      "efficiency": 0.2770833333333333,
      "dialogue_overall": 1.8614583333333332
    }
  },
  {
    "conv_id": "crbcrs_redial_7a69c19d-a316-4a9e-98d2-56f9d4ea7b32",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.46875000000000006,
          "interestingness": 1.0343750000000003
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7125000000000001,
          "interestingness": 1.09375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.42500000000000004,
          "interestingness": 1.0374999999999996
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.35625,
          "interestingness": 0.6218750000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.05416666666666666,
          "interestingness": 0.4666666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1661764705882353,
      "task_completion": 0.14117647058823532,
      "interest_arousal": 0.28970588235294126,
      "efficiency": 0.014705882352941176,
      "dialogue_overall": 1.3080882352941174
    }
  },
  {
    "conv_id": "kbrd_redial_7bcecb6c-8f73-4c4d-8820-c38c0e122d98",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.3875,
          "interestingness": 0.9
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4625000000000001,
          "interestingness": 1.270833333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05972222222222222,
          "interestingness": 0.13194444444444445
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.1
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.1125,
          "interestingness": 0.1
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.09666666666666668,
      "task_completion": 0.07749999999999999,
      "interest_arousal": 0.08083333333333333,
      "efficiency": 0.016666666666666666,
      "dialogue_overall": 0.8350000000000001
    }
  },
  {
    "conv_id": "unicrs_redial_7bcecb6c-8f73-4c4d-8820-c38c0e122d98",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.075,
          "interestingness": 1.2249999999999996
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.48750000000000004,
          "interestingness": 1.4000000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.2875,
          "interestingness": 1.475
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.12499999999999999,
          "interestingness": 0.5125000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.29583333333333334,
          "interestingness": 0.7208333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6013888888888888,
      "task_completion": 0.5513888888888889,
      "interest_arousal": 0.5097222222222223,
      "efficiency": 0.13333333333333333,
      "dialogue_overall": 1.6680555555555556
    }
  },
  {
    "conv_id": "crbcrs_redial_7f9fe5a0-4562-4a94-93ac-62ee2ad8f88a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.49374999999999997
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8500000000000002,
          "interestingness": 0.98125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.7562500000000001,
          "interestingness": 1.15
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.315625
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.20833333333333334,
          "interestingness": 0.35000000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2740384615384615,
      "task_completion": 0.21634615384615385,
      "interest_arousal": 0.20865384615384616,
      "efficiency": 0.05096153846153846,
      "dialogue_overall": 1.2798076923076922
    }
  },
  {
    "conv_id": "barcor_opendialkg_7f9fe5a0-4562-4a94-93ac-62ee2ad8f88a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.22500000000000003,
          "interestingness": 0.3125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.015625,
          "interestingness": 0.11250000000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.04375,
          "interestingness": 0.8
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.34375,
          "interestingness": 0.5312500000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.04375,
          "interestingness": 0.3875
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.20625000000000004,
          "interestingness": 0.6937500000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.19134615384615386,
      "task_completion": 0.06923076923076923,
      "interest_arousal": 0.10288461538461538,
      "efficiency": 0.004807692307692308,
      "dialogue_overall": 0.9625000000000001
    }
  },
  {
    "conv_id": "chatgpt_redial_80068270-5a9d-4c07-ae2e-1938816336b4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3,
          "interestingness": 0.029166666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.545,
          "interestingness": 0.48750000000000004
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.80875,
          "interestingness": 0.6025000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.909090909090909,
          "interestingness": 0.8295454545454544
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.029166666666666667,
          "interestingness": 0.04583333333333333
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.5833333333333334,
          "interestingness": 0.19583333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6131249999999998,
      "task_completion": 0.516875,
      "interest_arousal": 0.35500000000000004,
      "efficiency": 0.16781250000000003,
      "dialogue_overall": 1.5753125000000003
    }
  },
  {
    "conv_id": "unicrs_redial_80068270-5a9d-4c07-ae2e-1938816336b4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.04375,
          "interestingness": 0.125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0375,
          "interestingness": 0.49583333333333335
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.025
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.04583333333333334,
          "interestingness": 0.10416666666666666
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.15625000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.010416666666666666,
      "task_completion": 0.013541666666666667,
      "interest_arousal": 0.009375,
      "efficiency": 0.0,
      "dialogue_overall": 0.6302083333333333
    }
  },
  {
    "conv_id": "kbrd_opendialkg_84012567-adfd-4a34-84b3-87b344a97e2d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.05625000000000001,
          "interestingness": 0.48125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.05416666666666667,
          "interestingness": 0.5625000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.037500000000000006
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.009375000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6499999999999999,
          "interestingness": 0.775
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.725,
          "interestingness": 0.8291666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.06759259259259259,
      "task_completion": 0.04166666666666668,
      "interest_arousal": 0.060185185185185196,
      "efficiency": 0.007407407407407408,
      "dialogue_overall": 0.5962962962962962
    }
  },
  {
    "conv_id": "barcor_opendialkg_84012567-adfd-4a34-84b3-87b344a97e2d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6124999999999999,
          "interestingness": 0.9187500000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.43749999999999994,
          "interestingness": 0.31249999999999994
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.10833333333333332,
          "interestingness": 0.425
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.45624999999999993,
          "interestingness": 1.13125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.49374999999999997,
          "interestingness": 0.18750000000000006
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3011363636363636,
      "task_completion": 0.1511363636363636,
      "interest_arousal": 0.28181818181818186,
      "efficiency": 0.040909090909090916,
      "dialogue_overall": 1.1363636363636362
    }
  },
  {
    "conv_id": "barcor_redial_8a6940c8-7f17-4246-af76-8700a40c92af",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.4250000000000003,
          "interestingness": 1.1499999999999997
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.3375000000000001,
          "interestingness": 1.7875
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.8083333333333333,
          "interestingness": 0.8875000000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.4708333333333333,
          "interestingness": 0.6458333333333335
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.4
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.15000000000000002
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6,
      "task_completion": 0.38977272727272727,
      "interest_arousal": 0.3397727272727272,
      "efficiency": 0.1534090909090909,
      "dialogue_overall": 1.5988636363636364
    }
  },
  {
    "conv_id": "chatgpt_redial_8c19cc33-9d7f-4a25-a8eb-88c4f7e209b8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9175,
          "interestingness": 0.8200000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.32375,
          "interestingness": 1.2312499999999997
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.4412500000000001,
          "interestingness": 0.15875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.0,
          "interestingness": 1.6625
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.003125,
          "interestingness": 0.028124999999999997
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.17916666666666667,
          "interestingness": 0.09583333333333333
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.3875,
          "interestingness": 0.31250000000000006
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6024305555555556,
      "task_completion": 0.24548611111111113,
      "interest_arousal": 0.3052083333333334,
      "efficiency": 0.1940972222222222,
      "dialogue_overall": 1.7357638888888889
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_8c19cc33-9d7f-4a25-a8eb-88c4f7e209b8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.29166666666666674,
          "interestingness": 0.31666666666666665
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.12500000000000003
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6250000000000001,
          "interestingness": 1.1124999999999998
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.0068181818181818,
          "interestingness": 0.969318181818182
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.775,
          "interestingness": 1.825
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.85,
          "interestingness": 1.128125
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.325,
          "interestingness": 0.3875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6019999999999999,
      "task_completion": 0.3845000000000001,
      "interest_arousal": 0.3515000000000001,
      "efficiency": 0.11950000000000001,
      "dialogue_overall": 1.7914999999999999
    }
  },
  {
    "conv_id": "unicrs_redial_8cbdbc9d-33b3-4b81-9f8e-1aad1d902117",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.60625,
          "interestingness": 0.4124999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9166666666666667,
          "interestingness": 0.6166666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.09999999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {}
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.2124999999999997,
          "interestingness": 0.7916666666666666
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2569444444444445,
      "task_completion": 0.1652777777777778,
      "interest_arousal": 0.1625,
      "efficiency": 0.004166666666666667,
      "dialogue_overall": 0.9902777777777778
    }
  },
  {
    "conv_id": "crbcrs_redial_8cbdbc9d-33b3-4b81-9f8e-1aad1d902117",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.409375,
          "interestingness": 0.840625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6124999999999999,
          "interestingness": 1.0291666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.11875000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.15000000000000002,
          "interestingness": 0.27499999999999997
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.21250000000000002,
          "interestingness": 0.6812499999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.234375,
      "task_completion": 0.17395833333333333,
      "interest_arousal": 0.26979166666666665,
      "efficiency": 0.05104166666666667,
      "dialogue_overall": 1.1458333333333333
    }
  },
  {
    "conv_id": "barcor_redial_8f87e94f-8b0f-4e8a-9034-bb79f172c0bd",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.09999999999999999,
          "interestingness": 0.3291666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.037500000000000006
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.037500000000000006
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.08392857142857142,
      "task_completion": 0.03214285714285715,
      "interest_arousal": 0.06785714285714285,
      "efficiency": 0.0071428571428571435,
      "dialogue_overall": 0.880357142857143
    }
  },
  {
    "conv_id": "unicrs_opendialkg_8f87e94f-8b0f-4e8a-9034-bb79f172c0bd",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.1625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.18125,
          "interestingness": 0.11875000000000004
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.925,
          "interestingness": 0.525
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.05
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3583333333333333,
          "interestingness": 0.35833333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.24125000000000002,
      "task_completion": 0.17500000000000007,
      "interest_arousal": 0.19375000000000006,
      "efficiency": 0.0325,
      "dialogue_overall": 0.98125
    }
  },
  {
    "conv_id": "barcor_opendialkg_90c8aff4-30a2-422b-9820-456585d2e6e0",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.10833333333333332,
          "interestingness": 0.43333333333333335
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8,
          "interestingness": 1.175
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.7187500000000001,
          "interestingness": 1.04375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.03125,
          "interestingness": 0.08750000000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5375000000000001,
          "interestingness": 0.7875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2895833333333333,
      "task_completion": 0.21458333333333335,
      "interest_arousal": 0.2770833333333334,
      "efficiency": 0.08750000000000001,
      "dialogue_overall": 1.4218749999999998
    }
  },
  {
    "conv_id": "kbrd_opendialkg_90c8aff4-30a2-422b-9820-456585d2e6e0",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.1125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.3583333333333334,
          "interestingness": 0.5791666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.04375
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0375,
          "interestingness": 0.2833333333333333
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.06562500000000002,
          "interestingness": 0.521875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2107142857142857,
      "task_completion": 0.10089285714285713,
      "interest_arousal": 0.15535714285714286,
      "efficiency": 0.05267857142857143,
      "dialogue_overall": 0.9803571428571427
    }
  },
  {
    "conv_id": "barcor_redial_936abb41-428a-4327-a7e1-9d6c5ceae7ec",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5499999999999999,
          "interestingness": 0.81875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.925,
          "interestingness": 1.215625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.175
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.10750000000000003,
          "interestingness": 0.22500000000000006
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.1625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.38557692307692304,
      "task_completion": 0.3211538461538461,
      "interest_arousal": 0.31249999999999994,
      "efficiency": 0.1730769230769231,
      "dialogue_overall": 1.6480769230769232
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_936abb41-428a-4327-a7e1-9d6c5ceae7ec",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.07500000000000001,
          "interestingness": 0.35624999999999996
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.00625,
          "interestingness": 0.765
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6511363636363636,
          "interestingness": 0.7397727272727274
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.9343750000000002,
          "interestingness": 0.6375000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.05312500000000001,
          "interestingness": 0.45312499999999994
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6795454545454546,
      "task_completion": 0.5359848484848484,
      "interest_arousal": 0.39886363636363636,
      "efficiency": 0.225,
      "dialogue_overall": 2.35189393939394
    }
  },
  {
    "conv_id": "chatgpt_redial_9a71ff00-72eb-4716-a49b-f591ecae0f88",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2774999999999999,
          "interestingness": 0.5325
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.05357142857142858,
          "interestingness": 0.4642857142857143
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6825000000000001,
          "interestingness": 0.6412500000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.5375,
          "interestingness": 0.31625000000000003
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.18333333333333338,
          "interestingness": 0.3916666666666667
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.1291666666666664,
          "interestingness": 0.8124999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.0832236842105263,
      "task_completion": 0.8358552631578948,
      "interest_arousal": 0.7203947368421052,
      "efficiency": 0.35164473684210523,
      "dialogue_overall": 2.4124999999999996
    }
  },
  {
    "conv_id": "barcor_opendialkg_9a71ff00-72eb-4716-a49b-f591ecae0f88",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9375000000000001,
          "interestingness": 0.625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.25,
          "interestingness": 0.6666666666666665
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.11249999999999999,
          "interestingness": 0.5125000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.07916666666666666,
          "interestingness": 0.2791666666666667
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.08125,
          "interestingness": 0.35
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.59375,
      "task_completion": 0.49624999999999997,
      "interest_arousal": 0.49500000000000005,
      "efficiency": 0.21874999999999997,
      "dialogue_overall": 1.6525
    }
  },
  {
    "conv_id": "kbrd_redial_9c0cd453-157f-4fe1-a7e2-177ec2ce5792",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.1249999999999998,
          "interestingness": 1.1249999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.22812500000000002,
          "interestingness": 0.037500000000000006
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.275
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.04375,
          "interestingness": 0.22500000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.07083333333333333,
      "task_completion": 0.0125,
      "interest_arousal": 0.052777777777777785,
      "efficiency": 0.026388888888888885,
      "dialogue_overall": 0.9958333333333333
    }
  },
  {
    "conv_id": "kbrd_opendialkg_9c0cd453-157f-4fe1-a7e2-177ec2ce5792",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.09999999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.39687500000000003,
          "interestingness": 0.5437499999999998
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.30000000000000004
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.08125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.09250000000000001,
          "interestingness": 0.14500000000000002
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.08365384615384616,
      "task_completion": 0.06634615384615383,
      "interest_arousal": 0.09903846153846153,
      "efficiency": 0.004807692307692308,
      "dialogue_overall": 0.8250000000000001
    }
  },
  {
    "conv_id": "barcor_redial_9db35768-b230-4d1c-a40e-a9192efc54c2",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.94375,
          "interestingness": 1.175
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.2449999999999999,
          "interestingness": 0.9749999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.4675,
          "interestingness": 0.8099999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.6124999999999999,
          "interestingness": 0.7124999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.21875,
          "interestingness": 1.1749999999999998
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.6000000000000001,
          "interestingness": 0.7874999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5171874999999999,
      "task_completion": 0.5046875,
      "interest_arousal": 0.6382812500000001,
      "efficiency": 0.18906250000000002,
      "dialogue_overall": 1.8546874999999998
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_9db35768-b230-4d1c-a40e-a9192efc54c2",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6041666666666666,
          "interestingness": 0.5999999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.50625,
          "interestingness": 1.2000000000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.55375,
          "interestingness": 0.8150000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.0666666666666667,
          "interestingness": 0.8791666666666668
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.8250000000000001,
          "interestingness": 1.09375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5931249999999999,
      "task_completion": 0.52375,
      "interest_arousal": 0.44,
      "efficiency": 0.13875,
      "dialogue_overall": 1.9087500000000002
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_9e3e01c7-e2f6-4479-ae3d-95e7dbcc9d70",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.029166666666666667,
          "interestingness": 0.008333333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.2166666666666663,
          "interestingness": 1.4375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.5954545454545457,
          "interestingness": 0.9329545454545456
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.364285714285714,
          "interestingness": 1.2214285714285713
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.6656250000000001,
          "interestingness": 1.5781249999999998
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.08333333333333333,
          "interestingness": 0.2125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8362903225806452,
      "task_completion": 0.7310483870967741,
      "interest_arousal": 0.4508064516129033,
      "efficiency": 0.2346774193548387,
      "dialogue_overall": 2.1814516129032255
    }
  },
  {
    "conv_id": "unicrs_redial_9e3e01c7-e2f6-4479-ae3d-95e7dbcc9d70",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.13749999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.04583333333333333,
          "interestingness": 0.5791666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.425,
          "interestingness": 0.7125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.3875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5875,
          "interestingness": 0.4625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.12857142857142856,
      "task_completion": 0.08928571428571429,
      "interest_arousal": 0.11964285714285715,
      "efficiency": 0.008928571428571428,
      "dialogue_overall": 1.0107142857142857
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_9e76ec41-12a3-42a1-95e6-9fc1a587f980",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {}
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.21375,
          "interestingness": 0.2325
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.1512499999999999,
          "interestingness": 0.9587500000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.335,
          "interestingness": 0.24375000000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.0374999999999999,
          "interestingness": 1.3499999999999999
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.024999999999999998,
          "interestingness": 0.075
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.06249999999999999,
          "interestingness": 0.3791666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4560897435897437,
      "task_completion": 0.1923076923076923,
      "interest_arousal": 0.2692307692307693,
      "efficiency": 0.04487179487179488,
      "dialogue_overall": 1.5221153846153845
    }
  },
  {
    "conv_id": "barcor_opendialkg_9e76ec41-12a3-42a1-95e6-9fc1a587f980",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.37083333333333335
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.018750000000000003,
          "interestingness": 0.11875000000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.15833333333333333,
          "interestingness": 0.41666666666666663
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.39999999999999997,
          "interestingness": 0.43125000000000013
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.40416666666666673,
          "interestingness": 0.4875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.15096153846153848,
      "task_completion": 0.09711538461538462,
      "interest_arousal": 0.09807692307692308,
      "efficiency": 0.0028846153846153848,
      "dialogue_overall": 0.7288461538461538
    }
  },
  {
    "conv_id": "barcor_opendialkg_9fff722c-29d6-4a02-934e-f2e311214bcc",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7104166666666666,
          "interestingness": 0.6145833333333335
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.13437500000000002,
          "interestingness": 0.5
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.11250000000000002,
          "interestingness": 0.46
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.18125,
          "interestingness": 0.8999999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.30625,
          "interestingness": 0.6562500000000002
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4269736842105264,
      "task_completion": 0.3723684210526316,
      "interest_arousal": 0.33815789473684216,
      "efficiency": 0.08355263157894738,
      "dialogue_overall": 1.530263157894737
    }
  },
  {
    "conv_id": "kbrd_opendialkg_9fff722c-29d6-4a02-934e-f2e311214bcc",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.1625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.18000000000000005,
          "interestingness": 0.49500000000000005
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.0875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.008333333333333333,
          "interestingness": 0.024999999999999998
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.0125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.13229166666666667,
      "task_completion": 0.06770833333333334,
      "interest_arousal": 0.10520833333333336,
      "efficiency": 0.03333333333333333,
      "dialogue_overall": 0.9083333333333333
    }
  },
  {
    "conv_id": "unicrs_redial_a1b1f517-bfd5-40bb-ab3d-35ddcb313a20",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.23750000000000007,
          "interestingness": 0.7
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.049999999999999996,
          "interestingness": 0.43333333333333335
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.0875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.2125000000000001,
          "interestingness": 0.5625
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.9125,
          "interestingness": 0.35000000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.20714285714285718,
      "task_completion": 0.1875,
      "interest_arousal": 0.1982142857142857,
      "efficiency": 0.0125,
      "dialogue_overall": 0.9428571428571428
    }
  },
  {
    "conv_id": "barcor_redial_a1b1f517-bfd5-40bb-ab3d-35ddcb313a20",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7875,
          "interestingness": 1.0875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6593750000000002,
          "interestingness": 0.659375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.625,
          "interestingness": 1.2625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.9062499999999998,
          "interestingness": 1.73125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.1,
          "interestingness": 0.25
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.755,
      "task_completion": 0.92375,
      "interest_arousal": 0.6612500000000001,
      "efficiency": 0.29625,
      "dialogue_overall": 2.4625000000000004
    }
  },
  {
    "conv_id": "kbrd_opendialkg_a1b5343d-06f9-4ed1-b03d-66cd00474fad",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.15,
          "interestingness": 0.775
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.10833333333333332,
          "interestingness": 0.5
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.2625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.26875,
          "interestingness": 0.5125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.029166666666666664,
          "interestingness": 0.32499999999999996
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.08750000000000002,
      "task_completion": 0.061250000000000006,
      "interest_arousal": 0.10000000000000003,
      "efficiency": 0.0,
      "dialogue_overall": 0.7537499999999999
    }
  },
  {
    "conv_id": "unicrs_opendialkg_a1b5343d-06f9-4ed1-b03d-66cd00474fad",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9958333333333331,
          "interestingness": 0.8208333333333334
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.1875,
          "interestingness": 0.5249999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5375,
          "interestingness": 0.74375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.24166666666666667,
          "interestingness": 0.3125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3625,
          "interestingness": 0.8125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3943181818181818,
      "task_completion": 0.34659090909090906,
      "interest_arousal": 0.3113636363636364,
      "efficiency": 0.14204545454545453,
      "dialogue_overall": 1.3397727272727271
    }
  },
  {
    "conv_id": "crbcrs_redial_a3a4035d-b93f-42ff-a1ee-1758215208b4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.8750000000000001,
          "interestingness": 1.1375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.7875
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.08437500000000002,
          "interestingness": 0.45
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8166666666666669,
          "interestingness": 1.2416666666666665
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.1,
          "interestingness": 0.6458333333333334
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.28750000000000003,
          "interestingness": 0.7791666666666668
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3375,
      "task_completion": 0.30234375,
      "interest_arousal": 0.340625,
      "efficiency": 0.08984375000000001,
      "dialogue_overall": 1.4695312499999995
    }
  },
  {
    "conv_id": "barcor_redial_a3a4035d-b93f-42ff-a1ee-1758215208b4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.1750000000000003,
          "interestingness": 1.1874999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8458333333333334,
          "interestingness": 1.05
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.66875,
          "interestingness": 0.65
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.1625,
          "interestingness": 0.28750000000000003
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.38749999999999996,
          "interestingness": 0.8374999999999999
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.2750000000000001,
          "interestingness": 0.42500000000000004
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3638888888888888,
      "task_completion": 0.3402777777777778,
      "interest_arousal": 0.34027777777777773,
      "efficiency": 0.12638888888888888,
      "dialogue_overall": 1.3569444444444445
    }
  },
  {
    "conv_id": "barcor_redial_a40ccbfb-a9ab-46f5-9f1e-d3d48d475161",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2499999999999998,
          "interestingness": 1.0625
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9949999999999999,
          "interestingness": 0.37500000000000006
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.8250000000000001,
          "interestingness": 0.9375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.15000000000000002,
          "interestingness": 0.5
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.675,
          "interestingness": 0.5625
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.275,
          "interestingness": 0.1125
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.3875,
          "interestingness": 0.5875000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.7636363636363636,
      "task_completion": 0.47045454545454557,
      "interest_arousal": 0.2125,
      "efficiency": 0.19090909090909092,
      "dialogue_overall": 1.4920454545454545
    }
  },
  {
    "conv_id": "kbrd_redial_a40ccbfb-a9ab-46f5-9f1e-d3d48d475161",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.35,
          "interestingness": 1.2875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7291666666666666,
          "interestingness": 0.2041666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.28125000000000006,
          "interestingness": 1.1875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.15000000000000002,
          "interestingness": 0.75
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.060000000000000005,
          "interestingness": 0.46749999999999997
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.178125,
          "interestingness": 0.4375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2144736842105263,
      "task_completion": 0.16710526315789476,
      "interest_arousal": 0.12697368421052632,
      "efficiency": 0.08552631578947369,
      "dialogue_overall": 1.0046052631578948
    }
  },
  {
    "conv_id": "barcor_redial_a61ac294-3f5e-4b6a-892d-dbe1a8414e1a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.9375,
          "interestingness": 1.7500000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.4375,
          "interestingness": 1.3375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.09687500000000002,
          "interestingness": 0.26875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.3625,
          "interestingness": 0.8500000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.2625,
          "interestingness": 0.8
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.5499999999999999
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.06875,
          "interestingness": 0.44375000000000003
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.15
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.05
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4269230769230769,
      "task_completion": 0.3778846153846155,
      "interest_arousal": 0.43653846153846165,
      "efficiency": 0.19711538461538464,
      "dialogue_overall": 1.621153846153846
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_a61ac294-3f5e-4b6a-892d-dbe1a8414e1a",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.3041666666666665,
          "interestingness": 1.1124999999999998
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.0458333333333332,
          "interestingness": 0.4416666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.11666666666666665,
          "interestingness": 0.3916666666666667
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.475,
          "interestingness": 1.61875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.38,
          "interestingness": 0.4475
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.89375,
          "interestingness": 0.9375000000000001
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.10833333333333334,
          "interestingness": 0.5791666666666666
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.5166666666666666,
          "interestingness": 0.8500000000000001
        }
      },
      {
        "turn_ind": 17,
        "turn_level_pred": {
          "relevance": 0.19583333333333333,
          "interestingness": 0.11249999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6779411764705882,
      "task_completion": 0.5716911764705882,
      "interest_arousal": 0.36727941176470585,
      "efficiency": 0.10367647058823529,
      "dialogue_overall": 1.8768382352941175
    }
  },
  {
    "conv_id": "crbcrs_redial_a75606ed-700b-40a5-9b17-a5d51e691c36",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5999999999999999,
          "interestingness": 1.075
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6275000000000001,
          "interestingness": 0.7400000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.16562500000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.17500000000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.3500000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3740384615384616,
      "task_completion": 0.20096153846153847,
      "interest_arousal": 0.21826923076923077,
      "efficiency": 0.09326923076923076,
      "dialogue_overall": 1.4278846153846156
    }
  },
  {
    "conv_id": "chatgpt_redial_a75606ed-700b-40a5-9b17-a5d51e691c36",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.49500000000000016
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6987500000000001,
          "interestingness": 0.51
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.1437500000000003,
          "interestingness": 1.4937500000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.0468749999999998,
          "interestingness": 0.9458333333333333
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.0375
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.1833333333333333,
          "interestingness": 0.6583333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.7378571428571429,
      "task_completion": 0.4957142857142858,
      "interest_arousal": 0.45499999999999996,
      "efficiency": 0.3225,
      "dialogue_overall": 2.043214285714286
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_aa4e6c42-af03-401a-bf78-133777cf7841",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.333333333333333,
          "interestingness": 0.7625000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8562500000000002,
          "interestingness": 0.42187499999999994
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.49125,
          "interestingness": 0.565
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.49375,
          "interestingness": 0.09624999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.4875000000000003,
          "interestingness": 0.93125
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.20833333333333337,
          "interestingness": 0.28750000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6179687500000001,
      "task_completion": 0.34492187500000004,
      "interest_arousal": 0.23632812500000003,
      "efficiency": 0.07734375000000002,
      "dialogue_overall": 1.4246093750000002
    }
  },
  {
    "conv_id": "kbrd_redial_aa4e6c42-af03-401a-bf78-133777cf7841",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.0375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.1916666666666667,
          "interestingness": 0.2875000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.18750000000000003,
          "interestingness": 0.3968749999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.008333333333333333,
          "interestingness": 0.08333333333333333
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.05
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0025,
          "interestingness": 0.0375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.040277777777777767,
      "task_completion": 0.029861111111111113,
      "interest_arousal": 0.034722222222222224,
      "efficiency": 0.0,
      "dialogue_overall": 0.7805555555555557
    }
  },
  {
    "conv_id": "barcor_opendialkg_ac78cfb6-a9c0-456a-ab1e-962e51a8e60b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7312499999999998,
          "interestingness": 0.69375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6,
          "interestingness": 0.4625000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.38749999999999996,
          "interestingness": 1.0
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.15,
          "interestingness": 0.3375000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5375,
          "interestingness": 1.1375000000000002
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.5125,
          "interestingness": 1.1125
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.8687500000000001,
          "interestingness": 0.9249999999999998
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3920454545454546,
      "task_completion": 0.334090909090909,
      "interest_arousal": 0.4477272727272727,
      "efficiency": 0.07045454545454546,
      "dialogue_overall": 1.4465909090909088
    }
  },
  {
    "conv_id": "unicrs_redial_ac78cfb6-a9c0-456a-ab1e-962e51a8e60b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.18750000000000003
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9375,
          "interestingness": 0.7375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.2375,
          "interestingness": 0.25000000000000006
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.43125,
          "interestingness": 0.65
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3583333333333334,
          "interestingness": 0.425
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.3375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3159090909090909,
      "task_completion": 0.29886363636363633,
      "interest_arousal": 0.29090909090909084,
      "efficiency": 0.1488636363636364,
      "dialogue_overall": 1.3920454545454546
    }
  },
  {
    "conv_id": "crbcrs_redial_ae53dc9d-5817-4b12-801a-be241f3bc2d3",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.5062500000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.13125000000000003,
          "interestingness": 1.00625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.4875,
          "interestingness": 0.8875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.04375,
          "interestingness": 0.19375000000000006
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.1375
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.2,
          "interestingness": 0.4
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.05681818181818183,
      "task_completion": 0.012500000000000002,
      "interest_arousal": 0.0840909090909091,
      "efficiency": 0.0,
      "dialogue_overall": 0.509090909090909
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_ae53dc9d-5817-4b12-801a-be241f3bc2d3",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.2375,
          "interestingness": 0.041666666666666664
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.29000000000000004,
          "interestingness": 0.4175
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {}
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.36250000000000004,
          "interestingness": 1.2999999999999998
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6725,
          "interestingness": 0.8949999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4453947368421053,
      "task_completion": 0.1723684210526316,
      "interest_arousal": 0.23881578947368418,
      "efficiency": 0.03026315789473684,
      "dialogue_overall": 1.4217105263157894
    }
  },
  {
    "conv_id": "crbcrs_redial_b016ffa6-d3b3-47d9-9fad-ee8b3a7682e1",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.016666666666666666,
          "interestingness": 0.6458333333333334
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.1625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.29374999999999996,
          "interestingness": 0.8125000000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.06875,
          "interestingness": 0.45625
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.028124999999999997,
          "interestingness": 0.24375000000000005
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.039285714285714285,
      "task_completion": 0.02678571428571429,
      "interest_arousal": 0.05982142857142857,
      "efficiency": 0.04196428571428571,
      "dialogue_overall": 0.942857142857143
    }
  },
  {
    "conv_id": "kbrd_redial_b016ffa6-d3b3-47d9-9fad-ee8b3a7682e1",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.7125000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.17500000000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.11875000000000001,
          "interestingness": 0.290625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.2
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.3625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.07045454545454546,
      "task_completion": 0.11363636363636365,
      "interest_arousal": 0.09772727272727272,
      "efficiency": 0.011363636363636366,
      "dialogue_overall": 1.094318181818182
    }
  },
  {
    "conv_id": "barcor_opendialkg_b3ccf30b-f7fb-4f38-8b38-631c2ef232f6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.40625,
          "interestingness": 0.325
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.38749999999999996,
          "interestingness": 0.45
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.7625,
          "interestingness": 0.41875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.38750000000000007,
          "interestingness": 0.24375000000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6624999999999999,
          "interestingness": 0.27499999999999997
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.35000000000000003,
      "task_completion": 0.18522727272727274,
      "interest_arousal": 0.1590909090909091,
      "efficiency": 0.010227272727272729,
      "dialogue_overall": 1.002272727272727
    }
  },
  {
    "conv_id": "unicrs_opendialkg_b3ccf30b-f7fb-4f38-8b38-631c2ef232f6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.53125,
          "interestingness": 0.38125000000000003
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.2500000000000001,
          "interestingness": 0.1625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.7625000000000001,
          "interestingness": 0.6124999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.375
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.14166666666666666,
          "interestingness": 0.6208333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.25625000000000003,
      "task_completion": 0.1921875,
      "interest_arousal": 0.31249999999999994,
      "efficiency": 0.018750000000000003,
      "dialogue_overall": 0.9734375
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_b4ab3e8d-5404-4bfd-b227-c3aed54dd4d3",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0541666666666667,
          "interestingness": 0.7
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9812499999999998,
          "interestingness": 1.6187500000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.37625,
          "interestingness": 0.99625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.20937499999999998,
          "interestingness": 0.8343750000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.2249999999999999,
          "interestingness": 0.9180555555555556
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.9433035714285715,
      "task_completion": 0.6705357142857143,
      "interest_arousal": 0.6178571428571429,
      "efficiency": 0.2352678571428572,
      "dialogue_overall": 2.304017857142857
    }
  },
  {
    "conv_id": "barcor_redial_b4ab3e8d-5404-4bfd-b227-c3aed54dd4d3",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.225,
          "interestingness": 1.0375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.8375000000000004,
          "interestingness": 1.6833333333333338
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.325,
          "interestingness": 0.45
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.7625,
          "interestingness": 1.1812500000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.2125,
          "interestingness": 0.925
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8250000000000001,
      "task_completion": 0.584375,
      "interest_arousal": 0.4578125000000001,
      "efficiency": 0.37187499999999996,
      "dialogue_overall": 1.9796875
    }
  },
  {
    "conv_id": "barcor_opendialkg_b601c678-da6f-4226-922f-daa35f8afe1b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5499999999999999,
          "interestingness": 0.94375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9666666666666667,
          "interestingness": 0.9666666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.49166666666666664,
          "interestingness": 0.49166666666666664
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8625,
          "interestingness": 0.8624999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.30625,
          "interestingness": 0.70625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2636363636363636,
      "task_completion": 0.21477272727272723,
      "interest_arousal": 0.22386363636363638,
      "efficiency": 0.06363636363636364,
      "dialogue_overall": 1.4625
    }
  },
  {
    "conv_id": "crbcrs_redial_b601c678-da6f-4226-922f-daa35f8afe1b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.5250000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5333333333333333,
          "interestingness": 1.1749999999999998
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6833333333333332,
          "interestingness": 1.05
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.36250000000000004,
          "interestingness": 0.8333333333333335
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.08333333333333333,
          "interestingness": 1.0416666666666665
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.16250000000000003,
      "task_completion": 0.20625000000000002,
      "interest_arousal": 0.1928571428571429,
      "efficiency": 0.09285714285714286,
      "dialogue_overall": 1.29375
    }
  },
  {
    "conv_id": "unicrs_redial_bb4b4e12-0c35-427b-a4b9-65f3aa6188e9",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.22500000000000003
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4650000000000001,
          "interestingness": 0.7324999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5125,
          "interestingness": 0.6125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.0125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.03125,
          "interestingness": 0.16875000000000007
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.495,
      "task_completion": 0.535,
      "interest_arousal": 0.43250000000000005,
      "efficiency": 0.31875,
      "dialogue_overall": 1.62875
    }
  },
  {
    "conv_id": "kbrd_redial_bb4b4e12-0c35-427b-a4b9-65f3aa6188e9",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.875,
          "interestingness": 0.5437500000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.525,
          "interestingness": 0.6593750000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.21250000000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.11875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4284090909090909,
      "task_completion": 0.27386363636363636,
      "interest_arousal": 0.20909090909090913,
      "efficiency": 0.12613636363636366,
      "dialogue_overall": 1.3943181818181816
    }
  },
  {
    "conv_id": "kbrd_redial_bd9abd71-02e4-4bd3-aa79-748c3144f455",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.09375,
          "interestingness": 0.6
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.8750000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.04583333333333333,
          "interestingness": 0.2041666666666667
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.15416666666666665,
          "interestingness": 0.6291666666666667
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.04583333333333333,
          "interestingness": 0.6083333333333333
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.1625
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.04583333333333334,
          "interestingness": 0.12083333333333332
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.1125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.14191176470588235,
      "task_completion": 0.15073529411764705,
      "interest_arousal": 0.05661764705882355,
      "efficiency": 0.0007352941176470588,
      "dialogue_overall": 0.9426470588235296
    }
  },
  {
    "conv_id": "barcor_opendialkg_bd9abd71-02e4-4bd3-aa79-748c3144f455",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.015625,
          "interestingness": 0.34687500000000004
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4208333333333334,
          "interestingness": 1.4624999999999997
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.44583333333333336,
          "interestingness": 0.24999999999999997
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.004166666666666667,
          "interestingness": 0.12083333333333333
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3375,
          "interestingness": 0.4625
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.5375,
          "interestingness": 0.5083333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.12430555555555554,
      "task_completion": 0.034722222222222224,
      "interest_arousal": 0.08194444444444443,
      "efficiency": 0.002777777777777778,
      "dialogue_overall": 0.7895833333333334
    }
  },
  {
    "conv_id": "unicrs_redial_c2ecc39b-b40c-4ebf-a291-368fb066468e",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.225,
          "interestingness": 1.1999999999999997
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.4916666666666667,
          "interestingness": 0.5833333333333334
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.671875,
          "interestingness": 0.975
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.5562499999999999,
          "interestingness": 0.5125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.05,
          "interestingness": 0.7875000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6522727272727272,
      "task_completion": 0.4522727272727274,
      "interest_arousal": 0.4034090909090909,
      "efficiency": 0.33636363636363636,
      "dialogue_overall": 2.0568181818181817
    }
  },
  {
    "conv_id": "kbrd_redial_c2ecc39b-b40c-4ebf-a291-368fb066468e",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5531249999999999,
          "interestingness": 0.609375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.125,
          "interestingness": 0.5875
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.7625000000000002,
          "interestingness": 0.675
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.1,
          "interestingness": 0.3125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.0625,
          "interestingness": 0.9249999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.37187499999999996,
      "task_completion": 0.3489583333333334,
      "interest_arousal": 0.2697916666666667,
      "efficiency": 0.078125,
      "dialogue_overall": 1.4083333333333334
    }
  },
  {
    "conv_id": "unicrs_opendialkg_c33bfb9a-5e87-4a55-91e2-625ca903c4d4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.18750000000000003,
          "interestingness": 0.41250000000000003
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5750000000000001,
          "interestingness": 0.8500000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.12500000000000003
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.0708333333333333,
          "interestingness": 1.0166666666666664
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5125,
          "interestingness": 0.625
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.23750000000000002,
          "interestingness": 0.11249999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4208333333333333,
      "task_completion": 0.30000000000000004,
      "interest_arousal": 0.2555555555555556,
      "efficiency": 0.0625,
      "dialogue_overall": 1.3888888888888888
    }
  },
  {
    "conv_id": "chatgpt_redial_c33f6f45-6a99-415e-b428-efb43ee66f06",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.2708333333333333,
          "interestingness": 0.15000000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7862500000000001,
          "interestingness": 0.6649999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.14125000000000004,
          "interestingness": 0.25125000000000003
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.30875,
          "interestingness": 0.18000000000000005
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.2874999999999996,
          "interestingness": 0.3500000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.0295138888888888,
      "task_completion": 0.7357638888888891,
      "interest_arousal": 0.6763888888888889,
      "efficiency": 0.3253472222222223,
      "dialogue_overall": 2.3975694444444446
    }
  },
  {
    "conv_id": "kbrd_opendialkg_c33f6f45-6a99-415e-b428-efb43ee66f06",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.05
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.016666666666666666,
          "interestingness": 0.058333333333333334
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.018750000000000003,
          "interestingness": 0.16875000000000004
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.17500000000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0375,
          "interestingness": 0.4833333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.09270833333333334,
      "task_completion": 0.04479166666666668,
      "interest_arousal": 0.11979166666666666,
      "efficiency": 0.003125,
      "dialogue_overall": 0.8541666666666666
    }
  },
  {
    "conv_id": "chatgpt_redial_c5203936-eb32-448e-acdb-cd3a75c75751",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6000000000000001,
          "interestingness": 0.4375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.4587500000000002,
          "interestingness": 1.0825
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.135,
          "interestingness": 0.23750000000000004
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.6787500000000001,
          "interestingness": 0.7575000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.0166666666666666,
          "interestingness": 0.8875000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8621527777777779,
      "task_completion": 0.5670138888888889,
      "interest_arousal": 0.4548611111111111,
      "efficiency": 0.27326388888888886,
      "dialogue_overall": 2.267013888888889
    }
  },
  {
    "conv_id": "crbcrs_redial_c8f99970-736d-4770-b17a-4b24818ac6f7",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.020833333333333332,
          "interestingness": 0.39583333333333337
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.3166666666666669,
          "interestingness": 1.0875
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.020833333333333332,
          "interestingness": 0.2625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.39999999999999997
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3125000000000001,
          "interestingness": 1.1833333333333331
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.020833333333333336,
          "interestingness": 0.17083333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.27734375,
      "task_completion": 0.39140625,
      "interest_arousal": 0.2890625,
      "efficiency": 0.10234374999999998,
      "dialogue_overall": 1.57421875
    }
  },
  {
    "conv_id": "kbrd_redial_c8f99970-736d-4770-b17a-4b24818ac6f7",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3,
          "interestingness": 0.3999999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.5499999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.22083333333333338
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.23750000000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.04375,
          "interestingness": 0.28750000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.09722222222222221,
      "task_completion": 0.059722222222222225,
      "interest_arousal": 0.14444444444444443,
      "efficiency": 0.011111111111111112,
      "dialogue_overall": 1.0208333333333333
    }
  },
  {
    "conv_id": "kbrd_redial_d2e2b537-c954-4c41-944a-e976905c7ff4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9,
          "interestingness": 1.375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7749999999999999,
          "interestingness": 0.9749999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.03333333333333333,
          "interestingness": 0.41250000000000003
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.325
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.07500000000000002,
          "interestingness": 0.6687499999999998
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2671875,
      "task_completion": 0.19843750000000002,
      "interest_arousal": 0.3406249999999999,
      "efficiency": 0.0515625,
      "dialogue_overall": 1.3765625
    }
  },
  {
    "conv_id": "crbcrs_redial_d2e2b537-c954-4c41-944a-e976905c7ff4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.016666666666666666,
          "interestingness": 0.2791666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.38749999999999996,
          "interestingness": 1.05625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.046875,
          "interestingness": 0.16875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.5
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.008333333333333333,
          "interestingness": 0.20416666666666664
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.07678571428571429,
      "task_completion": 0.05803571428571429,
      "interest_arousal": 0.1294642857142857,
      "efficiency": 0.021428571428571432,
      "dialogue_overall": 1.0687499999999999
    }
  },
  {
    "conv_id": "chatgpt_redial_d67317e4-82be-4ec7-99c4-da61954237b8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.085,
          "interestingness": 0.9574999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.3875,
          "interestingness": 0.8487500000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5025000000000001,
          "interestingness": 0.18500000000000003
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.42000000000000004,
          "interestingness": 0.54
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.7593749999999999,
          "interestingness": 0.7437499999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.7259615384615384,
      "task_completion": 0.41538461538461535,
      "interest_arousal": 0.33974358974358976,
      "efficiency": 0.1455128205128205,
      "dialogue_overall": 1.843269230769231
    }
  },
  {
    "conv_id": "unicrs_redial_d67317e4-82be-4ec7-99c4-da61954237b8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6375,
          "interestingness": 0.8999999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.3500000000000001,
          "interestingness": 1.275
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.9083333333333334,
          "interestingness": 1.4791666666666665
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.4875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {}
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.07500000000000001,
          "interestingness": 0.1625
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 1.3406250000000002,
          "interestingness": 1.046875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6568181818181819,
      "task_completion": 0.7261363636363636,
      "interest_arousal": 0.4454545454545454,
      "efficiency": 0.22500000000000003,
      "dialogue_overall": 1.7909090909090908
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_df6e1f05-04d0-4d55-8d14-a5e2b0e17adf",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.32000000000000006,
          "interestingness": 0.49249999999999994
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.34375,
          "interestingness": 1.7750000000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.47625,
          "interestingness": 1.10375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.6230769230769231,
          "interestingness": 0.8365384615384616
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6675,
          "interestingness": 0.825
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.9800000000000002,
          "interestingness": 0.6575000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8425,
      "task_completion": 0.7375,
      "interest_arousal": 0.5421874999999999,
      "efficiency": 0.1815625,
      "dialogue_overall": 2.36625
    }
  },
  {
    "conv_id": "chatgpt_redial_df6e1f05-04d0-4d55-8d14-a5e2b0e17adf",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.1666666666666665,
          "interestingness": 0.9874999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.18125,
          "interestingness": 1.59375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.9937499999999999,
          "interestingness": 0.9812500000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8777777777777778,
          "interestingness": 0.9416666666666667
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5791666666666666,
          "interestingness": 0.475
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.5208333333333333,
          "interestingness": 0.5333333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 1.0119318181818182,
      "task_completion": 1.022159090909091,
      "interest_arousal": 0.6738636363636363,
      "efficiency": 0.2869318181818182,
      "dialogue_overall": 2.2999999999999994
    }
  },
  {
    "conv_id": "kbrd_redial_e0b60b18-a648-405d-a214-144a986fd655",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.20833333333333331,
          "interestingness": 0.3666666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8624999999999999,
          "interestingness": 1.0375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.19583333333333336,
          "interestingness": 0.24583333333333332
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.22500000000000003,
          "interestingness": 0.4625000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.35000000000000003
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2575,
      "task_completion": 0.25625,
      "interest_arousal": 0.20875000000000005,
      "efficiency": 0.04,
      "dialogue_overall": 1.2200000000000002
    }
  },
  {
    "conv_id": "unicrs_opendialkg_e0b60b18-a648-405d-a214-144a986fd655",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.55,
          "interestingness": 0.125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6625,
          "interestingness": 0.8562500000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.2875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.8166666666666667,
          "interestingness": 1.258333333333333
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6125,
          "interestingness": 0.55
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.43055555555555564,
      "task_completion": 0.6902777777777778,
      "interest_arousal": 0.3805555555555556,
      "efficiency": 0.1597222222222222,
      "dialogue_overall": 1.584722222222222
    }
  },
  {
    "conv_id": "unicrs_opendialkg_e10f83c5-ce2a-493b-af1e-a29526e16ae6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.75,
          "interestingness": 0.26250000000000007
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.43750000000000006,
          "interestingness": 0.21250000000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.0625,
          "interestingness": 1.2666666666666666
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.35,
          "interestingness": 0.3375
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.3625,
          "interestingness": 0.43749999999999994
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4232142857142857,
      "task_completion": 0.3928571428571429,
      "interest_arousal": 0.40178571428571425,
      "efficiency": 0.175,
      "dialogue_overall": 1.5232142857142859
    }
  },
  {
    "conv_id": "barcor_redial_e10f83c5-ce2a-493b-af1e-a29526e16ae6",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9750000000000001,
          "interestingness": 1.325
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.2666666666666667,
          "interestingness": 0.5583333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.3708333333333331,
          "interestingness": 0.8
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.9625000000000001,
          "interestingness": 1.5875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.09999999999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.661111111111111,
      "task_completion": 0.7611111111111113,
      "interest_arousal": 0.5319444444444446,
      "efficiency": 0.22500000000000003,
      "dialogue_overall": 1.948611111111111
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_e33250cc-9763-4218-92dd-c9860c10517c",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6375000000000001,
          "interestingness": 0.7375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.23125,
          "interestingness": 1.34375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.8037499999999997,
          "interestingness": 1.5987500000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.1,
          "interestingness": 1.5968749999999998
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.3837499999999998,
          "interestingness": 0.6387499999999999
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8409482758620692,
      "task_completion": 0.6556034482758621,
      "interest_arousal": 0.44008620689655176,
      "efficiency": 0.2831896551724138,
      "dialogue_overall": 2.2943965517241374
    }
  },
  {
    "conv_id": "barcor_redial_e47ea879-f857-4945-b7a0-ff1d7bf4080b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.29375,
          "interestingness": 1.175
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.49374999999999997,
          "interestingness": 0.5062500000000001
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5750000000000001,
          "interestingness": 1.09375
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.13749999999999998,
          "interestingness": 0.3541666666666667
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.3
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.32500000000000007
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1625,
      "task_completion": 0.09583333333333334,
      "interest_arousal": 0.21875,
      "efficiency": 0.0010416666666666667,
      "dialogue_overall": 1.0947916666666666
    }
  },
  {
    "conv_id": "crbcrs_redial_e5986f25-bf4e-48dc-9b3d-b83d45ea0ae1",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.6541666666666668
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7000000000000001,
          "interestingness": 0.6624999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.06875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.39375000000000004
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.64375,
          "interestingness": 0.59375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.14772727272727273,
      "task_completion": 0.16022727272727272,
      "interest_arousal": 0.13068181818181818,
      "efficiency": 0.03863636363636364,
      "dialogue_overall": 1.1352272727272728
    }
  },
  {
    "conv_id": "unicrs_redial_e5986f25-bf4e-48dc-9b3d-b83d45ea0ae1",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.3,
          "interestingness": 0.7875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.6325000000000001,
          "interestingness": 0.9999999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {}
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {}
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6225,
          "interestingness": 0.675
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.39999999999999997,
      "task_completion": 0.3886363636363636,
      "interest_arousal": 0.28409090909090906,
      "efficiency": 0.08181818181818182,
      "dialogue_overall": 1.459090909090909
    }
  },
  {
    "conv_id": "chatgpt_redial_ec1c6990-f2f7-4275-9039-8cb4dcdeb132",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7312500000000001,
          "interestingness": 0.5000000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.3750000000000002,
          "interestingness": 1.3437499999999998
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.1237499999999998,
          "interestingness": 0.9000000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.3375,
          "interestingness": 0.975
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0375,
          "interestingness": 0.20416666666666664
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.0458333333333332,
          "interestingness": 0.6333333333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6478260869565218,
      "task_completion": 0.45163043478260867,
      "interest_arousal": 0.36249999999999993,
      "efficiency": 0.18750000000000003,
      "dialogue_overall": 1.7282608695652175
    }
  },
  {
    "conv_id": "unicrs_redial_ec1c6990-f2f7-4275-9039-8cb4dcdeb132",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.18750000000000008,
          "interestingness": 0.2125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.0,
          "interestingness": 0.8333333333333335
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.275,
          "interestingness": 0.11249999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.037500000000000006
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.037500000000000006,
          "interestingness": 0.175
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3571428571428572,
      "task_completion": 0.3982142857142857,
      "interest_arousal": 0.23392857142857143,
      "efficiency": 0.27321428571428574,
      "dialogue_overall": 1.605357142857143
    }
  },
  {
    "conv_id": "unicrs_opendialkg_ec300989-22db-4bb7-907d-5971942ae11c",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.2812500000000002,
          "interestingness": 1.23125
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.9000000000000001,
          "interestingness": 0.075
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.17500000000000004,
          "interestingness": 0.8125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.5031249999999999,
          "interestingness": 0.6906249999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.07083333333333333,
          "interestingness": 0.32083333333333336
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5318181818181819,
      "task_completion": 0.5590909090909091,
      "interest_arousal": 0.3579545454545454,
      "efficiency": 0.15795454545454543,
      "dialogue_overall": 1.7284090909090908
    }
  },
  {
    "conv_id": "barcor_opendialkg_ec300989-22db-4bb7-907d-5971942ae11c",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.018750000000000003,
          "interestingness": 0.06874999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.2458333333333334,
          "interestingness": 0.5416666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6812499999999999,
          "interestingness": 0.7500000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.5437500000000001,
          "interestingness": 0.41875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5687500000000002,
          "interestingness": 0.9625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3022727272727272,
      "task_completion": 0.22499999999999998,
      "interest_arousal": 0.15909090909090912,
      "efficiency": 0.01931818181818182,
      "dialogue_overall": 1.0295454545454545
    }
  },
  {
    "conv_id": "crbcrs_redial_ed93ad5f-b83f-4c35-b1d8-0b17188b73ed",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9083333333333334,
          "interestingness": 1.2958333333333334
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.05416666666666666,
          "interestingness": 0.42499999999999993
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.16875,
          "interestingness": 0.61875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.008333333333333333,
          "interestingness": 0.09166666666666666
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0025,
          "interestingness": 0.0675
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1796875,
      "task_completion": 0.10156249999999999,
      "interest_arousal": 0.19296875000000002,
      "efficiency": 0.0859375,
      "dialogue_overall": 1.29296875
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_ed93ad5f-b83f-4c35-b1d8-0b17188b73ed",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.13333333333333333,
          "interestingness": 0.28750000000000003
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.2175,
          "interestingness": 0.7375000000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.23125,
          "interestingness": 1.1625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.5374999999999999,
          "interestingness": 0.6833333333333333
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.5,
          "interestingness": 1.0
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.12083333333333333,
          "interestingness": 0.3041666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6215909090909091,
      "task_completion": 0.3670454545454546,
      "interest_arousal": 0.2710227272727273,
      "efficiency": 0.1573863636363636,
      "dialogue_overall": 1.727272727272727
    }
  },
  {
    "conv_id": "chatgpt_redial_ef424103-6dd5-4671-8a60-016a96998f41",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9775,
          "interestingness": 1.0775000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8708333333333336,
          "interestingness": 0.48749999999999993
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6138888888888888,
          "interestingness": 0.5527777777777778
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.3944444444444444,
          "interestingness": 0.13194444444444445
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6124999999999999,
          "interestingness": 0.48750000000000004
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5323275862068966,
      "task_completion": 0.36853448275862066,
      "interest_arousal": 0.2711206896551724,
      "efficiency": 0.08275862068965517,
      "dialogue_overall": 1.504310344827586
    }
  },
  {
    "conv_id": "unicrs_redial_ef424103-6dd5-4671-8a60-016a96998f41",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.1125,
          "interestingness": 1.2375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.225,
          "interestingness": 1.3250000000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.1125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.48749999999999993
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.05,
          "interestingness": 0.6
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2107142857142857,
      "task_completion": 0.22142857142857145,
      "interest_arousal": 0.26249999999999996,
      "efficiency": 0.06071428571428573,
      "dialogue_overall": 1.1928571428571426
    }
  },
  {
    "conv_id": "kbrd_redial_ef42bb06-47e3-47f1-9fbb-8131b15f7ab0",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.11250000000000002,
          "interestingness": 0.3375000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.07916666666666666,
          "interestingness": 0.5791666666666666
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.031249999999999997,
          "interestingness": 0.115625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.04375,
          "interestingness": 0.11562500000000002
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.06874999999999999,
          "interestingness": 0.42500000000000004
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.03333333333333333,
      "task_completion": 0.023333333333333334,
      "interest_arousal": 0.033333333333333326,
      "efficiency": 0.0008333333333333334,
      "dialogue_overall": 0.745
    }
  },
  {
    "conv_id": "barcor_opendialkg_ef42bb06-47e3-47f1-9fbb-8131b15f7ab0",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.6875,
          "interestingness": 0.4625000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.8125,
          "interestingness": 0.8124999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.45312499999999994,
          "interestingness": 0.6875000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.12916666666666665,
          "interestingness": 0.4666666666666666
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.9375,
          "interestingness": 0.83125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.2278846153846154,
      "task_completion": 0.13173076923076923,
      "interest_arousal": 0.20961538461538465,
      "efficiency": 0.007692307692307693,
      "dialogue_overall": 0.9701923076923078
    }
  },
  {
    "conv_id": "unicrs_opendialkg_f2ce74aa-457a-441b-8995-7800d33f956b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.5250000000000001,
          "interestingness": 0.31250000000000006
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.22500000000000003,
          "interestingness": 0.5499999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.27083333333333337,
          "interestingness": 0.3666666666666667
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.475
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.024999999999999998,
          "interestingness": 0.12750000000000003
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.6125000000000002,
          "interestingness": 0.4875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.11923076923076924,
      "task_completion": 0.057692307692307696,
      "interest_arousal": 0.13846153846153847,
      "efficiency": 0.004807692307692308,
      "dialogue_overall": 0.9740384615384615
    }
  },
  {
    "conv_id": "kbrd_opendialkg_f2ce74aa-457a-441b-8995-7800d33f956b",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.1625,
          "interestingness": 0.32500000000000007
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.3791666666666667,
          "interestingness": 0.525
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.0
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.42500000000000004,
          "interestingness": 1.125
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.0999999999999999,
          "interestingness": 0.7000000000000001
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3859375,
      "task_completion": 0.4078124999999999,
      "interest_arousal": 0.2875,
      "efficiency": 0.06250000000000001,
      "dialogue_overall": 1.321875
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_f2dc36f1-2501-4a48-a96a-d531f5b307a8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.10312500000000002,
          "interestingness": 0.16875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.2750000000000001,
          "interestingness": 0.76125
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.04625,
          "interestingness": 1.1662499999999998
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.27749999999999997,
          "interestingness": 0.5175000000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.03375,
          "interestingness": 0.9974999999999999
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.06562500000000002,
          "interestingness": 0.525
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.34687500000000004,
          "interestingness": 0.15
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.7747596153846152,
      "task_completion": 0.5819711538461538,
      "interest_arousal": 0.5302884615384615,
      "efficiency": 0.12980769230769232,
      "dialogue_overall": 1.8437500000000002
    }
  },
  {
    "conv_id": "unicrs_opendialkg_f2dc36f1-2501-4a48-a96a-d531f5b307a8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.325,
          "interestingness": 1.16875
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5625,
          "interestingness": 0.09999999999999999
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.6375000000000001,
          "interestingness": 0.9625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.08750000000000001,
          "interestingness": 0.525
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.4666666666666667,
          "interestingness": 0.7333333333333335
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.4552083333333333,
      "task_completion": 0.20625000000000002,
      "interest_arousal": 0.384375,
      "efficiency": 0.057291666666666664,
      "dialogue_overall": 1.3083333333333331
    }
  },
  {
    "conv_id": "unicrs_opendialkg_f3129d35-3a1a-49fa-bf01-b85b91337f15",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.125,
          "interestingness": 0.11249999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.21250000000000002,
          "interestingness": 0.275
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.2541666666666667,
          "interestingness": 0.5416666666666667
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.24583333333333335,
          "interestingness": 0.7541666666666667
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.5,
          "interestingness": 0.74375
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.40625000000000006,
      "task_completion": 0.38375,
      "interest_arousal": 0.35,
      "efficiency": 0.07625000000000001,
      "dialogue_overall": 1.34875
    }
  },
  {
    "conv_id": "crbcrs_redial_f3129d35-3a1a-49fa-bf01-b85b91337f15",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.1875,
          "interestingness": 0.5166666666666666
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.18750000000000003
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.5375000000000001,
          "interestingness": 0.86875
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.6375,
          "interestingness": 0.61875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.4708333333333332,
          "interestingness": 1.0916666666666666
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.25729166666666664,
      "task_completion": 0.28229166666666666,
      "interest_arousal": 0.31041666666666673,
      "efficiency": 0.09270833333333334,
      "dialogue_overall": 1.3854166666666667
    }
  },
  {
    "conv_id": "kbrd_redial_f4f0b45b-f71c-44d3-9c42-07f5d7f3c9eb",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.5999999999999999,
          "interestingness": 0.8250000000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.0875,
          "interestingness": 0.4166666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0125,
          "interestingness": 0.11249999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.7875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.16250000000000003
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.09583333333333333,
          "interestingness": 0.15833333333333335
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.0,
          "interestingness": 0.175
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.7489583333333334,
      "task_completion": 0.5718749999999999,
      "interest_arousal": 0.3333333333333333,
      "efficiency": 0.28437500000000004,
      "dialogue_overall": 1.7416666666666665
    }
  },
  {
    "conv_id": "unicrs_opendialkg_f4f0b45b-f71c-44d3-9c42-07f5d7f3c9eb",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.25,
          "interestingness": 0.12500000000000003
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.025,
          "interestingness": 0.1625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.16874999999999998,
          "interestingness": 0.275
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.85,
          "interestingness": 0.5875
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.7333333333333335,
          "interestingness": 0.6458333333333334
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.3921875000000001,
      "task_completion": 0.34375,
      "interest_arousal": 0.33125,
      "efficiency": 0.03906250000000001,
      "dialogue_overall": 1.196875
    }
  },
  {
    "conv_id": "crbcrs_redial_f7bdfc54-445d-43f1-98fa-854ae0aaae83",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.7625000000000001,
          "interestingness": 0.6750000000000002
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.19999999999999998,
          "interestingness": 0.7041666666666668
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.20937500000000003,
          "interestingness": 0.7937500000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.0291666666666668,
          "interestingness": 1.3458333333333332
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.275,
          "interestingness": 0.9916666666666666
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.45535714285714285,
      "task_completion": 0.40089285714285716,
      "interest_arousal": 0.5999999999999999,
      "efficiency": 0.06517857142857142,
      "dialogue_overall": 1.51875
    }
  },
  {
    "conv_id": "barcor_opendialkg_f7bdfc54-445d-43f1-98fa-854ae0aaae83",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.8583333333333333,
          "interestingness": 0.6416666666666667
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.04375,
          "interestingness": 0.19062500000000002
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.04375,
          "interestingness": 0.2750000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.4375,
          "interestingness": 0.8916666666666666
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.15416666666666667,
          "interestingness": 0.24166666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.25833333333333336,
      "task_completion": 0.16083333333333333,
      "interest_arousal": 0.22250000000000006,
      "efficiency": 0.021666666666666667,
      "dialogue_overall": 1.0608333333333335
    }
  },
  {
    "conv_id": "barcor_opendialkg_f8f1280c-474b-4229-a37b-a222f09ae9e4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.2625,
          "interestingness": 0.375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.0562500000000001,
          "interestingness": 1.14375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.42500000000000004,
          "interestingness": 0.9625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.42916666666666675,
          "interestingness": 0.5541666666666667
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.0083333333333333,
          "interestingness": 0.7625
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.7925000000000001,
          "interestingness": 0.6775
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 1.2,
          "interestingness": 0.55
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6236842105263157,
      "task_completion": 0.786842105263158,
      "interest_arousal": 0.36118421052631583,
      "efficiency": 0.04671052631578948,
      "dialogue_overall": 1.5473684210526315
    }
  },
  {
    "conv_id": "barcor_redial_f8f1280c-474b-4229-a37b-a222f09ae9e4",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.81875,
          "interestingness": 1.025
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7,
          "interestingness": 0.6916666666666668
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.0374999999999999,
          "interestingness": 0.8250000000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.5499999999999999,
          "interestingness": 1.025
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.24583333333333338,
          "interestingness": 0.26666666666666666
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.13749999999999998,
          "interestingness": 0.7875
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 1.2,
          "interestingness": 1.1875
        }
      },
      {
        "turn_ind": 15,
        "turn_level_pred": {
          "relevance": 0.175,
          "interestingness": 0.31250000000000006
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.5455882352941176,
      "task_completion": 0.5227941176470587,
      "interest_arousal": 0.4308823529411765,
      "efficiency": 0.058823529411764705,
      "dialogue_overall": 1.7823529411764711
    }
  },
  {
    "conv_id": "barcor_redial_f913f35a-93c5-497d-afc5-1a7fcc5ea845",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9875,
          "interestingness": 1.2
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.008333333333333333,
          "interestingness": 0.17916666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.42500000000000004,
          "interestingness": 0.9999999999999999
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.4000000000000001,
          "interestingness": 0.9999999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.0,
          "interestingness": 0.85
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.21607142857142855,
      "task_completion": 0.13749999999999996,
      "interest_arousal": 0.2517857142857143,
      "efficiency": 0.008928571428571428,
      "dialogue_overall": 1.2785714285714285
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_f913f35a-93c5-497d-afc5-1a7fcc5ea845",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.0225,
          "interestingness": 0.7074999999999999
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.3900000000000003,
          "interestingness": 0.92375
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.42500000000000004,
          "interestingness": 1.3125
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.1725000000000003,
          "interestingness": 0.7212500000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.245,
          "interestingness": 0.92125
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.9506756756756756,
      "task_completion": 0.5756756756756756,
      "interest_arousal": 0.5560810810810811,
      "efficiency": 0.2418918918918919,
      "dialogue_overall": 2.334797297297297
    }
  },
  {
    "conv_id": "crbcrs_redial_f9f3e816-8a08-4bf1-9d7e-fd3ef4cf18e8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.12083333333333332,
          "interestingness": 0.5041666666666668
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5125,
          "interestingness": 0.9499999999999998
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.2625,
          "interestingness": 0.49999999999999994
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.04375,
          "interestingness": 0.975
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.05625,
          "interestingness": 0.7062499999999998
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.65625,
          "interestingness": 0.5625
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.18269230769230774,
      "task_completion": 0.11923076923076925,
      "interest_arousal": 0.15384615384615383,
      "efficiency": 0.04807692307692308,
      "dialogue_overall": 1.169230769230769
    }
  },
  {
    "conv_id": "chatgpt_opendialkg_f9f3e816-8a08-4bf1-9d7e-fd3ef4cf18e8",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9500000000000001,
          "interestingness": 0.6958333333333333
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.5812500000000002,
          "interestingness": 1.5750000000000004
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.0738636363636362,
          "interestingness": 0.6818181818181818
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.9160714285714288,
          "interestingness": 0.8839285714285715
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 1.0333333333333332,
          "interestingness": 0.5270833333333333
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8827586206896552,
      "task_completion": 0.735344827586207,
      "interest_arousal": 0.4267241379310344,
      "efficiency": 0.29956896551724144,
      "dialogue_overall": 2.260344827586207
    }
  },
  {
    "conv_id": "kbrd_opendialkg_fb14551b-6c59-467d-86b4-8b422495b76d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.0625,
          "interestingness": 0.25
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7208333333333333,
          "interestingness": 1.0041666666666667
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.075,
          "interestingness": 0.15000000000000002
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.39375,
          "interestingness": 0.8499999999999999
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.018750000000000003
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 0.2875,
          "interestingness": 0.5
        }
      },
      {
        "turn_ind": 13,
        "turn_level_pred": {
          "relevance": 0.30000000000000004,
          "interestingness": 0.7666666666666666
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.1701923076923077,
      "task_completion": 0.1105769230769231,
      "interest_arousal": 0.1557692307692308,
      "efficiency": 0.06826923076923076,
      "dialogue_overall": 0.8365384615384616
    }
  },
  {
    "conv_id": "crbcrs_redial_fb14551b-6c59-467d-86b4-8b422495b76d",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.69375,
          "interestingness": 0.6687500000000001
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.20416666666666666,
          "interestingness": 0.8083333333333333
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.0375,
          "interestingness": 0.2625
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.5291666666666668,
          "interestingness": 0.8
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6875,
          "interestingness": 0.275
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.25416666666666665,
      "task_completion": 0.18333333333333335,
      "interest_arousal": 0.44270833333333337,
      "efficiency": 0.03229166666666666,
      "dialogue_overall": 1.2895833333333335
    }
  },
  {
    "conv_id": "barcor_opendialkg_fecb512e-7910-46f3-b18c-2e3d44800519",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.9125000000000001,
          "interestingness": 0.8375
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.7124999999999999,
          "interestingness": 1.05
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.2000000000000002,
          "interestingness": 1.0250000000000001
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 1.3437499999999998,
          "interestingness": 1.2999999999999998
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.6375000000000001,
          "interestingness": 0.4916666666666667
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.6111111111111112,
      "task_completion": 0.47916666666666663,
      "interest_arousal": 0.6777777777777777,
      "efficiency": 0.1763888888888889,
      "dialogue_overall": 1.854166666666667
    }
  },
  {
    "conv_id": "chatgpt_redial_ff5e2c84-00a1-4f5c-9953-501bfefaa50e",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 1.25,
          "interestingness": 0.9666666666666668
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 1.6374999999999997,
          "interestingness": 1.6625
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 1.3025000000000002,
          "interestingness": 0.715
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.9946428571428572,
          "interestingness": 1.0464285714285713
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.049999999999999996,
          "interestingness": 0.3333333333333334
        }
      },
      {
        "turn_ind": 11,
        "turn_level_pred": {
          "relevance": 1.0500000000000003,
          "interestingness": 0.5875
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.8912037037037037,
      "task_completion": 0.5055555555555556,
      "interest_arousal": 0.4472222222222222,
      "efficiency": 0.22083333333333338,
      "dialogue_overall": 2.0115740740740744
    }
  },
  {
    "conv_id": "kbrd_opendialkg_ff5e2c84-00a1-4f5c-9953-501bfefaa50e",
    "turns": [
      {
        "turn_ind": 1,
        "turn_level_pred": {
          "relevance": 0.325,
          "interestingness": 0.7
        }
      },
      {
        "turn_ind": 3,
        "turn_level_pred": {
          "relevance": 0.05416666666666667,
          "interestingness": 0.22916666666666669
        }
      },
      {
        "turn_ind": 5,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.056249999999999994
        }
      },
      {
        "turn_ind": 7,
        "turn_level_pred": {
          "relevance": 0.00625,
          "interestingness": 0.07187500000000001
        }
      },
      {
        "turn_ind": 9,
        "turn_level_pred": {
          "relevance": 0.125,
          "interestingness": 0.23125000000000004
        }
      }
    ],
    "dial_level_pred": {
      "understanding": 0.0375,
      "task_completion": 0.03645833333333334,
      "interest_arousal": 0.05729166666666668,
      "efficiency": 0.0020833333333333333,
      "dialogue_overall": 0.725
    }
  }
]